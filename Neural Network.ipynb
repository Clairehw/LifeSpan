{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insight1\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# from transformers import  AutoTokenizer, AutoModel\n",
    "# from transformers import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"I:\")\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_pickle('note_vec_token.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['note_split'] = data['notes'].str.replace('\\n', '').str.replace(r' +', ' ').str.split(' ') #replace \\n with space or not\n",
    "data['len_word'] = data['note_split'].apply(len)\n",
    "\n",
    "data['token_id_matrix'].apply(lambda x: x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y from noteclean_spacy_vec\n",
    "df = pd.read_pickle('clean_note_spacy_vec.pkl')\n",
    "df2 = pd.read_pickle('notes_clean.pkl')\n",
    "df['len_clean'] = df2['len_clean']\n",
    "\n",
    "filt = df[(df['len_clean']>=100) & (df['len_clean']<=2000) & (df['le_months']<= 250)] # filter data for ML\n",
    "\n",
    "X = np.array(filt['noteclean_spacy_vec'].values.tolist())\n",
    "y = filt['le_months'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnn = data[(data['le_months'] <= 250) & (data['len_word'] <= 2000)]\n",
    "X = np.array(dfnn['note_spacy_vec'].tolist())\n",
    "# y = dfnn['le_months'].astype(np.float32).to_numpy()\n",
    "y = dfnn['le_months']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.125, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 256)               77056     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 110,081\n",
      "Trainable params: 110,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36515 samples, validate on 5217 samples\n",
      "Epoch 1/3000\n",
      "36515/36515 [==============================] - 1s 24us/sample - loss: 11532.3282 - val_loss: 11432.9180\n",
      "Epoch 2/3000\n",
      "36515/36515 [==============================] - 1s 14us/sample - loss: 11342.9999 - val_loss: 11171.6240\n",
      "Epoch 3/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 11027.9199 - val_loss: 10745.0293\n",
      "Epoch 4/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 10537.8690 - val_loss: 10118.3643\n",
      "Epoch 5/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 9839.5918 - val_loss: 9265.5244\n",
      "Epoch 6/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 8909.5985 - val_loss: 8184.1631\n",
      "Epoch 7/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 7770.0859 - val_loss: 6905.1147\n",
      "Epoch 8/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 6456.7525 - val_loss: 5513.0952\n",
      "Epoch 9/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 5095.5056 - val_loss: 4162.5825\n",
      "Epoch 10/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 3852.5737 - val_loss: 3072.3823\n",
      "Epoch 11/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2958.8872 - val_loss: 2458.4980\n",
      "Epoch 12/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2604.9406 - val_loss: 2359.5530\n",
      "Epoch 13/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 2659.7576 - val_loss: 2470.9932\n",
      "Epoch 14/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 2760.2125 - val_loss: 2454.8782\n",
      "Epoch 15/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2694.7233 - val_loss: 2327.2070\n",
      "Epoch 16/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2553.1239 - val_loss: 2241.1919\n",
      "Epoch 17/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2455.7459 - val_loss: 2231.0623\n",
      "Epoch 18/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 2447.4364 - val_loss: 2242.3928\n",
      "Epoch 19/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 2434.2803 - val_loss: 2232.0874\n",
      "Epoch 20/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2431.4001 - val_loss: 2196.9265\n",
      "Epoch 21/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2397.5808 - val_loss: 2159.3350\n",
      "Epoch 22/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2361.9883 - val_loss: 2132.7283\n",
      "Epoch 23/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2352.6054 - val_loss: 2115.7263\n",
      "Epoch 24/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2350.2665 - val_loss: 2101.7007\n",
      "Epoch 25/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2329.5355 - val_loss: 2088.9880\n",
      "Epoch 26/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2317.6386 - val_loss: 2078.8586\n",
      "Epoch 27/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2292.2787 - val_loss: 2068.9438\n",
      "Epoch 28/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2286.4393 - val_loss: 2056.7395\n",
      "Epoch 29/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2283.0929 - val_loss: 2042.3022\n",
      "Epoch 30/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2271.1106 - val_loss: 2027.1187\n",
      "Epoch 31/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 2241.6681 - val_loss: 2012.8971\n",
      "Epoch 32/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2238.7634 - val_loss: 1999.2800\n",
      "Epoch 33/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2215.7795 - val_loss: 1986.6041\n",
      "Epoch 34/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 2209.0561 - val_loss: 1974.6598\n",
      "Epoch 35/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 2181.3230 - val_loss: 1962.5367\n",
      "Epoch 36/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 2196.8203 - val_loss: 1949.5875\n",
      "Epoch 37/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 2167.3311 - val_loss: 1935.4777\n",
      "Epoch 38/3000\n",
      "36515/36515 [==============================] - 0s 8us/sample - loss: 2152.9615 - val_loss: 1921.8134\n",
      "Epoch 39/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 2144.1617 - val_loss: 1908.6191\n",
      "Epoch 40/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2137.3255 - val_loss: 1896.5890\n",
      "Epoch 41/3000\n",
      "36515/36515 [==============================] - 1s 23us/sample - loss: 2114.8971 - val_loss: 1885.1698\n",
      "Epoch 42/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2113.7193 - val_loss: 1872.6591\n",
      "Epoch 43/3000\n",
      "36515/36515 [==============================] - 1s 14us/sample - loss: 2093.3527 - val_loss: 1858.8125\n",
      "Epoch 44/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2090.4727 - val_loss: 1845.6335\n",
      "Epoch 45/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2082.0961 - val_loss: 1834.0999\n",
      "Epoch 46/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2061.3141 - val_loss: 1823.4326\n",
      "Epoch 47/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 2050.3366 - val_loss: 1811.7629\n",
      "Epoch 48/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2041.8851 - val_loss: 1798.4556\n",
      "Epoch 49/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2035.9063 - val_loss: 1785.9490\n",
      "Epoch 50/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 2014.0799 - val_loss: 1774.8279\n",
      "Epoch 51/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 2013.7173 - val_loss: 1764.4114\n",
      "Epoch 52/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1984.7574 - val_loss: 1752.6523\n",
      "Epoch 53/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1989.0556 - val_loss: 1741.0266\n",
      "Epoch 54/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1983.6196 - val_loss: 1730.6920\n",
      "Epoch 55/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1965.8327 - val_loss: 1719.9210\n",
      "Epoch 56/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1953.7311 - val_loss: 1708.1503\n",
      "Epoch 57/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1960.1246 - val_loss: 1697.4248\n",
      "Epoch 58/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1936.1944 - val_loss: 1686.9250\n",
      "Epoch 59/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1922.5227 - val_loss: 1675.8014\n",
      "Epoch 60/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1915.8895 - val_loss: 1665.2847\n",
      "Epoch 61/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1908.9083 - val_loss: 1655.1277\n",
      "Epoch 62/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1890.8266 - val_loss: 1644.8473\n",
      "Epoch 63/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1878.3427 - val_loss: 1633.6599\n",
      "Epoch 64/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1879.9007 - val_loss: 1623.0078\n",
      "Epoch 65/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1864.5545 - val_loss: 1612.5889\n",
      "Epoch 66/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1862.0415 - val_loss: 1600.8079\n",
      "Epoch 67/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1845.0979 - val_loss: 1590.7101\n",
      "Epoch 68/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1839.7373 - val_loss: 1581.5702\n",
      "Epoch 69/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1812.6237 - val_loss: 1571.7301\n",
      "Epoch 70/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1817.3169 - val_loss: 1561.7715\n",
      "Epoch 71/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1801.9432 - val_loss: 1551.6409\n",
      "Epoch 72/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1806.8907 - val_loss: 1542.7826\n",
      "Epoch 73/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1786.4856 - val_loss: 1532.3152\n",
      "Epoch 74/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1770.8744 - val_loss: 1523.5753\n",
      "Epoch 75/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1782.0875 - val_loss: 1519.2535\n",
      "Epoch 76/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1759.3059 - val_loss: 1507.8214\n",
      "Epoch 77/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1754.6029 - val_loss: 1498.3682\n",
      "Epoch 78/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1740.8306 - val_loss: 1493.6166\n",
      "Epoch 79/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1734.3761 - val_loss: 1484.1261\n",
      "Epoch 80/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1742.1877 - val_loss: 1477.4240\n",
      "Epoch 81/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1737.7635 - val_loss: 1470.8505\n",
      "Epoch 82/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1713.8639 - val_loss: 1462.3362\n",
      "Epoch 83/3000\n",
      "36515/36515 [==============================] - 1s 22us/sample - loss: 1713.9972 - val_loss: 1457.0249\n",
      "Epoch 84/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1694.1400 - val_loss: 1450.7977\n",
      "Epoch 85/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1709.0199 - val_loss: 1442.9015\n",
      "Epoch 86/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1697.1847 - val_loss: 1439.0131\n",
      "Epoch 87/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1695.9798 - val_loss: 1435.3597\n",
      "Epoch 88/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1676.8235 - val_loss: 1426.5906\n",
      "Epoch 89/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1676.5422 - val_loss: 1423.9376\n",
      "Epoch 90/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1678.6372 - val_loss: 1417.0776\n",
      "Epoch 91/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1674.1190 - val_loss: 1411.6528\n",
      "Epoch 92/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1667.8145 - val_loss: 1408.2817\n",
      "Epoch 93/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1658.0822 - val_loss: 1405.9523\n",
      "Epoch 94/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1654.4089 - val_loss: 1398.8649\n",
      "Epoch 95/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1654.7019 - val_loss: 1396.8931\n",
      "Epoch 96/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1649.9701 - val_loss: 1392.4972\n",
      "Epoch 97/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1634.2600 - val_loss: 1388.2362\n",
      "Epoch 98/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1645.6369 - val_loss: 1387.6445\n",
      "Epoch 99/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1642.6029 - val_loss: 1380.7449\n",
      "Epoch 100/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1632.1740 - val_loss: 1381.4998\n",
      "Epoch 101/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1620.3278 - val_loss: 1375.4854\n",
      "Epoch 102/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1625.8243 - val_loss: 1372.3824\n",
      "Epoch 103/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1616.7706 - val_loss: 1371.1832\n",
      "Epoch 104/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1628.9412 - val_loss: 1366.8947\n",
      "Epoch 105/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1624.4578 - val_loss: 1366.6729\n",
      "Epoch 106/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1615.1365 - val_loss: 1364.7258\n",
      "Epoch 107/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1617.4052 - val_loss: 1357.1112\n",
      "Epoch 108/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1608.1290 - val_loss: 1361.8962\n",
      "Epoch 109/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1601.7166 - val_loss: 1353.9226\n",
      "Epoch 110/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1606.2881 - val_loss: 1353.8857\n",
      "Epoch 111/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1601.8163 - val_loss: 1354.5143\n",
      "Epoch 112/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1600.4160 - val_loss: 1347.1616\n",
      "Epoch 113/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1594.0088 - val_loss: 1352.1416\n",
      "Epoch 114/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1594.9845 - val_loss: 1348.4138\n",
      "Epoch 115/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1598.7767 - val_loss: 1344.6400\n",
      "Epoch 116/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1600.1733 - val_loss: 1345.4822\n",
      "Epoch 117/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1597.7052 - val_loss: 1338.8188\n",
      "Epoch 118/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1596.8232 - val_loss: 1340.6350\n",
      "Epoch 119/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1576.8179 - val_loss: 1340.3641\n",
      "Epoch 120/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1589.2321 - val_loss: 1335.4961\n",
      "Epoch 121/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1588.8069 - val_loss: 1334.2911\n",
      "Epoch 122/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1586.5081 - val_loss: 1335.7692\n",
      "Epoch 123/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1583.0297 - val_loss: 1329.7755\n",
      "Epoch 124/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1578.3969 - val_loss: 1331.7880\n",
      "Epoch 125/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1579.8677 - val_loss: 1328.7465\n",
      "Epoch 126/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1585.1605 - val_loss: 1326.6648\n",
      "Epoch 127/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1577.3337 - val_loss: 1327.7401\n",
      "Epoch 128/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1577.9376 - val_loss: 1322.1001\n",
      "Epoch 129/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1580.0590 - val_loss: 1325.2876\n",
      "Epoch 130/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1587.1879 - val_loss: 1317.5696\n",
      "Epoch 131/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1566.1403 - val_loss: 1320.1219\n",
      "Epoch 132/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1573.2820 - val_loss: 1318.2465\n",
      "Epoch 133/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1568.1712 - val_loss: 1315.3673\n",
      "Epoch 134/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1551.8413 - val_loss: 1314.6555\n",
      "Epoch 135/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1562.6879 - val_loss: 1311.7788\n",
      "Epoch 136/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1558.1298 - val_loss: 1311.5175\n",
      "Epoch 137/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1560.4351 - val_loss: 1310.3146\n",
      "Epoch 138/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1551.6998 - val_loss: 1307.5364\n",
      "Epoch 139/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1560.0252 - val_loss: 1306.5756\n",
      "Epoch 140/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1561.4131 - val_loss: 1305.4233\n",
      "Epoch 141/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1546.8019 - val_loss: 1302.8505\n",
      "Epoch 142/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1549.5434 - val_loss: 1303.0283\n",
      "Epoch 143/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1555.8350 - val_loss: 1301.8729\n",
      "Epoch 144/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1555.2823 - val_loss: 1298.2438\n",
      "Epoch 145/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1548.3647 - val_loss: 1301.1746\n",
      "Epoch 146/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1558.1133 - val_loss: 1296.1221\n",
      "Epoch 147/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1541.0685 - val_loss: 1294.5922\n",
      "Epoch 148/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1544.8804 - val_loss: 1294.6298\n",
      "Epoch 149/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1539.6258 - val_loss: 1290.1836\n",
      "Epoch 150/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1549.3504 - val_loss: 1293.3180\n",
      "Epoch 151/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1544.1540 - val_loss: 1289.5172\n",
      "Epoch 152/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1543.3615 - val_loss: 1288.5927\n",
      "Epoch 153/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1537.1207 - val_loss: 1291.1349\n",
      "Epoch 154/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1535.8440 - val_loss: 1287.1208\n",
      "Epoch 155/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1535.1031 - val_loss: 1284.6724\n",
      "Epoch 156/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1532.7480 - val_loss: 1285.0524\n",
      "Epoch 157/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1541.0871 - val_loss: 1283.3210\n",
      "Epoch 158/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1538.3548 - val_loss: 1281.9792\n",
      "Epoch 159/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1529.4496 - val_loss: 1278.7395\n",
      "Epoch 160/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1522.5643 - val_loss: 1279.9637\n",
      "Epoch 161/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1533.4819 - val_loss: 1277.9225\n",
      "Epoch 162/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1530.2114 - val_loss: 1278.8053\n",
      "Epoch 163/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1523.4939 - val_loss: 1274.1437\n",
      "Epoch 164/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1529.3535 - val_loss: 1275.7092\n",
      "Epoch 165/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1522.7965 - val_loss: 1272.1565\n",
      "Epoch 166/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1535.0458 - val_loss: 1274.6763\n",
      "Epoch 167/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1525.9927 - val_loss: 1271.1823\n",
      "Epoch 168/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1517.2514 - val_loss: 1268.8290\n",
      "Epoch 169/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1518.0146 - val_loss: 1273.9177\n",
      "Epoch 170/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1519.6451 - val_loss: 1268.7479\n",
      "Epoch 171/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1523.9761 - val_loss: 1268.9373\n",
      "Epoch 172/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1520.2342 - val_loss: 1268.4496\n",
      "Epoch 173/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1518.8100 - val_loss: 1262.6041\n",
      "Epoch 174/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1528.6632 - val_loss: 1266.5039\n",
      "Epoch 175/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1514.2204 - val_loss: 1262.8419\n",
      "Epoch 176/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1518.8099 - val_loss: 1262.3159\n",
      "Epoch 177/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1510.2705 - val_loss: 1261.3254\n",
      "Epoch 178/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1517.1923 - val_loss: 1260.3291\n",
      "Epoch 179/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1509.3792 - val_loss: 1260.9625\n",
      "Epoch 180/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1508.2622 - val_loss: 1256.9636\n",
      "Epoch 181/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1514.9666 - val_loss: 1260.9280\n",
      "Epoch 182/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1512.4180 - val_loss: 1255.4105\n",
      "Epoch 183/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1497.0203 - val_loss: 1257.6335\n",
      "Epoch 184/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1512.1150 - val_loss: 1253.7848\n",
      "Epoch 185/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1501.1220 - val_loss: 1253.1063\n",
      "Epoch 186/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1512.5363 - val_loss: 1257.6506\n",
      "Epoch 187/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1494.2397 - val_loss: 1248.9044\n",
      "Epoch 188/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1514.5214 - val_loss: 1251.5509\n",
      "Epoch 189/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1508.0098 - val_loss: 1250.1899\n",
      "Epoch 190/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1495.8910 - val_loss: 1251.3772\n",
      "Epoch 191/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1495.8471 - val_loss: 1245.8682\n",
      "Epoch 192/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1496.5410 - val_loss: 1250.0686\n",
      "Epoch 193/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1509.4532 - val_loss: 1243.9106\n",
      "Epoch 194/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1490.6148 - val_loss: 1246.3809\n",
      "Epoch 195/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1499.3159 - val_loss: 1244.1365\n",
      "Epoch 196/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1507.2562 - val_loss: 1243.7788\n",
      "Epoch 197/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1498.3371 - val_loss: 1243.7703\n",
      "Epoch 198/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1485.4039 - val_loss: 1243.2767\n",
      "Epoch 199/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1493.3205 - val_loss: 1241.0752\n",
      "Epoch 200/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1504.2323 - val_loss: 1245.8193\n",
      "Epoch 201/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1486.9051 - val_loss: 1236.5521\n",
      "Epoch 202/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1497.8495 - val_loss: 1240.9424\n",
      "Epoch 203/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1493.5877 - val_loss: 1238.7029\n",
      "Epoch 204/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1486.0194 - val_loss: 1235.7902\n",
      "Epoch 205/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1492.7198 - val_loss: 1238.5203\n",
      "Epoch 206/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1484.6225 - val_loss: 1235.7201\n",
      "Epoch 207/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1488.3226 - val_loss: 1234.3053\n",
      "Epoch 208/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1504.1510 - val_loss: 1235.4767\n",
      "Epoch 209/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1495.6668 - val_loss: 1234.7815\n",
      "Epoch 210/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1489.1739 - val_loss: 1232.0551\n",
      "Epoch 211/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1484.2430 - val_loss: 1231.2123\n",
      "Epoch 212/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1478.9293 - val_loss: 1230.3085\n",
      "Epoch 213/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1488.9680 - val_loss: 1233.6299\n",
      "Epoch 214/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1490.4898 - val_loss: 1226.0232\n",
      "Epoch 215/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1478.1763 - val_loss: 1232.7899\n",
      "Epoch 216/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1489.2626 - val_loss: 1225.5626\n",
      "Epoch 217/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1472.0331 - val_loss: 1229.0026\n",
      "Epoch 218/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1491.5623 - val_loss: 1227.2594\n",
      "Epoch 219/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1483.6834 - val_loss: 1226.6224\n",
      "Epoch 220/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1476.5112 - val_loss: 1224.5734\n",
      "Epoch 221/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1472.7043 - val_loss: 1223.8981\n",
      "Epoch 222/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1480.2917 - val_loss: 1224.9696\n",
      "Epoch 223/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1471.0438 - val_loss: 1220.8870\n",
      "Epoch 224/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1467.1646 - val_loss: 1223.4321\n",
      "Epoch 225/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1481.8244 - val_loss: 1219.6033\n",
      "Epoch 226/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1466.9688 - val_loss: 1222.1342\n",
      "Epoch 227/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1471.0115 - val_loss: 1219.2411\n",
      "Epoch 228/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1477.6357 - val_loss: 1219.1398\n",
      "Epoch 229/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1470.3477 - val_loss: 1220.5591\n",
      "Epoch 230/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1465.2908 - val_loss: 1216.2426\n",
      "Epoch 231/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1470.9649 - val_loss: 1219.0043\n",
      "Epoch 232/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1472.3025 - val_loss: 1217.1532\n",
      "Epoch 233/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1468.1244 - val_loss: 1214.7883\n",
      "Epoch 234/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1470.0032 - val_loss: 1212.7660\n",
      "Epoch 235/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1467.0636 - val_loss: 1218.5216\n",
      "Epoch 236/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1480.5426 - val_loss: 1209.5405\n",
      "Epoch 237/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1454.0414 - val_loss: 1214.5338\n",
      "Epoch 238/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1460.7532 - val_loss: 1208.6818\n",
      "Epoch 239/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1466.3408 - val_loss: 1215.7393\n",
      "Epoch 240/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1448.3214 - val_loss: 1205.7620\n",
      "Epoch 241/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1457.2379 - val_loss: 1215.3778\n",
      "Epoch 242/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1464.9431 - val_loss: 1204.7487\n",
      "Epoch 243/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1465.7690 - val_loss: 1211.4200\n",
      "Epoch 244/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1458.0996 - val_loss: 1205.2112\n",
      "Epoch 245/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1456.3968 - val_loss: 1210.6302\n",
      "Epoch 246/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1459.5031 - val_loss: 1204.8245\n",
      "Epoch 247/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1460.1636 - val_loss: 1207.8236\n",
      "Epoch 248/3000\n",
      "36515/36515 [==============================] - 1s 14us/sample - loss: 1458.9687 - val_loss: 1204.3009\n",
      "Epoch 249/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1464.0911 - val_loss: 1203.2390\n",
      "Epoch 250/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1457.2335 - val_loss: 1204.4445\n",
      "Epoch 251/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1458.4048 - val_loss: 1202.1949\n",
      "Epoch 252/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1453.3424 - val_loss: 1204.7607\n",
      "Epoch 253/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1457.4283 - val_loss: 1198.7317\n",
      "Epoch 254/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1464.5240 - val_loss: 1200.4010\n",
      "Epoch 255/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1453.0933 - val_loss: 1199.2566\n",
      "Epoch 256/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1460.8836 - val_loss: 1201.0895\n",
      "Epoch 257/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1453.9046 - val_loss: 1197.4595\n",
      "Epoch 258/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1451.6650 - val_loss: 1201.1090\n",
      "Epoch 259/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1449.1184 - val_loss: 1198.1687\n",
      "Epoch 260/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1461.9313 - val_loss: 1197.8080\n",
      "Epoch 261/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1456.6214 - val_loss: 1196.2942\n",
      "Epoch 262/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1456.5484 - val_loss: 1194.8096\n",
      "Epoch 263/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1450.8033 - val_loss: 1195.2175\n",
      "Epoch 264/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1454.2924 - val_loss: 1195.9230\n",
      "Epoch 265/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1460.6298 - val_loss: 1192.3157\n",
      "Epoch 266/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1443.8561 - val_loss: 1194.4661\n",
      "Epoch 267/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1452.0525 - val_loss: 1194.3254\n",
      "Epoch 268/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1445.5810 - val_loss: 1192.5476\n",
      "Epoch 269/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1447.9317 - val_loss: 1191.2175\n",
      "Epoch 270/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1440.1200 - val_loss: 1190.7570\n",
      "Epoch 271/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1443.2007 - val_loss: 1190.0652\n",
      "Epoch 272/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1446.1303 - val_loss: 1189.2625\n",
      "Epoch 273/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1444.9435 - val_loss: 1188.4572\n",
      "Epoch 274/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1448.6555 - val_loss: 1189.3137\n",
      "Epoch 275/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1436.6282 - val_loss: 1186.2972\n",
      "Epoch 276/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1450.7065 - val_loss: 1189.7769\n",
      "Epoch 277/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1440.6704 - val_loss: 1188.1289\n",
      "Epoch 278/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1436.2526 - val_loss: 1184.6090\n",
      "Epoch 279/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1444.5261 - val_loss: 1187.7723\n",
      "Epoch 280/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1448.3448 - val_loss: 1184.5985\n",
      "Epoch 281/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1443.4244 - val_loss: 1189.6301\n",
      "Epoch 282/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1444.6595 - val_loss: 1180.6437\n",
      "Epoch 283/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1437.4159 - val_loss: 1186.7777\n",
      "Epoch 284/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1430.1295 - val_loss: 1180.0752\n",
      "Epoch 285/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1446.2667 - val_loss: 1189.6849\n",
      "Epoch 286/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1436.1897 - val_loss: 1180.0328\n",
      "Epoch 287/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1439.9578 - val_loss: 1182.6456\n",
      "Epoch 288/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1437.1205 - val_loss: 1180.8121\n",
      "Epoch 289/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1447.1291 - val_loss: 1179.0614\n",
      "Epoch 290/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1441.1487 - val_loss: 1181.3473\n",
      "Epoch 291/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1432.8419 - val_loss: 1178.7429\n",
      "Epoch 292/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1432.8226 - val_loss: 1178.3473\n",
      "Epoch 293/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1434.2233 - val_loss: 1179.0470\n",
      "Epoch 294/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1441.3365 - val_loss: 1175.2686\n",
      "Epoch 295/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1441.7367 - val_loss: 1177.4982\n",
      "Epoch 296/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1444.6749 - val_loss: 1175.3593\n",
      "Epoch 297/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1425.1069 - val_loss: 1177.1514\n",
      "Epoch 298/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1438.7159 - val_loss: 1174.7745\n",
      "Epoch 299/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1431.8068 - val_loss: 1176.8834\n",
      "Epoch 300/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1427.4241 - val_loss: 1173.0858\n",
      "Epoch 301/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1432.7730 - val_loss: 1174.7576\n",
      "Epoch 302/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1434.7711 - val_loss: 1169.9506\n",
      "Epoch 303/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1423.9356 - val_loss: 1176.8508\n",
      "Epoch 304/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1436.1305 - val_loss: 1169.6146\n",
      "Epoch 305/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1426.8209 - val_loss: 1175.3743\n",
      "Epoch 306/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1424.9899 - val_loss: 1170.7412\n",
      "Epoch 307/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1433.4588 - val_loss: 1167.9651\n",
      "Epoch 308/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1428.8644 - val_loss: 1172.6686\n",
      "Epoch 309/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1426.3256 - val_loss: 1168.9139\n",
      "Epoch 310/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1433.3710 - val_loss: 1173.8486\n",
      "Epoch 311/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1413.4724 - val_loss: 1166.6140\n",
      "Epoch 312/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1433.4528 - val_loss: 1170.5582\n",
      "Epoch 313/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1429.1345 - val_loss: 1165.7065\n",
      "Epoch 314/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1424.3052 - val_loss: 1166.3893\n",
      "Epoch 315/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1426.3174 - val_loss: 1171.7389\n",
      "Epoch 316/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1429.4857 - val_loss: 1163.4396\n",
      "Epoch 317/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1425.5701 - val_loss: 1174.4130\n",
      "Epoch 318/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1418.9585 - val_loss: 1161.7028\n",
      "Epoch 319/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1428.2617 - val_loss: 1168.4384\n",
      "Epoch 320/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1428.9516 - val_loss: 1161.8917\n",
      "Epoch 321/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1432.1926 - val_loss: 1167.7882\n",
      "Epoch 322/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1424.5478 - val_loss: 1162.9080\n",
      "Epoch 323/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1425.0007 - val_loss: 1166.5939\n",
      "Epoch 324/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1434.0805 - val_loss: 1161.8129\n",
      "Epoch 325/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1427.2425 - val_loss: 1165.2925\n",
      "Epoch 326/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1421.9403 - val_loss: 1160.2513\n",
      "Epoch 327/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1425.2667 - val_loss: 1164.3510\n",
      "Epoch 328/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1421.3857 - val_loss: 1161.3546\n",
      "Epoch 329/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1431.8380 - val_loss: 1162.7448\n",
      "Epoch 330/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1420.5548 - val_loss: 1160.4664\n",
      "Epoch 331/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1411.7634 - val_loss: 1159.5244\n",
      "Epoch 332/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1424.9939 - val_loss: 1161.9083\n",
      "Epoch 333/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1424.0445 - val_loss: 1155.4233\n",
      "Epoch 334/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1419.4103 - val_loss: 1160.6440\n",
      "Epoch 335/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1411.3716 - val_loss: 1156.1353\n",
      "Epoch 336/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1405.3533 - val_loss: 1157.3622\n",
      "Epoch 337/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1418.3561 - val_loss: 1155.9983\n",
      "Epoch 338/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1418.9450 - val_loss: 1156.5358\n",
      "Epoch 339/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1411.0195 - val_loss: 1155.5680\n",
      "Epoch 340/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1412.0644 - val_loss: 1157.1279\n",
      "Epoch 341/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1408.2068 - val_loss: 1157.2203\n",
      "Epoch 342/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1423.0600 - val_loss: 1153.6057\n",
      "Epoch 343/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1426.7406 - val_loss: 1156.9612\n",
      "Epoch 344/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1409.2167 - val_loss: 1152.4821\n",
      "Epoch 345/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1415.3970 - val_loss: 1156.0605\n",
      "Epoch 346/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1420.2085 - val_loss: 1152.2844\n",
      "Epoch 347/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1423.1182 - val_loss: 1153.7841\n",
      "Epoch 348/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1415.6546 - val_loss: 1152.0142\n",
      "Epoch 349/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1405.5231 - val_loss: 1156.1143\n",
      "Epoch 350/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1411.7062 - val_loss: 1148.1284\n",
      "Epoch 351/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1410.5959 - val_loss: 1155.8073\n",
      "Epoch 352/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1396.6121 - val_loss: 1148.0760\n",
      "Epoch 353/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1420.8821 - val_loss: 1153.6588\n",
      "Epoch 354/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1413.1150 - val_loss: 1150.6512\n",
      "Epoch 355/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1421.5095 - val_loss: 1149.2638\n",
      "Epoch 356/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1405.5797 - val_loss: 1146.8721\n",
      "Epoch 357/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1417.9970 - val_loss: 1153.6448\n",
      "Epoch 358/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1408.6713 - val_loss: 1145.2054\n",
      "Epoch 359/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1410.2631 - val_loss: 1154.5854\n",
      "Epoch 360/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1397.6716 - val_loss: 1143.8925\n",
      "Epoch 361/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1415.0789 - val_loss: 1157.5524\n",
      "Epoch 362/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1405.5103 - val_loss: 1144.9261\n",
      "Epoch 363/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1395.8599 - val_loss: 1146.8831\n",
      "Epoch 364/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1416.1401 - val_loss: 1150.7195\n",
      "Epoch 365/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1408.2620 - val_loss: 1143.6316\n",
      "Epoch 366/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1411.2732 - val_loss: 1147.0338\n",
      "Epoch 367/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1397.6745 - val_loss: 1142.4515\n",
      "Epoch 368/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1419.9420 - val_loss: 1147.4811\n",
      "Epoch 369/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1409.0646 - val_loss: 1142.4883\n",
      "Epoch 370/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1411.1513 - val_loss: 1147.9449\n",
      "Epoch 371/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1397.7410 - val_loss: 1138.7808\n",
      "Epoch 372/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1400.5761 - val_loss: 1150.6414\n",
      "Epoch 373/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1400.5172 - val_loss: 1139.5488\n",
      "Epoch 374/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1408.8917 - val_loss: 1147.3821\n",
      "Epoch 375/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1407.4707 - val_loss: 1141.6135\n",
      "Epoch 376/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1401.9434 - val_loss: 1142.0024\n",
      "Epoch 377/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1409.8395 - val_loss: 1142.4764\n",
      "Epoch 378/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1400.7210 - val_loss: 1137.4152\n",
      "Epoch 379/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1397.0438 - val_loss: 1147.5465\n",
      "Epoch 380/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1410.1050 - val_loss: 1135.9933\n",
      "Epoch 381/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1404.9770 - val_loss: 1146.2273\n",
      "Epoch 382/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1396.2361 - val_loss: 1139.1974\n",
      "Epoch 383/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1403.9574 - val_loss: 1141.0127\n",
      "Epoch 384/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1394.7813 - val_loss: 1139.3254\n",
      "Epoch 385/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1404.5078 - val_loss: 1136.7777\n",
      "Epoch 386/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1398.4503 - val_loss: 1142.5106\n",
      "Epoch 387/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1407.1651 - val_loss: 1133.8044\n",
      "Epoch 388/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1390.8313 - val_loss: 1146.3579\n",
      "Epoch 389/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1404.4855 - val_loss: 1135.6893\n",
      "Epoch 390/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1392.3966 - val_loss: 1141.1460\n",
      "Epoch 391/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1405.8641 - val_loss: 1133.5215\n",
      "Epoch 392/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1403.5081 - val_loss: 1137.0640\n",
      "Epoch 393/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1392.7466 - val_loss: 1139.5610\n",
      "Epoch 394/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1396.4410 - val_loss: 1131.3436\n",
      "Epoch 395/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1398.9576 - val_loss: 1144.0560\n",
      "Epoch 396/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1396.2749 - val_loss: 1131.2048\n",
      "Epoch 397/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1405.6309 - val_loss: 1137.2522\n",
      "Epoch 398/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1397.3797 - val_loss: 1134.5333\n",
      "Epoch 399/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1394.3520 - val_loss: 1132.0992\n",
      "Epoch 400/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1396.0376 - val_loss: 1137.7361\n",
      "Epoch 401/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1398.3837 - val_loss: 1132.1202\n",
      "Epoch 402/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1402.8805 - val_loss: 1137.6200\n",
      "Epoch 403/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1390.9428 - val_loss: 1131.7134\n",
      "Epoch 404/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1406.7584 - val_loss: 1130.5371\n",
      "Epoch 405/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1395.0999 - val_loss: 1136.9976\n",
      "Epoch 406/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1394.0352 - val_loss: 1129.9609\n",
      "Epoch 407/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1393.4764 - val_loss: 1132.4131\n",
      "Epoch 408/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1390.0901 - val_loss: 1133.4972\n",
      "Epoch 409/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1393.2207 - val_loss: 1129.5193\n",
      "Epoch 410/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1389.4332 - val_loss: 1129.3091\n",
      "Epoch 411/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1396.5030 - val_loss: 1134.9452\n",
      "Epoch 412/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1398.9989 - val_loss: 1124.8062\n",
      "Epoch 413/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1393.0238 - val_loss: 1136.3916\n",
      "Epoch 414/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1397.1021 - val_loss: 1124.6470\n",
      "Epoch 415/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1395.5739 - val_loss: 1130.4360\n",
      "Epoch 416/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1397.1673 - val_loss: 1129.0592\n",
      "Epoch 417/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1394.2539 - val_loss: 1129.8062\n",
      "Epoch 418/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1382.6807 - val_loss: 1126.8073\n",
      "Epoch 419/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1385.1818 - val_loss: 1130.2488\n",
      "Epoch 420/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1386.8261 - val_loss: 1126.9866\n",
      "Epoch 421/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1384.7488 - val_loss: 1125.4742\n",
      "Epoch 422/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1387.6233 - val_loss: 1127.8925\n",
      "Epoch 423/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1384.1392 - val_loss: 1130.4525\n",
      "Epoch 424/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1388.8012 - val_loss: 1121.7926\n",
      "Epoch 425/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1389.1165 - val_loss: 1128.5604\n",
      "Epoch 426/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1387.8706 - val_loss: 1125.7898\n",
      "Epoch 427/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1379.2109 - val_loss: 1123.5189\n",
      "Epoch 428/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1399.1695 - val_loss: 1125.2422\n",
      "Epoch 429/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1388.0017 - val_loss: 1128.6041\n",
      "Epoch 430/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1397.2089 - val_loss: 1122.5691\n",
      "Epoch 431/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1391.1236 - val_loss: 1129.4751\n",
      "Epoch 432/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1380.6999 - val_loss: 1123.2798\n",
      "Epoch 433/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1378.3352 - val_loss: 1120.8802\n",
      "Epoch 434/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1387.7398 - val_loss: 1130.5956\n",
      "Epoch 435/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1386.4307 - val_loss: 1122.2142\n",
      "Epoch 436/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1388.7927 - val_loss: 1124.8607\n",
      "Epoch 437/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1387.0272 - val_loss: 1124.0792\n",
      "Epoch 438/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1382.3220 - val_loss: 1121.5122\n",
      "Epoch 439/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1389.0308 - val_loss: 1124.5129\n",
      "Epoch 440/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1368.4619 - val_loss: 1119.7969\n",
      "Epoch 441/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1392.3583 - val_loss: 1121.3962\n",
      "Epoch 442/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1383.7182 - val_loss: 1125.8625\n",
      "Epoch 443/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1373.6410 - val_loss: 1117.0734\n",
      "Epoch 444/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1372.4292 - val_loss: 1122.7537\n",
      "Epoch 445/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1384.1237 - val_loss: 1118.0845\n",
      "Epoch 446/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1384.1936 - val_loss: 1120.5879\n",
      "Epoch 447/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1395.7144 - val_loss: 1120.2748\n",
      "Epoch 448/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1392.7708 - val_loss: 1115.5275\n",
      "Epoch 449/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1384.8979 - val_loss: 1127.9574\n",
      "Epoch 450/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1381.0960 - val_loss: 1117.0497\n",
      "Epoch 451/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1376.7930 - val_loss: 1121.1956\n",
      "Epoch 452/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1381.2461 - val_loss: 1120.3337\n",
      "Epoch 453/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1372.7046 - val_loss: 1116.5836\n",
      "Epoch 454/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1385.8737 - val_loss: 1119.7822\n",
      "Epoch 455/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1384.3641 - val_loss: 1122.2828\n",
      "Epoch 456/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1391.1631 - val_loss: 1113.2910\n",
      "Epoch 457/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1393.6707 - val_loss: 1121.2545\n",
      "Epoch 458/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1381.2434 - val_loss: 1121.9623\n",
      "Epoch 459/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1378.3175 - val_loss: 1114.3441\n",
      "Epoch 460/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1371.5469 - val_loss: 1120.4575\n",
      "Epoch 461/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1388.3427 - val_loss: 1112.9707\n",
      "Epoch 462/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1370.8107 - val_loss: 1117.4198\n",
      "Epoch 463/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1382.4531 - val_loss: 1114.5459\n",
      "Epoch 464/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1373.2450 - val_loss: 1118.2542\n",
      "Epoch 465/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1369.8854 - val_loss: 1118.9795\n",
      "Epoch 466/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1378.5409 - val_loss: 1112.8356\n",
      "Epoch 467/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1378.9300 - val_loss: 1116.3994\n",
      "Epoch 468/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1379.0740 - val_loss: 1114.0784\n",
      "Epoch 469/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1372.0841 - val_loss: 1115.2086\n",
      "Epoch 470/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1378.2549 - val_loss: 1115.3564\n",
      "Epoch 471/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1371.0834 - val_loss: 1113.4685\n",
      "Epoch 472/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1373.7820 - val_loss: 1116.1858\n",
      "Epoch 473/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1382.2282 - val_loss: 1110.0323\n",
      "Epoch 474/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1379.8154 - val_loss: 1119.4912\n",
      "Epoch 475/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1379.4498 - val_loss: 1111.5231\n",
      "Epoch 476/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1377.2902 - val_loss: 1115.8495\n",
      "Epoch 477/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1374.5415 - val_loss: 1111.6659\n",
      "Epoch 478/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1372.8777 - val_loss: 1109.6904\n",
      "Epoch 479/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1371.6385 - val_loss: 1117.3223\n",
      "Epoch 480/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1373.2090 - val_loss: 1108.6849\n",
      "Epoch 481/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1381.7068 - val_loss: 1111.3597\n",
      "Epoch 482/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1371.9585 - val_loss: 1111.4417\n",
      "Epoch 483/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1365.5717 - val_loss: 1109.9219\n",
      "Epoch 484/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1376.0978 - val_loss: 1111.2224\n",
      "Epoch 485/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1383.9932 - val_loss: 1110.8453\n",
      "Epoch 486/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1377.0091 - val_loss: 1109.0707\n",
      "Epoch 487/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1377.9141 - val_loss: 1113.0203\n",
      "Epoch 488/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1383.2158 - val_loss: 1111.2792\n",
      "Epoch 489/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1375.0938 - val_loss: 1106.8784\n",
      "Epoch 490/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1374.9163 - val_loss: 1117.3381\n",
      "Epoch 491/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1370.0863 - val_loss: 1107.4480\n",
      "Epoch 492/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1373.8797 - val_loss: 1111.7988\n",
      "Epoch 493/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1374.9817 - val_loss: 1115.6030\n",
      "Epoch 494/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1371.0866 - val_loss: 1103.1084\n",
      "Epoch 495/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1377.6604 - val_loss: 1113.1259\n",
      "Epoch 496/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1378.4358 - val_loss: 1114.7430\n",
      "Epoch 497/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1367.8821 - val_loss: 1103.5524\n",
      "Epoch 498/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1368.8937 - val_loss: 1106.7455\n",
      "Epoch 499/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1384.7000 - val_loss: 1118.4109\n",
      "Epoch 500/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1367.2852 - val_loss: 1102.6956\n",
      "Epoch 501/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1382.9859 - val_loss: 1115.1245\n",
      "Epoch 502/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1362.2124 - val_loss: 1108.0364\n",
      "Epoch 503/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1373.8733 - val_loss: 1102.2194\n",
      "Epoch 504/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1360.4347 - val_loss: 1113.6163\n",
      "Epoch 505/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1369.4271 - val_loss: 1104.4485\n",
      "Epoch 506/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1370.7016 - val_loss: 1106.0243\n",
      "Epoch 507/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1366.9742 - val_loss: 1106.7197\n",
      "Epoch 508/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1366.0805 - val_loss: 1103.8602\n",
      "Epoch 509/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1364.0788 - val_loss: 1105.0648\n",
      "Epoch 510/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1375.1295 - val_loss: 1103.4697\n",
      "Epoch 511/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1377.8366 - val_loss: 1107.4329\n",
      "Epoch 512/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1363.3244 - val_loss: 1104.0858\n",
      "Epoch 513/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1359.4851 - val_loss: 1102.9633\n",
      "Epoch 514/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1366.1245 - val_loss: 1105.3590\n",
      "Epoch 515/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1363.6553 - val_loss: 1101.4303\n",
      "Epoch 516/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1363.4700 - val_loss: 1105.8972\n",
      "Epoch 517/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1363.6340 - val_loss: 1102.1101\n",
      "Epoch 518/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1356.9254 - val_loss: 1104.5106\n",
      "Epoch 519/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1371.3175 - val_loss: 1104.1903\n",
      "Epoch 520/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1370.6869 - val_loss: 1104.0565\n",
      "Epoch 521/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1363.8119 - val_loss: 1103.2214\n",
      "Epoch 522/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1363.8881 - val_loss: 1100.8209\n",
      "Epoch 523/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1360.4549 - val_loss: 1102.3698\n",
      "Epoch 524/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1357.7505 - val_loss: 1099.1962\n",
      "Epoch 525/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1373.3214 - val_loss: 1102.7292\n",
      "Epoch 526/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1362.4997 - val_loss: 1105.4053\n",
      "Epoch 527/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1360.9903 - val_loss: 1103.1085\n",
      "Epoch 528/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1367.3444 - val_loss: 1099.6559\n",
      "Epoch 529/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1360.8824 - val_loss: 1101.7931\n",
      "Epoch 530/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1363.7302 - val_loss: 1100.8899\n",
      "Epoch 531/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1364.8250 - val_loss: 1098.6174\n",
      "Epoch 532/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1365.5103 - val_loss: 1106.4576\n",
      "Epoch 533/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1367.2228 - val_loss: 1099.4215\n",
      "Epoch 534/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1366.1350 - val_loss: 1099.9664\n",
      "Epoch 535/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.1889 - val_loss: 1100.4349\n",
      "Epoch 536/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1370.5323 - val_loss: 1099.9009\n",
      "Epoch 537/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1362.7775 - val_loss: 1101.8895\n",
      "Epoch 538/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1354.3210 - val_loss: 1100.5094\n",
      "Epoch 539/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1364.8541 - val_loss: 1094.0948\n",
      "Epoch 540/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1359.9743 - val_loss: 1103.6842\n",
      "Epoch 541/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1359.0865 - val_loss: 1102.2830\n",
      "Epoch 542/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1360.8648 - val_loss: 1095.1707\n",
      "Epoch 543/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1373.3394 - val_loss: 1100.0277\n",
      "Epoch 544/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1360.4158 - val_loss: 1097.0520\n",
      "Epoch 545/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1346.4254 - val_loss: 1099.6151\n",
      "Epoch 546/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.4471 - val_loss: 1098.0723\n",
      "Epoch 547/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1362.6943 - val_loss: 1104.2085\n",
      "Epoch 548/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1365.3654 - val_loss: 1096.1216\n",
      "Epoch 549/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1347.9942 - val_loss: 1094.2008\n",
      "Epoch 550/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1361.1605 - val_loss: 1106.4307\n",
      "Epoch 551/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1366.0845 - val_loss: 1096.4355\n",
      "Epoch 552/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1363.0699 - val_loss: 1094.7906\n",
      "Epoch 553/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1362.1807 - val_loss: 1105.4573\n",
      "Epoch 554/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1362.4036 - val_loss: 1092.3264\n",
      "Epoch 555/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1353.3801 - val_loss: 1091.3318\n",
      "Epoch 556/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1364.0066 - val_loss: 1103.9329\n",
      "Epoch 557/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1347.4349 - val_loss: 1095.2935\n",
      "Epoch 558/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1357.0047 - val_loss: 1091.6172\n",
      "Epoch 559/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1362.3315 - val_loss: 1113.6826\n",
      "Epoch 560/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1364.7715 - val_loss: 1092.3408\n",
      "Epoch 561/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1354.1263 - val_loss: 1090.5016\n",
      "Epoch 562/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1360.3638 - val_loss: 1108.7563\n",
      "Epoch 563/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1350.1958 - val_loss: 1091.6726\n",
      "Epoch 564/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1355.3391 - val_loss: 1094.1533\n",
      "Epoch 565/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1354.9699 - val_loss: 1100.3231\n",
      "Epoch 566/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1360.9524 - val_loss: 1089.8517\n",
      "Epoch 567/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1352.8938 - val_loss: 1097.0493\n",
      "Epoch 568/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1351.3188 - val_loss: 1091.4340\n",
      "Epoch 569/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1364.5039 - val_loss: 1093.0072\n",
      "Epoch 570/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.6553 - val_loss: 1095.0935\n",
      "Epoch 571/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1352.3591 - val_loss: 1096.2264\n",
      "Epoch 572/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1352.6309 - val_loss: 1096.2738\n",
      "Epoch 573/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1349.6607 - val_loss: 1088.9792\n",
      "Epoch 574/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1360.6596 - val_loss: 1092.5697\n",
      "Epoch 575/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.0385 - val_loss: 1106.1448\n",
      "Epoch 576/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1348.7380 - val_loss: 1089.7555\n",
      "Epoch 577/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1364.0041 - val_loss: 1095.8066\n",
      "Epoch 578/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1350.4210 - val_loss: 1089.4752\n",
      "Epoch 579/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1364.7085 - val_loss: 1090.6692\n",
      "Epoch 580/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1349.7928 - val_loss: 1091.9868\n",
      "Epoch 581/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.6279 - val_loss: 1093.9017\n",
      "Epoch 582/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1350.8964 - val_loss: 1089.9917\n",
      "Epoch 583/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1360.3119 - val_loss: 1092.7509\n",
      "Epoch 584/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.3610 - val_loss: 1089.0013\n",
      "Epoch 585/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1357.8363 - val_loss: 1096.7550\n",
      "Epoch 586/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1346.3363 - val_loss: 1088.7634\n",
      "Epoch 587/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1351.8401 - val_loss: 1091.4445\n",
      "Epoch 588/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1348.4394 - val_loss: 1092.9846\n",
      "Epoch 589/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.5224 - val_loss: 1089.8843\n",
      "Epoch 590/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1355.0959 - val_loss: 1102.0370\n",
      "Epoch 591/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1352.8627 - val_loss: 1086.3796\n",
      "Epoch 592/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1353.3495 - val_loss: 1090.7546\n",
      "Epoch 593/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1352.8131 - val_loss: 1089.9390\n",
      "Epoch 594/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1355.4188 - val_loss: 1093.4270\n",
      "Epoch 595/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1354.1957 - val_loss: 1086.2883\n",
      "Epoch 596/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1353.1053 - val_loss: 1095.5729\n",
      "Epoch 597/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1356.7752 - val_loss: 1092.9026\n",
      "Epoch 598/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1354.6188 - val_loss: 1084.2448\n",
      "Epoch 599/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1351.1080 - val_loss: 1094.0845\n",
      "Epoch 600/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1341.4987 - val_loss: 1088.6648\n",
      "Epoch 601/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1347.8277 - val_loss: 1088.4321\n",
      "Epoch 602/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1340.1850 - val_loss: 1095.5270\n",
      "Epoch 603/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1351.9811 - val_loss: 1088.2362\n",
      "Epoch 604/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1358.3418 - val_loss: 1084.0399\n",
      "Epoch 605/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1346.1209 - val_loss: 1097.7653\n",
      "Epoch 606/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1359.4116 - val_loss: 1088.7495\n",
      "Epoch 607/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1344.0493 - val_loss: 1085.1349\n",
      "Epoch 608/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1341.7133 - val_loss: 1094.5350\n",
      "Epoch 609/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1351.4019 - val_loss: 1086.9764\n",
      "Epoch 610/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1359.2855 - val_loss: 1084.4124\n",
      "Epoch 611/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1355.8460 - val_loss: 1089.3512\n",
      "Epoch 612/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1347.9639 - val_loss: 1092.1158\n",
      "Epoch 613/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1347.9336 - val_loss: 1089.1987\n",
      "Epoch 614/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1353.3869 - val_loss: 1083.2855\n",
      "Epoch 615/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1343.4092 - val_loss: 1088.3228\n",
      "Epoch 616/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1342.3439 - val_loss: 1090.2927\n",
      "Epoch 617/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1358.9072 - val_loss: 1085.3932\n",
      "Epoch 618/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.4947 - val_loss: 1088.9449\n",
      "Epoch 619/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1349.6246 - val_loss: 1087.7151\n",
      "Epoch 620/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1353.3276 - val_loss: 1084.0546\n",
      "Epoch 621/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1349.6569 - val_loss: 1086.4944\n",
      "Epoch 622/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1338.2772 - val_loss: 1082.2057\n",
      "Epoch 623/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1349.6179 - val_loss: 1095.8223\n",
      "Epoch 624/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1345.9691 - val_loss: 1083.9128\n",
      "Epoch 625/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1343.1671 - val_loss: 1084.1290\n",
      "Epoch 626/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1346.5744 - val_loss: 1089.6176\n",
      "Epoch 627/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1343.4983 - val_loss: 1081.4105\n",
      "Epoch 628/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1336.2463 - val_loss: 1090.9976\n",
      "Epoch 629/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1341.0883 - val_loss: 1084.5400\n",
      "Epoch 630/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.7639 - val_loss: 1084.0811\n",
      "Epoch 631/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1342.4077 - val_loss: 1084.2438\n",
      "Epoch 632/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1354.8473 - val_loss: 1088.9192\n",
      "Epoch 633/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1348.2421 - val_loss: 1082.1611\n",
      "Epoch 634/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1355.3237 - val_loss: 1085.3226\n",
      "Epoch 635/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1343.1386 - val_loss: 1083.6975\n",
      "Epoch 636/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1344.6936 - val_loss: 1082.2349\n",
      "Epoch 637/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1349.8500 - val_loss: 1081.6478\n",
      "Epoch 638/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1343.9111 - val_loss: 1089.7042\n",
      "Epoch 639/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1350.3001 - val_loss: 1086.3870\n",
      "Epoch 640/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.9162 - val_loss: 1083.0477\n",
      "Epoch 641/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1345.7256 - val_loss: 1086.3945\n",
      "Epoch 642/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1337.0949 - val_loss: 1081.4246\n",
      "Epoch 643/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1338.8541 - val_loss: 1080.8693\n",
      "Epoch 644/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.2506 - val_loss: 1085.8612\n",
      "Epoch 645/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1340.9649 - val_loss: 1084.6356\n",
      "Epoch 646/3000\n",
      "36515/36515 [==============================] - 1s 21us/sample - loss: 1336.8314 - val_loss: 1080.0837\n",
      "Epoch 647/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1340.5559 - val_loss: 1098.2939\n",
      "Epoch 648/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1345.1354 - val_loss: 1080.8348\n",
      "Epoch 649/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.7570 - val_loss: 1080.6925\n",
      "Epoch 650/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1336.9501 - val_loss: 1091.3573\n",
      "Epoch 651/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1336.7659 - val_loss: 1081.7966\n",
      "Epoch 652/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1330.3677 - val_loss: 1081.1842\n",
      "Epoch 653/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1346.4442 - val_loss: 1086.8048\n",
      "Epoch 654/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1339.3272 - val_loss: 1083.3389\n",
      "Epoch 655/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1347.3805 - val_loss: 1079.5391\n",
      "Epoch 656/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1328.8025 - val_loss: 1086.9630\n",
      "Epoch 657/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1340.2459 - val_loss: 1081.1141\n",
      "Epoch 658/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1338.9045 - val_loss: 1078.3301\n",
      "Epoch 659/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1337.2622 - val_loss: 1083.2345\n",
      "Epoch 660/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1337.1855 - val_loss: 1087.8496\n",
      "Epoch 661/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1330.4623 - val_loss: 1076.9922\n",
      "Epoch 662/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1342.8391 - val_loss: 1079.5431\n",
      "Epoch 663/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1336.8998 - val_loss: 1081.2201\n",
      "Epoch 664/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1335.0566 - val_loss: 1080.7383\n",
      "Epoch 665/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1334.2844 - val_loss: 1077.5616\n",
      "Epoch 666/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1343.6345 - val_loss: 1084.2202\n",
      "Epoch 667/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.2309 - val_loss: 1079.6206\n",
      "Epoch 668/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1332.0451 - val_loss: 1076.6117\n",
      "Epoch 669/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1340.8648 - val_loss: 1077.3210\n",
      "Epoch 670/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1341.1826 - val_loss: 1090.8821\n",
      "Epoch 671/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1336.5734 - val_loss: 1078.0721\n",
      "Epoch 672/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1344.7272 - val_loss: 1078.0146\n",
      "Epoch 673/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1342.5999 - val_loss: 1082.8058\n",
      "Epoch 674/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1334.2450 - val_loss: 1079.4485\n",
      "Epoch 675/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1332.5810 - val_loss: 1073.9503\n",
      "Epoch 676/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1331.2063 - val_loss: 1080.9712\n",
      "Epoch 677/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1335.1364 - val_loss: 1086.7607\n",
      "Epoch 678/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1334.6395 - val_loss: 1078.6104\n",
      "Epoch 679/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1325.3408 - val_loss: 1076.0923\n",
      "Epoch 680/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1333.5013 - val_loss: 1084.3281\n",
      "Epoch 681/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1332.0789 - val_loss: 1078.6241\n",
      "Epoch 682/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1331.2975 - val_loss: 1077.7212\n",
      "Epoch 683/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1330.1711 - val_loss: 1090.4061\n",
      "Epoch 684/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1341.2488 - val_loss: 1077.0824\n",
      "Epoch 685/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1336.3127 - val_loss: 1073.1666\n",
      "Epoch 686/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1336.7105 - val_loss: 1089.7473\n",
      "Epoch 687/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1335.5958 - val_loss: 1079.4263\n",
      "Epoch 688/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1332.8086 - val_loss: 1074.0117\n",
      "Epoch 689/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1325.1103 - val_loss: 1079.3486\n",
      "Epoch 690/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.1478 - val_loss: 1081.5132\n",
      "Epoch 691/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.2363 - val_loss: 1081.4471\n",
      "Epoch 692/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1328.4944 - val_loss: 1073.2236\n",
      "Epoch 693/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1332.3832 - val_loss: 1077.7834\n",
      "Epoch 694/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1333.6570 - val_loss: 1081.4890\n",
      "Epoch 695/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1338.0392 - val_loss: 1081.8210\n",
      "Epoch 696/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1327.0357 - val_loss: 1072.9329\n",
      "Epoch 697/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1339.4971 - val_loss: 1083.3593\n",
      "Epoch 698/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1331.2627 - val_loss: 1078.3915\n",
      "Epoch 699/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1323.2609 - val_loss: 1072.8945\n",
      "Epoch 700/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1340.5364 - val_loss: 1078.7139\n",
      "Epoch 701/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1322.7806 - val_loss: 1075.4160\n",
      "Epoch 702/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1330.5217 - val_loss: 1076.6345\n",
      "Epoch 703/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.9605 - val_loss: 1078.3002\n",
      "Epoch 704/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1328.1742 - val_loss: 1074.6924\n",
      "Epoch 705/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1331.5175 - val_loss: 1081.3204\n",
      "Epoch 706/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.0379 - val_loss: 1078.3876\n",
      "Epoch 707/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1338.7630 - val_loss: 1071.5731\n",
      "Epoch 708/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1335.4174 - val_loss: 1081.5302\n",
      "Epoch 709/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1328.9662 - val_loss: 1077.3846\n",
      "Epoch 710/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1334.1861 - val_loss: 1072.8187\n",
      "Epoch 711/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1334.5414 - val_loss: 1079.0996\n",
      "Epoch 712/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1325.7885 - val_loss: 1074.4165\n",
      "Epoch 713/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1325.9857 - val_loss: 1079.3236\n",
      "Epoch 714/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.3201 - val_loss: 1072.1072\n",
      "Epoch 715/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1336.0959 - val_loss: 1073.8574\n",
      "Epoch 716/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1332.6482 - val_loss: 1079.0984\n",
      "Epoch 717/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.1152 - val_loss: 1073.4329\n",
      "Epoch 718/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1331.4775 - val_loss: 1080.3120\n",
      "Epoch 719/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1321.0275 - val_loss: 1071.7739\n",
      "Epoch 720/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.0303 - val_loss: 1074.4629\n",
      "Epoch 721/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.7621 - val_loss: 1073.3069\n",
      "Epoch 722/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1328.0421 - val_loss: 1071.7629\n",
      "Epoch 723/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1330.3044 - val_loss: 1081.4458\n",
      "Epoch 724/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1333.4944 - val_loss: 1073.7119\n",
      "Epoch 725/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1328.3888 - val_loss: 1070.9321\n",
      "Epoch 726/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1325.9366 - val_loss: 1074.3682\n",
      "Epoch 727/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1340.4991 - val_loss: 1079.3088\n",
      "Epoch 728/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1329.1543 - val_loss: 1070.1848\n",
      "Epoch 729/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1333.4203 - val_loss: 1073.9935\n",
      "Epoch 730/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1328.0399 - val_loss: 1079.7546\n",
      "Epoch 731/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1330.9025 - val_loss: 1073.8549\n",
      "Epoch 732/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1321.8306 - val_loss: 1069.5917\n",
      "Epoch 733/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1321.8748 - val_loss: 1081.1001\n",
      "Epoch 734/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1325.1718 - val_loss: 1076.6991\n",
      "Epoch 735/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1323.7060 - val_loss: 1071.7236\n",
      "Epoch 736/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1326.6745 - val_loss: 1081.0100\n",
      "Epoch 737/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1330.4393 - val_loss: 1077.0979\n",
      "Epoch 738/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1326.5394 - val_loss: 1067.6636\n",
      "Epoch 739/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1332.4354 - val_loss: 1067.6656\n",
      "Epoch 740/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1323.1153 - val_loss: 1083.4497\n",
      "Epoch 741/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1340.2982 - val_loss: 1076.6196\n",
      "Epoch 742/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1335.8543 - val_loss: 1068.9420\n",
      "Epoch 743/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.2299 - val_loss: 1073.4623\n",
      "Epoch 744/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1336.4268 - val_loss: 1070.3552\n",
      "Epoch 745/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1317.3737 - val_loss: 1081.4104\n",
      "Epoch 746/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1318.1893 - val_loss: 1065.8101\n",
      "Epoch 747/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1321.1553 - val_loss: 1073.1577\n",
      "Epoch 748/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.2685 - val_loss: 1087.6703\n",
      "Epoch 749/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1327.8061 - val_loss: 1069.2462\n",
      "Epoch 750/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1325.9704 - val_loss: 1072.5764\n",
      "Epoch 751/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1327.2626 - val_loss: 1073.8269\n",
      "Epoch 752/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1321.6330 - val_loss: 1069.8778\n",
      "Epoch 753/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1315.7806 - val_loss: 1067.9567\n",
      "Epoch 754/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.0587 - val_loss: 1076.3792\n",
      "Epoch 755/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1317.6351 - val_loss: 1074.7065\n",
      "Epoch 756/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1320.6250 - val_loss: 1071.2223\n",
      "Epoch 757/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1320.8638 - val_loss: 1068.2905\n",
      "Epoch 758/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1311.1153 - val_loss: 1074.3870\n",
      "Epoch 759/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1323.1111 - val_loss: 1071.8427\n",
      "Epoch 760/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1309.0392 - val_loss: 1065.2407\n",
      "Epoch 761/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1326.2244 - val_loss: 1081.5436\n",
      "Epoch 762/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.3762 - val_loss: 1066.9569\n",
      "Epoch 763/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1326.0303 - val_loss: 1065.8517\n",
      "Epoch 764/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1331.9071 - val_loss: 1079.9020\n",
      "Epoch 765/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.4194 - val_loss: 1073.5432\n",
      "Epoch 766/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.6622 - val_loss: 1066.6635\n",
      "Epoch 767/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1320.8816 - val_loss: 1080.0380\n",
      "Epoch 768/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1323.2247 - val_loss: 1076.5338\n",
      "Epoch 769/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1327.4815 - val_loss: 1063.9858\n",
      "Epoch 770/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1321.0285 - val_loss: 1077.6000\n",
      "Epoch 771/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1323.9336 - val_loss: 1076.0995\n",
      "Epoch 772/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.6640 - val_loss: 1066.5876\n",
      "Epoch 773/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.2562 - val_loss: 1066.3704\n",
      "Epoch 774/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1315.2876 - val_loss: 1072.7212\n",
      "Epoch 775/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1315.1848 - val_loss: 1067.1111\n",
      "Epoch 776/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1312.8596 - val_loss: 1067.2335\n",
      "Epoch 777/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.9254 - val_loss: 1077.1395\n",
      "Epoch 778/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1317.8713 - val_loss: 1070.0853\n",
      "Epoch 779/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1312.8707 - val_loss: 1065.1011\n",
      "Epoch 780/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.9783 - val_loss: 1076.3182\n",
      "Epoch 781/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.6262 - val_loss: 1068.9513\n",
      "Epoch 782/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.9327 - val_loss: 1065.5310\n",
      "Epoch 783/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.1214 - val_loss: 1083.7495\n",
      "Epoch 784/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.4240 - val_loss: 1064.5083\n",
      "Epoch 785/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1314.4709 - val_loss: 1064.3545\n",
      "Epoch 786/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1314.1656 - val_loss: 1077.3499\n",
      "Epoch 787/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1320.5397 - val_loss: 1066.7573\n",
      "Epoch 788/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1320.6802 - val_loss: 1064.0282\n",
      "Epoch 789/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.9641 - val_loss: 1071.2725\n",
      "Epoch 790/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1315.7950 - val_loss: 1074.9912\n",
      "Epoch 791/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1323.5883 - val_loss: 1065.6591\n",
      "Epoch 792/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1321.2007 - val_loss: 1068.2366\n",
      "Epoch 793/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1326.6991 - val_loss: 1064.8994\n",
      "Epoch 794/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.0688 - val_loss: 1066.1578\n",
      "Epoch 795/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1314.3001 - val_loss: 1064.0280\n",
      "Epoch 796/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1327.0541 - val_loss: 1068.3230\n",
      "Epoch 797/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.4167 - val_loss: 1077.4423\n",
      "Epoch 798/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.1296 - val_loss: 1067.5353\n",
      "Epoch 799/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1317.7284 - val_loss: 1065.6746\n",
      "Epoch 800/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.5463 - val_loss: 1071.0222\n",
      "Epoch 801/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.9166 - val_loss: 1067.9626\n",
      "Epoch 802/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1304.3158 - val_loss: 1062.3717\n",
      "Epoch 803/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1321.6881 - val_loss: 1072.4576\n",
      "Epoch 804/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1320.9324 - val_loss: 1076.5087\n",
      "Epoch 805/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1317.5329 - val_loss: 1065.3362\n",
      "Epoch 806/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1320.7147 - val_loss: 1062.5825\n",
      "Epoch 807/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1312.9448 - val_loss: 1082.6791\n",
      "Epoch 808/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.5424 - val_loss: 1066.7273\n",
      "Epoch 809/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1315.7056 - val_loss: 1063.3063\n",
      "Epoch 810/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.4022 - val_loss: 1074.5026\n",
      "Epoch 811/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.6237 - val_loss: 1064.3024\n",
      "Epoch 812/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1312.4210 - val_loss: 1064.6278\n",
      "Epoch 813/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.3996 - val_loss: 1069.2899\n",
      "Epoch 814/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1314.8572 - val_loss: 1065.4388\n",
      "Epoch 815/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.3876 - val_loss: 1072.5974\n",
      "Epoch 816/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1307.4759 - val_loss: 1061.7128\n",
      "Epoch 817/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1314.2497 - val_loss: 1064.4655\n",
      "Epoch 818/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.1436 - val_loss: 1074.0597\n",
      "Epoch 819/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.4675 - val_loss: 1068.0353\n",
      "Epoch 820/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.0575 - val_loss: 1062.9141\n",
      "Epoch 821/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1315.7086 - val_loss: 1066.0995\n",
      "Epoch 822/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1322.7773 - val_loss: 1071.4175\n",
      "Epoch 823/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1312.4779 - val_loss: 1059.6492\n",
      "Epoch 824/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1314.2622 - val_loss: 1060.2130\n",
      "Epoch 825/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1315.9394 - val_loss: 1083.6443\n",
      "Epoch 826/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1310.1837 - val_loss: 1061.7317\n",
      "Epoch 827/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.8537 - val_loss: 1059.9180\n",
      "Epoch 828/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.2294 - val_loss: 1071.0919\n",
      "Epoch 829/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1321.6914 - val_loss: 1067.0071\n",
      "Epoch 830/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1309.6746 - val_loss: 1059.9530\n",
      "Epoch 831/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.7036 - val_loss: 1067.3375\n",
      "Epoch 832/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1309.3515 - val_loss: 1068.2948\n",
      "Epoch 833/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.0916 - val_loss: 1060.0447\n",
      "Epoch 834/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1324.3303 - val_loss: 1064.5004\n",
      "Epoch 835/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1307.1502 - val_loss: 1070.4237\n",
      "Epoch 836/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1303.7939 - val_loss: 1060.9337\n",
      "Epoch 837/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1312.2695 - val_loss: 1061.7361\n",
      "Epoch 838/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1311.0016 - val_loss: 1068.5593\n",
      "Epoch 839/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.8930 - val_loss: 1062.5240\n",
      "Epoch 840/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1309.5041 - val_loss: 1068.9847\n",
      "Epoch 841/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1309.4701 - val_loss: 1065.2732\n",
      "Epoch 842/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1305.8049 - val_loss: 1063.5123\n",
      "Epoch 843/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.7033 - val_loss: 1072.9995\n",
      "Epoch 844/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.4776 - val_loss: 1062.0247\n",
      "Epoch 845/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.6792 - val_loss: 1060.5179\n",
      "Epoch 846/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.4586 - val_loss: 1065.6238\n",
      "Epoch 847/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.8062 - val_loss: 1063.7201\n",
      "Epoch 848/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1319.7013 - val_loss: 1068.2871\n",
      "Epoch 849/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1309.7345 - val_loss: 1058.7157\n",
      "Epoch 850/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1315.7846 - val_loss: 1067.7004\n",
      "Epoch 851/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.9214 - val_loss: 1067.7224\n",
      "Epoch 852/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1312.2586 - val_loss: 1059.1154\n",
      "Epoch 853/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.8074 - val_loss: 1071.2867\n",
      "Epoch 854/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.0052 - val_loss: 1059.9409\n",
      "Epoch 855/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1309.3025 - val_loss: 1061.4811\n",
      "Epoch 856/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.3899 - val_loss: 1062.2562\n",
      "Epoch 857/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1310.3179 - val_loss: 1060.5856\n",
      "Epoch 858/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1310.0865 - val_loss: 1062.8296\n",
      "Epoch 859/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.1648 - val_loss: 1063.1888\n",
      "Epoch 860/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1307.2718 - val_loss: 1058.1504\n",
      "Epoch 861/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1299.6637 - val_loss: 1067.4520\n",
      "Epoch 862/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1317.2603 - val_loss: 1066.8976\n",
      "Epoch 863/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.3164 - val_loss: 1060.8151\n",
      "Epoch 864/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1307.8195 - val_loss: 1058.8781\n",
      "Epoch 865/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1305.1327 - val_loss: 1065.5391\n",
      "Epoch 866/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.4227 - val_loss: 1063.7523\n",
      "Epoch 867/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.1123 - val_loss: 1060.1709\n",
      "Epoch 868/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1303.3823 - val_loss: 1065.1119\n",
      "Epoch 869/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1301.6651 - val_loss: 1064.1229\n",
      "Epoch 870/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1314.6993 - val_loss: 1057.4342\n",
      "Epoch 871/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1308.7231 - val_loss: 1066.8663\n",
      "Epoch 872/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.3792 - val_loss: 1060.5453\n",
      "Epoch 873/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1303.2104 - val_loss: 1059.1167\n",
      "Epoch 874/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.6244 - val_loss: 1067.6018\n",
      "Epoch 875/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1298.8630 - val_loss: 1061.8888\n",
      "Epoch 876/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1298.0857 - val_loss: 1057.6517\n",
      "Epoch 877/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1309.6344 - val_loss: 1067.4854\n",
      "Epoch 878/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1299.0676 - val_loss: 1058.9097\n",
      "Epoch 879/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.9284 - val_loss: 1059.8757\n",
      "Epoch 880/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1311.4772 - val_loss: 1064.2360\n",
      "Epoch 881/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.8485 - val_loss: 1057.8717\n",
      "Epoch 882/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.2947 - val_loss: 1066.8754\n",
      "Epoch 883/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.0055 - val_loss: 1058.8893\n",
      "Epoch 884/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1305.6200 - val_loss: 1062.1932\n",
      "Epoch 885/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1312.3148 - val_loss: 1060.0657\n",
      "Epoch 886/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1302.1942 - val_loss: 1078.3131\n",
      "Epoch 887/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1310.1865 - val_loss: 1067.5563\n",
      "Epoch 888/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.4074 - val_loss: 1057.4413\n",
      "Epoch 889/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1305.0297 - val_loss: 1066.2637\n",
      "Epoch 890/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1298.1857 - val_loss: 1065.5057\n",
      "Epoch 891/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1307.4521 - val_loss: 1055.4025\n",
      "Epoch 892/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1302.5307 - val_loss: 1059.7761\n",
      "Epoch 893/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1309.3908 - val_loss: 1073.3203\n",
      "Epoch 894/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.6791 - val_loss: 1056.2863\n",
      "Epoch 895/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1311.0257 - val_loss: 1056.4242\n",
      "Epoch 896/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1318.8051 - val_loss: 1075.6229\n",
      "Epoch 897/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1317.1940 - val_loss: 1062.1925\n",
      "Epoch 898/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.7376 - val_loss: 1056.5667\n",
      "Epoch 899/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.0939 - val_loss: 1066.5118\n",
      "Epoch 900/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.7110 - val_loss: 1065.1241\n",
      "Epoch 901/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1295.9330 - val_loss: 1059.4437\n",
      "Epoch 902/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.0573 - val_loss: 1060.8766\n",
      "Epoch 903/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1310.2255 - val_loss: 1060.1222\n",
      "Epoch 904/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.8083 - val_loss: 1056.7795\n",
      "Epoch 905/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1294.5890 - val_loss: 1061.0172\n",
      "Epoch 906/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1311.2233 - val_loss: 1066.9105\n",
      "Epoch 907/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1297.3537 - val_loss: 1057.3562\n",
      "Epoch 908/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1301.7178 - val_loss: 1056.7426\n",
      "Epoch 909/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.9087 - val_loss: 1064.2861\n",
      "Epoch 910/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1295.7023 - val_loss: 1056.4713\n",
      "Epoch 911/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1316.6423 - val_loss: 1062.4891\n",
      "Epoch 912/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.4906 - val_loss: 1061.3361\n",
      "Epoch 913/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1305.9919 - val_loss: 1058.5341\n",
      "Epoch 914/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.6335 - val_loss: 1059.9226\n",
      "Epoch 915/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1310.1933 - val_loss: 1057.9507\n",
      "Epoch 916/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.6251 - val_loss: 1059.5970\n",
      "Epoch 917/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1299.4434 - val_loss: 1065.1729\n",
      "Epoch 918/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1298.6960 - val_loss: 1056.8815\n",
      "Epoch 919/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1302.2543 - val_loss: 1058.8722\n",
      "Epoch 920/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1294.6106 - val_loss: 1065.7767\n",
      "Epoch 921/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.3557 - val_loss: 1057.8597\n",
      "Epoch 922/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.2886 - val_loss: 1060.4100\n",
      "Epoch 923/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1303.5009 - val_loss: 1060.7843\n",
      "Epoch 924/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1302.1473 - val_loss: 1056.6527\n",
      "Epoch 925/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.2352 - val_loss: 1058.4159\n",
      "Epoch 926/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1298.3422 - val_loss: 1060.6965\n",
      "Epoch 927/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.3907 - val_loss: 1063.8412\n",
      "Epoch 928/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1301.4060 - val_loss: 1055.9849\n",
      "Epoch 929/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.9630 - val_loss: 1063.5332\n",
      "Epoch 930/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1292.1957 - val_loss: 1063.7401\n",
      "Epoch 931/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.6137 - val_loss: 1056.0424\n",
      "Epoch 932/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1295.9010 - val_loss: 1055.7584\n",
      "Epoch 933/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1306.9930 - val_loss: 1070.0985\n",
      "Epoch 934/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1299.2068 - val_loss: 1054.8242\n",
      "Epoch 935/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.9914 - val_loss: 1057.1689\n",
      "Epoch 936/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1299.8623 - val_loss: 1066.6892\n",
      "Epoch 937/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1297.5791 - val_loss: 1052.5269\n",
      "Epoch 938/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.5990 - val_loss: 1055.7570\n",
      "Epoch 939/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1302.9076 - val_loss: 1071.2554\n",
      "Epoch 940/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1297.4780 - val_loss: 1053.3905\n",
      "Epoch 941/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.1600 - val_loss: 1056.4364\n",
      "Epoch 942/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.5123 - val_loss: 1067.8373\n",
      "Epoch 943/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1300.0199 - val_loss: 1054.5421\n",
      "Epoch 944/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1313.2239 - val_loss: 1061.4338\n",
      "Epoch 945/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.6957 - val_loss: 1073.0591\n",
      "Epoch 946/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1295.2673 - val_loss: 1052.0205\n",
      "Epoch 947/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1303.8572 - val_loss: 1054.2651\n",
      "Epoch 948/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1294.9969 - val_loss: 1067.7247\n",
      "Epoch 949/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.3818 - val_loss: 1056.3778\n",
      "Epoch 950/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1302.0063 - val_loss: 1051.9727\n",
      "Epoch 951/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.4284 - val_loss: 1059.3214\n",
      "Epoch 952/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1294.1816 - val_loss: 1056.5758\n",
      "Epoch 953/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1289.3422 - val_loss: 1055.2638\n",
      "Epoch 954/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1295.3104 - val_loss: 1060.5859\n",
      "Epoch 955/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1305.4295 - val_loss: 1054.9512\n",
      "Epoch 956/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1301.3743 - val_loss: 1059.8147\n",
      "Epoch 957/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1299.7356 - val_loss: 1056.0061\n",
      "Epoch 958/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1309.9539 - val_loss: 1056.7286\n",
      "Epoch 959/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1298.7886 - val_loss: 1054.1927\n",
      "Epoch 960/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1292.3988 - val_loss: 1054.9679\n",
      "Epoch 961/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1304.4353 - val_loss: 1060.7166\n",
      "Epoch 962/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.2224 - val_loss: 1053.9266\n",
      "Epoch 963/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1303.4961 - val_loss: 1053.0083\n",
      "Epoch 964/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.7381 - val_loss: 1056.1750\n",
      "Epoch 965/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1296.5610 - val_loss: 1051.9280\n",
      "Epoch 966/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.8042 - val_loss: 1056.5676\n",
      "Epoch 967/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.3194 - val_loss: 1052.7964\n",
      "Epoch 968/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.5140 - val_loss: 1064.2665\n",
      "Epoch 969/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.7341 - val_loss: 1056.6478\n",
      "Epoch 970/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.3588 - val_loss: 1053.3840\n",
      "Epoch 971/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.9779 - val_loss: 1062.8206\n",
      "Epoch 972/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1286.7370 - val_loss: 1060.9094\n",
      "Epoch 973/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1297.0407 - val_loss: 1052.4619\n",
      "Epoch 974/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1295.3887 - val_loss: 1057.7281\n",
      "Epoch 975/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.4547 - val_loss: 1052.9846\n",
      "Epoch 976/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1298.0105 - val_loss: 1050.7090\n",
      "Epoch 977/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1300.8754 - val_loss: 1062.4427\n",
      "Epoch 978/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1294.1838 - val_loss: 1059.7764\n",
      "Epoch 979/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.2940 - val_loss: 1052.4708\n",
      "Epoch 980/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1303.2157 - val_loss: 1051.4646\n",
      "Epoch 981/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.9305 - val_loss: 1065.5413\n",
      "Epoch 982/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.4500 - val_loss: 1051.7144\n",
      "Epoch 983/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.5767 - val_loss: 1051.1443\n",
      "Epoch 984/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1294.7493 - val_loss: 1059.8950\n",
      "Epoch 985/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1289.4557 - val_loss: 1054.0964\n",
      "Epoch 986/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1294.4736 - val_loss: 1053.7659\n",
      "Epoch 987/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.3210 - val_loss: 1050.8888\n",
      "Epoch 988/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.5292 - val_loss: 1061.3811\n",
      "Epoch 989/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.3560 - val_loss: 1051.6255\n",
      "Epoch 990/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1291.2487 - val_loss: 1049.7777\n",
      "Epoch 991/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.0620 - val_loss: 1062.4729\n",
      "Epoch 992/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1295.8774 - val_loss: 1052.9994\n",
      "Epoch 993/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1299.2434 - val_loss: 1051.5852\n",
      "Epoch 994/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.6433 - val_loss: 1057.2209\n",
      "Epoch 995/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1285.0105 - val_loss: 1051.0818\n",
      "Epoch 996/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1302.5611 - val_loss: 1050.6630\n",
      "Epoch 997/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1295.6898 - val_loss: 1056.9716\n",
      "Epoch 998/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1288.0691 - val_loss: 1049.3177\n",
      "Epoch 999/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1289.1060 - val_loss: 1054.9052\n",
      "Epoch 1000/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.4312 - val_loss: 1056.9467\n",
      "Epoch 1001/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1285.7891 - val_loss: 1050.2938\n",
      "Epoch 1002/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.9806 - val_loss: 1056.5809\n",
      "Epoch 1003/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.6814 - val_loss: 1057.4338\n",
      "Epoch 1004/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.2003 - val_loss: 1050.1284\n",
      "Epoch 1005/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1296.1415 - val_loss: 1049.5375\n",
      "Epoch 1006/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.2855 - val_loss: 1066.1929\n",
      "Epoch 1007/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1282.6131 - val_loss: 1053.6371\n",
      "Epoch 1008/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1293.2413 - val_loss: 1049.1354\n",
      "Epoch 1009/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1291.5963 - val_loss: 1056.7091\n",
      "Epoch 1010/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.1220 - val_loss: 1060.8740\n",
      "Epoch 1011/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.8871 - val_loss: 1058.2482\n",
      "Epoch 1012/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1298.4179 - val_loss: 1047.1556\n",
      "Epoch 1013/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1291.1995 - val_loss: 1052.7371\n",
      "Epoch 1014/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1287.0922 - val_loss: 1058.8115\n",
      "Epoch 1015/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1286.6928 - val_loss: 1051.1660\n",
      "Epoch 1016/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1280.0662 - val_loss: 1054.2150\n",
      "Epoch 1017/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1298.6444 - val_loss: 1056.7009\n",
      "Epoch 1018/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.1504 - val_loss: 1050.5963\n",
      "Epoch 1019/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1291.5339 - val_loss: 1053.0946\n",
      "Epoch 1020/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1285.6170 - val_loss: 1052.2344\n",
      "Epoch 1021/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1289.8270 - val_loss: 1050.8022\n",
      "Epoch 1022/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.7764 - val_loss: 1054.9563\n",
      "Epoch 1023/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.5619 - val_loss: 1051.0244\n",
      "Epoch 1024/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.7828 - val_loss: 1048.0122\n",
      "Epoch 1025/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.0632 - val_loss: 1049.8276\n",
      "Epoch 1026/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1286.7028 - val_loss: 1047.9968\n",
      "Epoch 1027/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.5467 - val_loss: 1052.5963\n",
      "Epoch 1028/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1283.5660 - val_loss: 1049.8195\n",
      "Epoch 1029/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1281.9424 - val_loss: 1047.0646\n",
      "Epoch 1030/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1279.2337 - val_loss: 1052.9977\n",
      "Epoch 1031/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1283.2531 - val_loss: 1051.7520\n",
      "Epoch 1032/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.6321 - val_loss: 1055.6300\n",
      "Epoch 1033/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1279.0018 - val_loss: 1045.2341\n",
      "Epoch 1034/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.7020 - val_loss: 1051.7310\n",
      "Epoch 1035/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1285.7686 - val_loss: 1062.9445\n",
      "Epoch 1036/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1292.1999 - val_loss: 1048.1345\n",
      "Epoch 1037/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1280.6732 - val_loss: 1047.3799\n",
      "Epoch 1038/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.2910 - val_loss: 1055.1875\n",
      "Epoch 1039/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.4764 - val_loss: 1058.0376\n",
      "Epoch 1040/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1287.2444 - val_loss: 1055.2360\n",
      "Epoch 1041/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1279.9522 - val_loss: 1046.2389\n",
      "Epoch 1042/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.6406 - val_loss: 1046.9873\n",
      "Epoch 1043/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1280.4680 - val_loss: 1052.0376\n",
      "Epoch 1044/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1293.9270 - val_loss: 1055.2637\n",
      "Epoch 1045/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1282.6425 - val_loss: 1051.7919\n",
      "Epoch 1046/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1282.6399 - val_loss: 1045.8186\n",
      "Epoch 1047/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.4605 - val_loss: 1056.0085\n",
      "Epoch 1048/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.4502 - val_loss: 1057.8459\n",
      "Epoch 1049/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.8047 - val_loss: 1046.0708\n",
      "Epoch 1050/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1299.8762 - val_loss: 1045.5883\n",
      "Epoch 1051/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.3325 - val_loss: 1064.1956\n",
      "Epoch 1052/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1279.8666 - val_loss: 1046.0052\n",
      "Epoch 1053/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1283.8826 - val_loss: 1044.9351\n",
      "Epoch 1054/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1289.2403 - val_loss: 1056.5720\n",
      "Epoch 1055/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.8008 - val_loss: 1048.3695\n",
      "Epoch 1056/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1276.7261 - val_loss: 1045.5815\n",
      "Epoch 1057/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.9088 - val_loss: 1058.9739\n",
      "Epoch 1058/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1289.7915 - val_loss: 1048.1376\n",
      "Epoch 1059/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1277.4015 - val_loss: 1044.9011\n",
      "Epoch 1060/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1279.6803 - val_loss: 1047.9476\n",
      "Epoch 1061/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1279.7065 - val_loss: 1053.3544\n",
      "Epoch 1062/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1279.5480 - val_loss: 1047.7169\n",
      "Epoch 1063/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1282.2912 - val_loss: 1047.0500\n",
      "Epoch 1064/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1283.9347 - val_loss: 1048.1127\n",
      "Epoch 1065/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1289.3117 - val_loss: 1061.6681\n",
      "Epoch 1066/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1283.5839 - val_loss: 1044.3196\n",
      "Epoch 1067/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1290.1049 - val_loss: 1046.2366\n",
      "Epoch 1068/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1280.9315 - val_loss: 1055.1187\n",
      "Epoch 1069/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1284.1852 - val_loss: 1046.4347\n",
      "Epoch 1070/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.8825 - val_loss: 1045.1268\n",
      "Epoch 1071/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1278.2151 - val_loss: 1048.1368\n",
      "Epoch 1072/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1276.1200 - val_loss: 1050.0156\n",
      "Epoch 1073/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1277.0417 - val_loss: 1049.0565\n",
      "Epoch 1074/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1290.4442 - val_loss: 1046.9812\n",
      "Epoch 1075/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.4275 - val_loss: 1044.8496\n",
      "Epoch 1076/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.0818 - val_loss: 1047.9637\n",
      "Epoch 1077/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1285.4055 - val_loss: 1051.7623\n",
      "Epoch 1078/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1277.4627 - val_loss: 1043.6190\n",
      "Epoch 1079/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1278.9284 - val_loss: 1046.6289\n",
      "Epoch 1080/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.1225 - val_loss: 1060.8245\n",
      "Epoch 1081/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1284.7938 - val_loss: 1050.1443\n",
      "Epoch 1082/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1284.7467 - val_loss: 1044.5193\n",
      "Epoch 1083/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1283.8610 - val_loss: 1051.9180\n",
      "Epoch 1084/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.2537 - val_loss: 1051.3058\n",
      "Epoch 1085/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1283.2568 - val_loss: 1043.7593\n",
      "Epoch 1086/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1274.4536 - val_loss: 1044.0101\n",
      "Epoch 1087/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1273.9690 - val_loss: 1046.9766\n",
      "Epoch 1088/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1277.1780 - val_loss: 1051.5663\n",
      "Epoch 1089/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.3269 - val_loss: 1051.2576\n",
      "Epoch 1090/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1279.9136 - val_loss: 1043.6063\n",
      "Epoch 1091/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1277.7699 - val_loss: 1048.4257\n",
      "Epoch 1092/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1276.5077 - val_loss: 1046.1984\n",
      "Epoch 1093/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1280.4336 - val_loss: 1054.8008\n",
      "Epoch 1094/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1268.7573 - val_loss: 1043.2843\n",
      "Epoch 1095/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1281.8144 - val_loss: 1045.1189\n",
      "Epoch 1096/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1279.0433 - val_loss: 1047.6302\n",
      "Epoch 1097/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1281.5100 - val_loss: 1047.6104\n",
      "Epoch 1098/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1274.5267 - val_loss: 1044.0211\n",
      "Epoch 1099/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1266.0628 - val_loss: 1047.6683\n",
      "Epoch 1100/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1278.6756 - val_loss: 1053.2882\n",
      "Epoch 1101/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1274.0443 - val_loss: 1042.6677\n",
      "Epoch 1102/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1274.0564 - val_loss: 1043.9927\n",
      "Epoch 1103/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.3040 - val_loss: 1053.8165\n",
      "Epoch 1104/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1283.2819 - val_loss: 1050.4347\n",
      "Epoch 1105/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1269.7143 - val_loss: 1041.3375\n",
      "Epoch 1106/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1284.7595 - val_loss: 1041.8450\n",
      "Epoch 1107/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1287.7647 - val_loss: 1050.8811\n",
      "Epoch 1108/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1278.2946 - val_loss: 1056.4850\n",
      "Epoch 1109/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1285.4265 - val_loss: 1043.5494\n",
      "Epoch 1110/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1277.8818 - val_loss: 1040.8551\n",
      "Epoch 1111/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1278.3496 - val_loss: 1049.6956\n",
      "Epoch 1112/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.0871 - val_loss: 1046.1523\n",
      "Epoch 1113/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1276.6201 - val_loss: 1042.2223\n",
      "Epoch 1114/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1286.4329 - val_loss: 1047.8370\n",
      "Epoch 1115/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.1646 - val_loss: 1045.8690\n",
      "Epoch 1116/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1273.8102 - val_loss: 1040.4130\n",
      "Epoch 1117/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1288.4682 - val_loss: 1045.3184\n",
      "Epoch 1118/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1271.0861 - val_loss: 1044.6229\n",
      "Epoch 1119/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1259.5319 - val_loss: 1050.1880\n",
      "Epoch 1120/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1275.8472 - val_loss: 1050.1024\n",
      "Epoch 1121/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.5006 - val_loss: 1047.9280\n",
      "Epoch 1122/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1280.8999 - val_loss: 1042.7625\n",
      "Epoch 1123/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.0556 - val_loss: 1040.9585\n",
      "Epoch 1124/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.5293 - val_loss: 1045.5100\n",
      "Epoch 1125/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1261.3096 - val_loss: 1048.3958\n",
      "Epoch 1126/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.2730 - val_loss: 1042.4265\n",
      "Epoch 1127/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.7156 - val_loss: 1050.4135\n",
      "Epoch 1128/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1276.5836 - val_loss: 1044.9728\n",
      "Epoch 1129/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1274.3396 - val_loss: 1041.6328\n",
      "Epoch 1130/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1274.6690 - val_loss: 1043.9799\n",
      "Epoch 1131/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1275.6132 - val_loss: 1046.3818\n",
      "Epoch 1132/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1277.5548 - val_loss: 1050.1371\n",
      "Epoch 1133/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1273.1456 - val_loss: 1045.1573\n",
      "Epoch 1134/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1277.1679 - val_loss: 1042.7494\n",
      "Epoch 1135/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.4484 - val_loss: 1046.2162\n",
      "Epoch 1136/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1275.2429 - val_loss: 1041.5868\n",
      "Epoch 1137/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1275.6229 - val_loss: 1047.6342\n",
      "Epoch 1138/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1270.3032 - val_loss: 1042.8948\n",
      "Epoch 1139/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1271.6734 - val_loss: 1037.9973\n",
      "Epoch 1140/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1270.2822 - val_loss: 1053.5054\n",
      "Epoch 1141/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1273.3906 - val_loss: 1055.5848\n",
      "Epoch 1142/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1278.4433 - val_loss: 1038.6255\n",
      "Epoch 1143/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1264.7556 - val_loss: 1039.5375\n",
      "Epoch 1144/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1271.3749 - val_loss: 1049.1326\n",
      "Epoch 1145/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1260.3010 - val_loss: 1042.2850\n",
      "Epoch 1146/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1263.4089 - val_loss: 1037.8981\n",
      "Epoch 1147/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1270.9810 - val_loss: 1049.8588\n",
      "Epoch 1148/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1267.5879 - val_loss: 1050.3519\n",
      "Epoch 1149/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1269.5839 - val_loss: 1037.9280\n",
      "Epoch 1150/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1278.3634 - val_loss: 1038.2844\n",
      "Epoch 1151/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.6769 - val_loss: 1041.4478\n",
      "Epoch 1152/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1271.1409 - val_loss: 1049.6100\n",
      "Epoch 1153/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1274.0046 - val_loss: 1042.2979\n",
      "Epoch 1154/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1269.5005 - val_loss: 1037.9062\n",
      "Epoch 1155/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1268.2664 - val_loss: 1041.2786\n",
      "Epoch 1156/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.2931 - val_loss: 1038.6445\n",
      "Epoch 1157/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1253.9204 - val_loss: 1039.1860\n",
      "Epoch 1158/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1265.3206 - val_loss: 1042.2373\n",
      "Epoch 1159/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1264.1894 - val_loss: 1037.1615\n",
      "Epoch 1160/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1271.5839 - val_loss: 1042.2931\n",
      "Epoch 1161/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1271.3961 - val_loss: 1053.9868\n",
      "Epoch 1162/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.4356 - val_loss: 1037.8102\n",
      "Epoch 1163/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1269.3505 - val_loss: 1036.1335\n",
      "Epoch 1164/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1271.9266 - val_loss: 1058.7992\n",
      "Epoch 1165/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.2059 - val_loss: 1037.9194\n",
      "Epoch 1166/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1263.9887 - val_loss: 1035.5150\n",
      "Epoch 1167/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1283.0545 - val_loss: 1051.9094\n",
      "Epoch 1168/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1277.7281 - val_loss: 1059.2152\n",
      "Epoch 1169/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1265.1079 - val_loss: 1035.9792\n",
      "Epoch 1170/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1260.0105 - val_loss: 1041.2505\n",
      "Epoch 1171/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1268.5074 - val_loss: 1043.8660\n",
      "Epoch 1172/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1263.5638 - val_loss: 1038.8383\n",
      "Epoch 1173/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1263.7032 - val_loss: 1038.3823\n",
      "Epoch 1174/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1270.3205 - val_loss: 1042.1265\n",
      "Epoch 1175/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1258.1512 - val_loss: 1045.4530\n",
      "Epoch 1176/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1261.0201 - val_loss: 1040.2268\n",
      "Epoch 1177/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1262.1116 - val_loss: 1034.5332\n",
      "Epoch 1178/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1267.1347 - val_loss: 1044.4454\n",
      "Epoch 1179/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1266.7648 - val_loss: 1040.0077\n",
      "Epoch 1180/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1258.8423 - val_loss: 1035.0142\n",
      "Epoch 1181/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1272.6577 - val_loss: 1035.3308\n",
      "Epoch 1182/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1257.6619 - val_loss: 1041.2273\n",
      "Epoch 1183/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1280.4579 - val_loss: 1050.3945\n",
      "Epoch 1184/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1264.1381 - val_loss: 1034.1903\n",
      "Epoch 1185/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1261.4272 - val_loss: 1035.0306\n",
      "Epoch 1186/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1273.4924 - val_loss: 1039.6982\n",
      "Epoch 1187/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1259.7106 - val_loss: 1038.2670\n",
      "Epoch 1188/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1263.9283 - val_loss: 1034.3407\n",
      "Epoch 1189/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1264.4123 - val_loss: 1038.1475\n",
      "Epoch 1190/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1256.4855 - val_loss: 1057.5332\n",
      "Epoch 1191/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1264.2559 - val_loss: 1034.6063\n",
      "Epoch 1192/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1267.1214 - val_loss: 1035.8408\n",
      "Epoch 1193/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1258.1301 - val_loss: 1044.8115\n",
      "Epoch 1194/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1269.3664 - val_loss: 1039.0504\n",
      "Epoch 1195/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1268.3195 - val_loss: 1038.8009\n",
      "Epoch 1196/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1264.6713 - val_loss: 1035.1680\n",
      "Epoch 1197/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1255.8636 - val_loss: 1035.8673\n",
      "Epoch 1198/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1255.1073 - val_loss: 1042.9216\n",
      "Epoch 1199/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1258.5688 - val_loss: 1042.0653\n",
      "Epoch 1200/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1256.8824 - val_loss: 1034.2416\n",
      "Epoch 1201/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1250.7169 - val_loss: 1035.1320\n",
      "Epoch 1202/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1265.2208 - val_loss: 1039.0757\n",
      "Epoch 1203/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.8435 - val_loss: 1037.5623\n",
      "Epoch 1204/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1269.6843 - val_loss: 1040.3182\n",
      "Epoch 1205/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1253.9995 - val_loss: 1037.5292\n",
      "Epoch 1206/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1264.2208 - val_loss: 1034.9861\n",
      "Epoch 1207/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1267.5189 - val_loss: 1033.8986\n",
      "Epoch 1208/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1261.1969 - val_loss: 1033.3654\n",
      "Epoch 1209/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.4897 - val_loss: 1034.1766\n",
      "Epoch 1210/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1261.8038 - val_loss: 1039.8241\n",
      "Epoch 1211/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1263.4074 - val_loss: 1035.6781\n",
      "Epoch 1212/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1262.9598 - val_loss: 1041.2845\n",
      "Epoch 1213/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1249.9136 - val_loss: 1033.8687\n",
      "Epoch 1214/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1258.4958 - val_loss: 1031.1570\n",
      "Epoch 1215/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1259.9336 - val_loss: 1040.0151\n",
      "Epoch 1216/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1270.2539 - val_loss: 1042.9718\n",
      "Epoch 1217/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1263.6586 - val_loss: 1034.5752\n",
      "Epoch 1218/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1244.3086 - val_loss: 1033.8975\n",
      "Epoch 1219/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1246.1778 - val_loss: 1032.2094\n",
      "Epoch 1220/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1255.0918 - val_loss: 1044.4927\n",
      "Epoch 1221/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1261.4875 - val_loss: 1035.0699\n",
      "Epoch 1222/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1261.0344 - val_loss: 1031.1510\n",
      "Epoch 1223/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1259.8585 - val_loss: 1035.7698\n",
      "Epoch 1224/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1246.7375 - val_loss: 1045.7385\n",
      "Epoch 1225/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1262.0585 - val_loss: 1030.9281\n",
      "Epoch 1226/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1256.5286 - val_loss: 1029.2472\n",
      "Epoch 1227/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1262.4924 - val_loss: 1035.1818\n",
      "Epoch 1228/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1253.7743 - val_loss: 1059.9357\n",
      "Epoch 1229/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1263.9626 - val_loss: 1034.7299\n",
      "Epoch 1230/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1247.3924 - val_loss: 1029.5951\n",
      "Epoch 1231/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1266.3911 - val_loss: 1041.8218\n",
      "Epoch 1232/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1258.2246 - val_loss: 1050.5450\n",
      "Epoch 1233/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1261.5438 - val_loss: 1030.4172\n",
      "Epoch 1234/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.4518 - val_loss: 1032.1459\n",
      "Epoch 1235/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.1103 - val_loss: 1046.7590\n",
      "Epoch 1236/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1256.5640 - val_loss: 1029.7830\n",
      "Epoch 1237/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1254.0498 - val_loss: 1030.2960\n",
      "Epoch 1238/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1262.2895 - val_loss: 1030.9611\n",
      "Epoch 1239/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.6194 - val_loss: 1038.7933\n",
      "Epoch 1240/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1259.5477 - val_loss: 1031.1703\n",
      "Epoch 1241/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.6504 - val_loss: 1029.7461\n",
      "Epoch 1242/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1255.3015 - val_loss: 1036.8955\n",
      "Epoch 1243/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1254.4886 - val_loss: 1033.6215\n",
      "Epoch 1244/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1242.3264 - val_loss: 1029.0756\n",
      "Epoch 1245/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1255.6601 - val_loss: 1035.6643\n",
      "Epoch 1246/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1254.6465 - val_loss: 1038.4723\n",
      "Epoch 1247/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1243.7776 - val_loss: 1026.9375\n",
      "Epoch 1248/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1242.0536 - val_loss: 1030.0221\n",
      "Epoch 1249/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1251.2652 - val_loss: 1037.4315\n",
      "Epoch 1250/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1245.3402 - val_loss: 1027.6521\n",
      "Epoch 1251/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.8660 - val_loss: 1030.5480\n",
      "Epoch 1252/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1258.9644 - val_loss: 1037.4275\n",
      "Epoch 1253/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1240.1728 - val_loss: 1026.5116\n",
      "Epoch 1254/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1261.0423 - val_loss: 1027.3278\n",
      "Epoch 1255/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1251.1973 - val_loss: 1038.7451\n",
      "Epoch 1256/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1251.1215 - val_loss: 1027.5142\n",
      "Epoch 1257/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1246.4259 - val_loss: 1025.5244\n",
      "Epoch 1258/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1250.2731 - val_loss: 1038.6594\n",
      "Epoch 1259/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1260.8186 - val_loss: 1036.4552\n",
      "Epoch 1260/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1258.0880 - val_loss: 1029.2338\n",
      "Epoch 1261/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1260.7074 - val_loss: 1029.5667\n",
      "Epoch 1262/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1245.5026 - val_loss: 1025.9244\n",
      "Epoch 1263/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1248.5774 - val_loss: 1031.2351\n",
      "Epoch 1264/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1248.8339 - val_loss: 1031.7031\n",
      "Epoch 1265/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1247.6050 - val_loss: 1027.0159\n",
      "Epoch 1266/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1243.0330 - val_loss: 1026.1399\n",
      "Epoch 1267/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1244.7397 - val_loss: 1034.2246\n",
      "Epoch 1268/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1244.5156 - val_loss: 1031.9095\n",
      "Epoch 1269/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1246.9553 - val_loss: 1024.8843\n",
      "Epoch 1270/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1259.1702 - val_loss: 1026.9244\n",
      "Epoch 1271/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1246.7452 - val_loss: 1029.3762\n",
      "Epoch 1272/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1233.3839 - val_loss: 1035.2559\n",
      "Epoch 1273/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.6190 - val_loss: 1025.3549\n",
      "Epoch 1274/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1245.7535 - val_loss: 1030.0552\n",
      "Epoch 1275/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1245.6196 - val_loss: 1038.8185\n",
      "Epoch 1276/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1250.8018 - val_loss: 1024.9465\n",
      "Epoch 1277/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1255.8875 - val_loss: 1025.8033\n",
      "Epoch 1278/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1242.0956 - val_loss: 1032.6765\n",
      "Epoch 1279/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1254.4922 - val_loss: 1026.7441\n",
      "Epoch 1280/3000\n",
      "36515/36515 [==============================] - 0s 8us/sample - loss: 1248.5358 - val_loss: 1023.5028\n",
      "Epoch 1281/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.7524 - val_loss: 1030.6622\n",
      "Epoch 1282/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1250.0735 - val_loss: 1040.6648\n",
      "Epoch 1283/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1262.1951 - val_loss: 1025.8077\n",
      "Epoch 1284/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1243.9803 - val_loss: 1023.8248\n",
      "Epoch 1285/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.6510 - val_loss: 1031.7794\n",
      "Epoch 1286/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1238.6771 - val_loss: 1038.2217\n",
      "Epoch 1287/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1241.3174 - val_loss: 1021.7499\n",
      "Epoch 1288/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1242.1941 - val_loss: 1023.2371\n",
      "Epoch 1289/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1249.3465 - val_loss: 1030.4518\n",
      "Epoch 1290/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1240.5557 - val_loss: 1027.6865\n",
      "Epoch 1291/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.9555 - val_loss: 1024.8246\n",
      "Epoch 1292/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1238.1604 - val_loss: 1024.0564\n",
      "Epoch 1293/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1245.0223 - val_loss: 1027.2513\n",
      "Epoch 1294/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1240.0332 - val_loss: 1022.6910\n",
      "Epoch 1295/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1248.5737 - val_loss: 1033.0162\n",
      "Epoch 1296/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1253.7703 - val_loss: 1035.3999\n",
      "Epoch 1297/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1244.2081 - val_loss: 1023.6199\n",
      "Epoch 1298/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1252.9275 - val_loss: 1025.6173\n",
      "Epoch 1299/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1242.2734 - val_loss: 1036.9150\n",
      "Epoch 1300/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1243.8844 - val_loss: 1024.2869\n",
      "Epoch 1301/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1243.2119 - val_loss: 1021.2219\n",
      "Epoch 1302/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1241.8028 - val_loss: 1028.8950\n",
      "Epoch 1303/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1234.2224 - val_loss: 1019.6410\n",
      "Epoch 1304/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1246.8516 - val_loss: 1022.7118\n",
      "Epoch 1305/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1242.3047 - val_loss: 1031.9486\n",
      "Epoch 1306/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1248.0554 - val_loss: 1026.0038\n",
      "Epoch 1307/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1240.8900 - val_loss: 1017.2676\n",
      "Epoch 1308/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1243.3966 - val_loss: 1028.5895\n",
      "Epoch 1309/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1237.2423 - val_loss: 1033.0994\n",
      "Epoch 1310/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1240.1862 - val_loss: 1022.8184\n",
      "Epoch 1311/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1239.8604 - val_loss: 1021.2543\n",
      "Epoch 1312/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1242.0265 - val_loss: 1027.6047\n",
      "Epoch 1313/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1236.1235 - val_loss: 1027.8716\n",
      "Epoch 1314/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1247.7892 - val_loss: 1019.2304\n",
      "Epoch 1315/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1247.1759 - val_loss: 1024.2555\n",
      "Epoch 1316/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1239.9955 - val_loss: 1038.5188\n",
      "Epoch 1317/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1249.7696 - val_loss: 1021.0360\n",
      "Epoch 1318/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.1595 - val_loss: 1021.2395\n",
      "Epoch 1319/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1244.1654 - val_loss: 1022.0291\n",
      "Epoch 1320/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1237.3293 - val_loss: 1027.3257\n",
      "Epoch 1321/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1245.5203 - val_loss: 1020.3481\n",
      "Epoch 1322/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1238.7688 - val_loss: 1021.0992\n",
      "Epoch 1323/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1236.0220 - val_loss: 1029.7638\n",
      "Epoch 1324/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1249.8461 - val_loss: 1020.7827\n",
      "Epoch 1325/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1237.1024 - val_loss: 1021.1343\n",
      "Epoch 1326/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1233.0833 - val_loss: 1028.2029\n",
      "Epoch 1327/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.7572 - val_loss: 1023.5639\n",
      "Epoch 1328/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1238.3327 - val_loss: 1021.6950\n",
      "Epoch 1329/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.9517 - val_loss: 1021.7720\n",
      "Epoch 1330/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1234.8134 - val_loss: 1021.4803\n",
      "Epoch 1331/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1231.4980 - val_loss: 1018.6986\n",
      "Epoch 1332/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1233.3881 - val_loss: 1021.3359\n",
      "Epoch 1333/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1240.8257 - val_loss: 1024.0754\n",
      "Epoch 1334/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1243.5754 - val_loss: 1020.1631\n",
      "Epoch 1335/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.5020 - val_loss: 1017.5623\n",
      "Epoch 1336/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.0379 - val_loss: 1023.9271\n",
      "Epoch 1337/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1228.6871 - val_loss: 1021.8856\n",
      "Epoch 1338/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1233.5632 - val_loss: 1015.7033\n",
      "Epoch 1339/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1235.9824 - val_loss: 1022.3412\n",
      "Epoch 1340/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1231.4706 - val_loss: 1028.1730\n",
      "Epoch 1341/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1228.2284 - val_loss: 1014.8965\n",
      "Epoch 1342/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1241.9756 - val_loss: 1014.7433\n",
      "Epoch 1343/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1237.1473 - val_loss: 1021.1220\n",
      "Epoch 1344/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1232.7658 - val_loss: 1026.7512\n",
      "Epoch 1345/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1232.5843 - val_loss: 1018.6945\n",
      "Epoch 1346/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.9128 - val_loss: 1015.0677\n",
      "Epoch 1347/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1238.3507 - val_loss: 1028.5582\n",
      "Epoch 1348/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1228.3737 - val_loss: 1019.8879\n",
      "Epoch 1349/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.1988 - val_loss: 1016.1781\n",
      "Epoch 1350/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1226.7398 - val_loss: 1019.9498\n",
      "Epoch 1351/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.4969 - val_loss: 1019.2896\n",
      "Epoch 1352/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1237.0182 - val_loss: 1017.2605\n",
      "Epoch 1353/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1232.3958 - val_loss: 1019.2330\n",
      "Epoch 1354/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1228.2479 - val_loss: 1021.8102\n",
      "Epoch 1355/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1242.7113 - val_loss: 1017.6400\n",
      "Epoch 1356/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1241.2839 - val_loss: 1015.9207\n",
      "Epoch 1357/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1233.3327 - val_loss: 1016.1087\n",
      "Epoch 1358/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1236.8040 - val_loss: 1027.1647\n",
      "Epoch 1359/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1230.5961 - val_loss: 1018.3011\n",
      "Epoch 1360/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1229.5204 - val_loss: 1013.2869\n",
      "Epoch 1361/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1246.7014 - val_loss: 1023.2792\n",
      "Epoch 1362/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1228.1565 - val_loss: 1028.8589\n",
      "Epoch 1363/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1228.0070 - val_loss: 1016.3657\n",
      "Epoch 1364/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.4593 - val_loss: 1016.9301\n",
      "Epoch 1365/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1244.9547 - val_loss: 1024.8562\n",
      "Epoch 1366/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1223.1864 - val_loss: 1016.8913\n",
      "Epoch 1367/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1225.2932 - val_loss: 1015.7859\n",
      "Epoch 1368/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1228.4843 - val_loss: 1022.4392\n",
      "Epoch 1369/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1233.2485 - val_loss: 1018.2716\n",
      "Epoch 1370/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1221.4382 - val_loss: 1014.0151\n",
      "Epoch 1371/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.1599 - val_loss: 1019.4439\n",
      "Epoch 1372/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1235.5774 - val_loss: 1020.4142\n",
      "Epoch 1373/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1245.7324 - val_loss: 1016.8440\n",
      "Epoch 1374/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1227.9543 - val_loss: 1017.4501\n",
      "Epoch 1375/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1231.9745 - val_loss: 1026.6434\n",
      "Epoch 1376/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1232.3635 - val_loss: 1018.2490\n",
      "Epoch 1377/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1232.9164 - val_loss: 1018.1069\n",
      "Epoch 1378/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1231.3735 - val_loss: 1015.9624\n",
      "Epoch 1379/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1224.7077 - val_loss: 1013.2859\n",
      "Epoch 1380/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1238.8327 - val_loss: 1014.7567\n",
      "Epoch 1381/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.4213 - val_loss: 1016.9494\n",
      "Epoch 1382/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1228.0177 - val_loss: 1016.6807\n",
      "Epoch 1383/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1218.3422 - val_loss: 1011.7592\n",
      "Epoch 1384/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1220.6438 - val_loss: 1010.7570\n",
      "Epoch 1385/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1222.7505 - val_loss: 1022.3760\n",
      "Epoch 1386/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1234.9960 - val_loss: 1020.0775\n",
      "Epoch 1387/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1219.2701 - val_loss: 1011.9751\n",
      "Epoch 1388/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1232.3918 - val_loss: 1014.3788\n",
      "Epoch 1389/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.3464 - val_loss: 1019.2822\n",
      "Epoch 1390/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1235.5856 - val_loss: 1011.8030\n",
      "Epoch 1391/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1230.5079 - val_loss: 1014.7711\n",
      "Epoch 1392/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1220.1937 - val_loss: 1014.3588\n",
      "Epoch 1393/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1226.3635 - val_loss: 1011.5511\n",
      "Epoch 1394/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1233.1483 - val_loss: 1017.0897\n",
      "Epoch 1395/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1223.3252 - val_loss: 1016.3478\n",
      "Epoch 1396/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1213.2616 - val_loss: 1016.7113\n",
      "Epoch 1397/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1229.5580 - val_loss: 1010.1320\n",
      "Epoch 1398/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1226.3624 - val_loss: 1013.8740\n",
      "Epoch 1399/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1227.8063 - val_loss: 1023.2492\n",
      "Epoch 1400/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1221.8554 - val_loss: 1010.7404\n",
      "Epoch 1401/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1211.3481 - val_loss: 1008.5519\n",
      "Epoch 1402/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.5224 - val_loss: 1013.0837\n",
      "Epoch 1403/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1223.8285 - val_loss: 1017.8926\n",
      "Epoch 1404/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1225.3066 - val_loss: 1010.4713\n",
      "Epoch 1405/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.2590 - val_loss: 1013.0767\n",
      "Epoch 1406/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.1109 - val_loss: 1018.7625\n",
      "Epoch 1407/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1233.0693 - val_loss: 1015.7835\n",
      "Epoch 1408/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1223.6042 - val_loss: 1007.2352\n",
      "Epoch 1409/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1229.0543 - val_loss: 1012.9422\n",
      "Epoch 1410/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.4281 - val_loss: 1036.5310\n",
      "Epoch 1411/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1237.5499 - val_loss: 1011.2440\n",
      "Epoch 1412/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1230.2763 - val_loss: 1010.7737\n",
      "Epoch 1413/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1225.6530 - val_loss: 1015.1669\n",
      "Epoch 1414/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1227.2509 - val_loss: 1016.5170\n",
      "Epoch 1415/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1215.8352 - val_loss: 1012.1178\n",
      "Epoch 1416/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1225.7376 - val_loss: 1011.5276\n",
      "Epoch 1417/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1217.7870 - val_loss: 1014.2404\n",
      "Epoch 1418/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1219.4765 - val_loss: 1012.3699\n",
      "Epoch 1419/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1213.7252 - val_loss: 1009.6655\n",
      "Epoch 1420/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.5181 - val_loss: 1013.7523\n",
      "Epoch 1421/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1225.2521 - val_loss: 1019.3552\n",
      "Epoch 1422/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.4226 - val_loss: 1013.8371\n",
      "Epoch 1423/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1211.8195 - val_loss: 1009.7514\n",
      "Epoch 1424/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1218.5097 - val_loss: 1005.2735\n",
      "Epoch 1425/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1224.0378 - val_loss: 1014.1353\n",
      "Epoch 1426/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1218.8348 - val_loss: 1013.7830\n",
      "Epoch 1427/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.4068 - val_loss: 1007.0748\n",
      "Epoch 1428/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1223.9422 - val_loss: 1009.3766\n",
      "Epoch 1429/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1215.1820 - val_loss: 1013.0054\n",
      "Epoch 1430/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1215.3017 - val_loss: 1008.7265\n",
      "Epoch 1431/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.0462 - val_loss: 1009.9894\n",
      "Epoch 1432/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1219.9711 - val_loss: 1009.9716\n",
      "Epoch 1433/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1222.1550 - val_loss: 1006.4520\n",
      "Epoch 1434/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.0257 - val_loss: 1012.5615\n",
      "Epoch 1435/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1221.3111 - val_loss: 1010.6500\n",
      "Epoch 1436/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.3225 - val_loss: 1005.9212\n",
      "Epoch 1437/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.3996 - val_loss: 1008.6602\n",
      "Epoch 1438/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1219.1978 - val_loss: 1014.3546\n",
      "Epoch 1439/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1215.5881 - val_loss: 1010.7336\n",
      "Epoch 1440/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1214.6930 - val_loss: 1006.9091\n",
      "Epoch 1441/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1219.1024 - val_loss: 1007.2289\n",
      "Epoch 1442/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1222.6137 - val_loss: 1011.5743\n",
      "Epoch 1443/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1218.6043 - val_loss: 1008.5378\n",
      "Epoch 1444/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1229.8301 - val_loss: 1006.9067\n",
      "Epoch 1445/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1223.7768 - val_loss: 1010.1425\n",
      "Epoch 1446/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1218.3449 - val_loss: 1012.3538\n",
      "Epoch 1447/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1223.5838 - val_loss: 1010.5554\n",
      "Epoch 1448/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1213.4177 - val_loss: 1014.3152\n",
      "Epoch 1449/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1209.5849 - val_loss: 1004.2856\n",
      "Epoch 1450/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1220.5403 - val_loss: 1009.7745\n",
      "Epoch 1451/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1214.9543 - val_loss: 1008.0445\n",
      "Epoch 1452/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1215.6596 - val_loss: 1003.1396\n",
      "Epoch 1453/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1210.7929 - val_loss: 1008.7111\n",
      "Epoch 1454/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1218.5975 - val_loss: 1009.8143\n",
      "Epoch 1455/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1225.3779 - val_loss: 1005.6728\n",
      "Epoch 1456/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1212.9089 - val_loss: 1006.1982\n",
      "Epoch 1457/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1209.8432 - val_loss: 1006.0666\n",
      "Epoch 1458/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1215.7363 - val_loss: 1003.4746\n",
      "Epoch 1459/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1221.8479 - val_loss: 1006.7067\n",
      "Epoch 1460/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.3006 - val_loss: 1007.9722\n",
      "Epoch 1461/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1214.6755 - val_loss: 1004.1607\n",
      "Epoch 1462/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1205.0464 - val_loss: 1012.7104\n",
      "Epoch 1463/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1212.5672 - val_loss: 1010.0008\n",
      "Epoch 1464/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1210.7447 - val_loss: 1001.7233\n",
      "Epoch 1465/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1206.6864 - val_loss: 1006.7272\n",
      "Epoch 1466/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1209.5517 - val_loss: 1008.4823\n",
      "Epoch 1467/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1214.6339 - val_loss: 1008.6832\n",
      "Epoch 1468/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.2756 - val_loss: 1002.4689\n",
      "Epoch 1469/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1220.6821 - val_loss: 1002.1334\n",
      "Epoch 1470/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1215.7644 - val_loss: 1021.2415\n",
      "Epoch 1471/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1224.5220 - val_loss: 1007.4677\n",
      "Epoch 1472/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1204.5195 - val_loss: 999.8988\n",
      "Epoch 1473/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1202.6479 - val_loss: 1005.3257\n",
      "Epoch 1474/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1217.6754 - val_loss: 1005.6622\n",
      "Epoch 1475/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1201.1092 - val_loss: 1005.5428\n",
      "Epoch 1476/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1211.5158 - val_loss: 1002.7318\n",
      "Epoch 1477/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1205.4003 - val_loss: 1006.9835\n",
      "Epoch 1478/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1212.9245 - val_loss: 1009.8923\n",
      "Epoch 1479/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1208.2274 - val_loss: 1006.1959\n",
      "Epoch 1480/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1212.5838 - val_loss: 1002.8498\n",
      "Epoch 1481/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1198.3340 - val_loss: 1005.3790\n",
      "Epoch 1482/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1214.8800 - val_loss: 1008.0499\n",
      "Epoch 1483/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1215.2104 - val_loss: 1002.4408\n",
      "Epoch 1484/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1205.5085 - val_loss: 1003.8805\n",
      "Epoch 1485/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1209.9436 - val_loss: 1010.6771\n",
      "Epoch 1486/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1210.4786 - val_loss: 1007.1417\n",
      "Epoch 1487/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1208.6571 - val_loss: 997.8453\n",
      "Epoch 1488/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.3217 - val_loss: 1004.3907\n",
      "Epoch 1489/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1208.7405 - val_loss: 1008.1659\n",
      "Epoch 1490/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1207.9809 - val_loss: 1004.2432\n",
      "Epoch 1491/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1210.3413 - val_loss: 1003.3849\n",
      "Epoch 1492/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1198.6336 - val_loss: 1001.8665\n",
      "Epoch 1493/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1206.5667 - val_loss: 1005.5059\n",
      "Epoch 1494/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1204.4209 - val_loss: 1002.4501\n",
      "Epoch 1495/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1200.8514 - val_loss: 1001.0525\n",
      "Epoch 1496/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1197.3335 - val_loss: 1008.2515\n",
      "Epoch 1497/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1204.4316 - val_loss: 1003.4652\n",
      "Epoch 1498/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1205.4051 - val_loss: 997.0506\n",
      "Epoch 1499/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1194.6971 - val_loss: 1005.6569\n",
      "Epoch 1500/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1207.7677 - val_loss: 1003.8832\n",
      "Epoch 1501/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1204.5739 - val_loss: 998.8699\n",
      "Epoch 1502/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1216.7710 - val_loss: 1001.2414\n",
      "Epoch 1503/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1209.8148 - val_loss: 1017.2233\n",
      "Epoch 1504/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1210.2399 - val_loss: 1006.4412\n",
      "Epoch 1505/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1207.2331 - val_loss: 998.3730\n",
      "Epoch 1506/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1207.9387 - val_loss: 1000.9497\n",
      "Epoch 1507/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1195.3590 - val_loss: 1000.5387\n",
      "Epoch 1508/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1192.5714 - val_loss: 1010.3713\n",
      "Epoch 1509/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1210.8073 - val_loss: 999.8815\n",
      "Epoch 1510/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1205.8398 - val_loss: 997.4886\n",
      "Epoch 1511/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1205.9846 - val_loss: 1002.4891\n",
      "Epoch 1512/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1202.0041 - val_loss: 1000.0500\n",
      "Epoch 1513/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1204.4766 - val_loss: 1003.6872\n",
      "Epoch 1514/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1192.8110 - val_loss: 999.4827\n",
      "Epoch 1515/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1193.4900 - val_loss: 1000.7079\n",
      "Epoch 1516/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1206.5723 - val_loss: 998.1653\n",
      "Epoch 1517/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1202.7686 - val_loss: 1004.5892\n",
      "Epoch 1518/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1198.5633 - val_loss: 1001.0468\n",
      "Epoch 1519/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1201.2199 - val_loss: 1001.1467\n",
      "Epoch 1520/3000\n",
      "36515/36515 [==============================] - 1s 21us/sample - loss: 1207.7363 - val_loss: 996.7597\n",
      "Epoch 1521/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1198.3391 - val_loss: 1002.0630\n",
      "Epoch 1522/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1206.8515 - val_loss: 1007.2988\n",
      "Epoch 1523/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1197.3491 - val_loss: 996.0294\n",
      "Epoch 1524/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1219.6162 - val_loss: 1000.9620\n",
      "Epoch 1525/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1200.5073 - val_loss: 1007.4588\n",
      "Epoch 1526/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.6704 - val_loss: 996.4053\n",
      "Epoch 1527/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1191.0272 - val_loss: 999.8235\n",
      "Epoch 1528/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1202.0829 - val_loss: 994.1738\n",
      "Epoch 1529/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1201.5985 - val_loss: 1002.2548\n",
      "Epoch 1530/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1201.3179 - val_loss: 1000.8599\n",
      "Epoch 1531/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1201.1538 - val_loss: 995.4089\n",
      "Epoch 1532/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1201.1857 - val_loss: 1002.0913\n",
      "Epoch 1533/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1201.8771 - val_loss: 1006.9622\n",
      "Epoch 1534/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.8527 - val_loss: 1000.9551\n",
      "Epoch 1535/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1195.2930 - val_loss: 996.4079\n",
      "Epoch 1536/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.5740 - val_loss: 994.6269\n",
      "Epoch 1537/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1200.1752 - val_loss: 1001.4617\n",
      "Epoch 1538/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1199.1968 - val_loss: 1000.0950\n",
      "Epoch 1539/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1193.9432 - val_loss: 995.2599\n",
      "Epoch 1540/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.0126 - val_loss: 997.6749\n",
      "Epoch 1541/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1193.5639 - val_loss: 1000.0980\n",
      "Epoch 1542/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.2078 - val_loss: 1002.9113\n",
      "Epoch 1543/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1199.7982 - val_loss: 994.7189\n",
      "Epoch 1544/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1193.4873 - val_loss: 995.4469\n",
      "Epoch 1545/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.0119 - val_loss: 997.3986\n",
      "Epoch 1546/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.1038 - val_loss: 1006.0970\n",
      "Epoch 1547/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1206.8227 - val_loss: 996.1993\n",
      "Epoch 1548/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1186.1529 - val_loss: 994.1221\n",
      "Epoch 1549/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1186.5653 - val_loss: 1004.1942\n",
      "Epoch 1550/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1197.0251 - val_loss: 993.8703\n",
      "Epoch 1551/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1216.9243 - val_loss: 997.4644\n",
      "Epoch 1552/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1199.6572 - val_loss: 1000.1430\n",
      "Epoch 1553/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1197.4251 - val_loss: 995.1917\n",
      "Epoch 1554/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1199.4098 - val_loss: 995.7215\n",
      "Epoch 1555/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.4535 - val_loss: 1012.7328\n",
      "Epoch 1556/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1202.2425 - val_loss: 996.8812\n",
      "Epoch 1557/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.2259 - val_loss: 995.9666\n",
      "Epoch 1558/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1195.6179 - val_loss: 993.9465\n",
      "Epoch 1559/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1195.9771 - val_loss: 1009.8739\n",
      "Epoch 1560/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1194.5887 - val_loss: 997.1145\n",
      "Epoch 1561/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.4322 - val_loss: 996.1339\n",
      "Epoch 1562/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1187.6424 - val_loss: 994.0269\n",
      "Epoch 1563/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1180.5289 - val_loss: 999.8832\n",
      "Epoch 1564/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1200.4489 - val_loss: 993.6953\n",
      "Epoch 1565/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1192.0830 - val_loss: 994.4477\n",
      "Epoch 1566/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1207.0864 - val_loss: 994.7577\n",
      "Epoch 1567/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1193.8133 - val_loss: 993.3082\n",
      "Epoch 1568/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1199.5997 - val_loss: 1001.6103\n",
      "Epoch 1569/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1189.1267 - val_loss: 991.6469\n",
      "Epoch 1570/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1195.3910 - val_loss: 994.3185\n",
      "Epoch 1571/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.6134 - val_loss: 1002.7929\n",
      "Epoch 1572/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1197.4467 - val_loss: 991.0294\n",
      "Epoch 1573/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1182.8750 - val_loss: 995.4800\n",
      "Epoch 1574/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1193.8561 - val_loss: 995.5933\n",
      "Epoch 1575/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1195.8902 - val_loss: 997.7405\n",
      "Epoch 1576/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1203.6005 - val_loss: 1000.7964\n",
      "Epoch 1577/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1192.1121 - val_loss: 989.6136\n",
      "Epoch 1578/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1195.0455 - val_loss: 997.8197\n",
      "Epoch 1579/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1188.3911 - val_loss: 992.6387\n",
      "Epoch 1580/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.3312 - val_loss: 995.3876\n",
      "Epoch 1581/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1205.3702 - val_loss: 999.1553\n",
      "Epoch 1582/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1190.5158 - val_loss: 995.2535\n",
      "Epoch 1583/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1187.1033 - val_loss: 994.2508\n",
      "Epoch 1584/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1190.2025 - val_loss: 991.8154\n",
      "Epoch 1585/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1201.6486 - val_loss: 995.3040\n",
      "Epoch 1586/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1187.2260 - val_loss: 994.1080\n",
      "Epoch 1587/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1191.7562 - val_loss: 992.7386\n",
      "Epoch 1588/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1181.9595 - val_loss: 996.9033\n",
      "Epoch 1589/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1194.9577 - val_loss: 990.9472\n",
      "Epoch 1590/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.0701 - val_loss: 992.6908\n",
      "Epoch 1591/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1197.8888 - val_loss: 996.6844\n",
      "Epoch 1592/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1182.8816 - val_loss: 993.3444\n",
      "Epoch 1593/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.3222 - val_loss: 992.7874\n",
      "Epoch 1594/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1188.3751 - val_loss: 991.2699\n",
      "Epoch 1595/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.4614 - val_loss: 997.3201\n",
      "Epoch 1596/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.3958 - val_loss: 992.0462\n",
      "Epoch 1597/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1191.2932 - val_loss: 986.9937\n",
      "Epoch 1598/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1192.7099 - val_loss: 992.3184\n",
      "Epoch 1599/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1185.3251 - val_loss: 997.6072\n",
      "Epoch 1600/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1190.5060 - val_loss: 991.9623\n",
      "Epoch 1601/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1186.3789 - val_loss: 993.9604\n",
      "Epoch 1602/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1192.4143 - val_loss: 991.9954\n",
      "Epoch 1603/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1178.1212 - val_loss: 995.0677\n",
      "Epoch 1604/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1186.8757 - val_loss: 992.2853\n",
      "Epoch 1605/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1188.7257 - val_loss: 991.8585\n",
      "Epoch 1606/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1198.9188 - val_loss: 995.1383\n",
      "Epoch 1607/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1186.6056 - val_loss: 988.4604\n",
      "Epoch 1608/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1185.8686 - val_loss: 996.8705\n",
      "Epoch 1609/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.0641 - val_loss: 988.7817\n",
      "Epoch 1610/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.5785 - val_loss: 989.8844\n",
      "Epoch 1611/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.9561 - val_loss: 995.7740\n",
      "Epoch 1612/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.7983 - val_loss: 993.0667\n",
      "Epoch 1613/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1179.2546 - val_loss: 989.3259\n",
      "Epoch 1614/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1186.2024 - val_loss: 989.9158\n",
      "Epoch 1615/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1189.7759 - val_loss: 993.5042\n",
      "Epoch 1616/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1186.3252 - val_loss: 990.3259\n",
      "Epoch 1617/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1190.4982 - val_loss: 987.2055\n",
      "Epoch 1618/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1185.5945 - val_loss: 987.3407\n",
      "Epoch 1619/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1180.2301 - val_loss: 992.1032\n",
      "Epoch 1620/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1176.9469 - val_loss: 994.4407\n",
      "Epoch 1621/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1177.5802 - val_loss: 986.2990\n",
      "Epoch 1622/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1181.1312 - val_loss: 990.5607\n",
      "Epoch 1623/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.9249 - val_loss: 997.1909\n",
      "Epoch 1624/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1188.4662 - val_loss: 992.5613\n",
      "Epoch 1625/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1185.6727 - val_loss: 994.0507\n",
      "Epoch 1626/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1183.3127 - val_loss: 989.1586\n",
      "Epoch 1627/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1181.6576 - val_loss: 991.8106\n",
      "Epoch 1628/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1170.6865 - val_loss: 987.6361\n",
      "Epoch 1629/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1176.6325 - val_loss: 990.5163\n",
      "Epoch 1630/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1180.3531 - val_loss: 989.6053\n",
      "Epoch 1631/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1177.1171 - val_loss: 988.2089\n",
      "Epoch 1632/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1179.4203 - val_loss: 991.2415\n",
      "Epoch 1633/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1188.7447 - val_loss: 995.7669\n",
      "Epoch 1634/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1188.6232 - val_loss: 985.2748\n",
      "Epoch 1635/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1181.1676 - val_loss: 986.0197\n",
      "Epoch 1636/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.0979 - val_loss: 994.3188\n",
      "Epoch 1637/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.8296 - val_loss: 990.2123\n",
      "Epoch 1638/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1186.1172 - val_loss: 989.0390\n",
      "Epoch 1639/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1174.3570 - val_loss: 984.6064\n",
      "Epoch 1640/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1186.7413 - val_loss: 988.9086\n",
      "Epoch 1641/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1184.0419 - val_loss: 986.7219\n",
      "Epoch 1642/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1176.7104 - val_loss: 993.0659\n",
      "Epoch 1643/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1172.1574 - val_loss: 985.8995\n",
      "Epoch 1644/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1174.7151 - val_loss: 984.1605\n",
      "Epoch 1645/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1185.3454 - val_loss: 987.9580\n",
      "Epoch 1646/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1169.3645 - val_loss: 985.9542\n",
      "Epoch 1647/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1181.9989 - val_loss: 989.5729\n",
      "Epoch 1648/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1188.7475 - val_loss: 985.4254\n",
      "Epoch 1649/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1183.8546 - val_loss: 987.1096\n",
      "Epoch 1650/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1179.5776 - val_loss: 986.8909\n",
      "Epoch 1651/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1176.3064 - val_loss: 984.6172\n",
      "Epoch 1652/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1178.0003 - val_loss: 986.6556\n",
      "Epoch 1653/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1180.1664 - val_loss: 982.9713\n",
      "Epoch 1654/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1178.5279 - val_loss: 990.3088\n",
      "Epoch 1655/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1169.5855 - val_loss: 988.9644\n",
      "Epoch 1656/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1174.1362 - val_loss: 981.4334\n",
      "Epoch 1657/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1176.1114 - val_loss: 984.6914\n",
      "Epoch 1658/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1170.6427 - val_loss: 994.6985\n",
      "Epoch 1659/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1182.3218 - val_loss: 992.0928\n",
      "Epoch 1660/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1175.8061 - val_loss: 983.3716\n",
      "Epoch 1661/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1170.4670 - val_loss: 983.5802\n",
      "Epoch 1662/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1180.8582 - val_loss: 987.1861\n",
      "Epoch 1663/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1180.7579 - val_loss: 990.1405\n",
      "Epoch 1664/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1188.0335 - val_loss: 987.2743\n",
      "Epoch 1665/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1180.8364 - val_loss: 982.4914\n",
      "Epoch 1666/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1175.7832 - val_loss: 983.0663\n",
      "Epoch 1667/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1176.9758 - val_loss: 986.3946\n",
      "Epoch 1668/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1172.5311 - val_loss: 983.2385\n",
      "Epoch 1669/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1168.8707 - val_loss: 984.2138\n",
      "Epoch 1670/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1171.2678 - val_loss: 987.0197\n",
      "Epoch 1671/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1170.6013 - val_loss: 983.0002\n",
      "Epoch 1672/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1185.8321 - val_loss: 984.2762\n",
      "Epoch 1673/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1167.8885 - val_loss: 981.6682\n",
      "Epoch 1674/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1180.4616 - val_loss: 991.2917\n",
      "Epoch 1675/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1169.0895 - val_loss: 980.9355\n",
      "Epoch 1676/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1175.4671 - val_loss: 985.0367\n",
      "Epoch 1677/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.2407 - val_loss: 981.3224\n",
      "Epoch 1678/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1174.1979 - val_loss: 982.9187\n",
      "Epoch 1679/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1176.2054 - val_loss: 985.0615\n",
      "Epoch 1680/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1187.5812 - val_loss: 985.2000\n",
      "Epoch 1681/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1179.3373 - val_loss: 980.8444\n",
      "Epoch 1682/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1157.9965 - val_loss: 986.4435\n",
      "Epoch 1683/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1169.6292 - val_loss: 987.7907\n",
      "Epoch 1684/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1168.4991 - val_loss: 980.9450\n",
      "Epoch 1685/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1166.1092 - val_loss: 983.6945\n",
      "Epoch 1686/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1175.4271 - val_loss: 982.2916\n",
      "Epoch 1687/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1174.1164 - val_loss: 979.0029\n",
      "Epoch 1688/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1175.8629 - val_loss: 985.1558\n",
      "Epoch 1689/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1165.1476 - val_loss: 983.3414\n",
      "Epoch 1690/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1167.2638 - val_loss: 985.2512\n",
      "Epoch 1691/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1170.1244 - val_loss: 978.8679\n",
      "Epoch 1692/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1175.1623 - val_loss: 982.1665\n",
      "Epoch 1693/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1167.5176 - val_loss: 984.5763\n",
      "Epoch 1694/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1163.4382 - val_loss: 983.7240\n",
      "Epoch 1695/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1166.8246 - val_loss: 987.6625\n",
      "Epoch 1696/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1164.8970 - val_loss: 977.5859\n",
      "Epoch 1697/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1166.4098 - val_loss: 984.5984\n",
      "Epoch 1698/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1170.9347 - val_loss: 979.6588\n",
      "Epoch 1699/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1174.1780 - val_loss: 983.9365\n",
      "Epoch 1700/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1173.8530 - val_loss: 979.7125\n",
      "Epoch 1701/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.7837 - val_loss: 981.3753\n",
      "Epoch 1702/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1152.2758 - val_loss: 981.1572\n",
      "Epoch 1703/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1165.8501 - val_loss: 982.0845\n",
      "Epoch 1704/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1173.8965 - val_loss: 980.4385\n",
      "Epoch 1705/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1167.7679 - val_loss: 979.9497\n",
      "Epoch 1706/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1175.1171 - val_loss: 979.3866\n",
      "Epoch 1707/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1174.6361 - val_loss: 981.8010\n",
      "Epoch 1708/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1173.3325 - val_loss: 979.2208\n",
      "Epoch 1709/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.0219 - val_loss: 981.6274\n",
      "Epoch 1710/3000\n",
      "36515/36515 [==============================] - 0s 9us/sample - loss: 1171.9229 - val_loss: 976.0715\n",
      "Epoch 1711/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1161.3868 - val_loss: 979.2876\n",
      "Epoch 1712/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1168.2640 - val_loss: 980.2615\n",
      "Epoch 1713/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1162.1988 - val_loss: 980.2062\n",
      "Epoch 1714/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1174.5959 - val_loss: 979.6049\n",
      "Epoch 1715/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1157.5867 - val_loss: 979.0024\n",
      "Epoch 1716/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1163.8816 - val_loss: 982.3685\n",
      "Epoch 1717/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1166.8122 - val_loss: 978.2354\n",
      "Epoch 1718/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1173.5854 - val_loss: 978.7358\n",
      "Epoch 1719/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1173.4639 - val_loss: 978.9467\n",
      "Epoch 1720/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1175.9030 - val_loss: 981.2510\n",
      "Epoch 1721/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.6201 - val_loss: 978.8375\n",
      "Epoch 1722/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1163.4419 - val_loss: 982.0721\n",
      "Epoch 1723/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1152.3521 - val_loss: 979.1617\n",
      "Epoch 1724/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1178.0785 - val_loss: 980.7603\n",
      "Epoch 1725/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1158.4422 - val_loss: 977.0500\n",
      "Epoch 1726/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1170.2588 - val_loss: 976.8647\n",
      "Epoch 1727/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1161.7733 - val_loss: 975.9615\n",
      "Epoch 1728/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1157.6514 - val_loss: 979.1185\n",
      "Epoch 1729/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1165.2971 - val_loss: 983.6042\n",
      "Epoch 1730/3000\n",
      "36515/36515 [==============================] - 1s 22us/sample - loss: 1167.3598 - val_loss: 973.2128\n",
      "Epoch 1731/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1156.3377 - val_loss: 978.2172\n",
      "Epoch 1732/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1163.5932 - val_loss: 975.8044\n",
      "Epoch 1733/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1166.5771 - val_loss: 977.5746\n",
      "Epoch 1734/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1172.1569 - val_loss: 976.4435\n",
      "Epoch 1735/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1162.4700 - val_loss: 978.5871\n",
      "Epoch 1736/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.5023 - val_loss: 975.2904\n",
      "Epoch 1737/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1170.7779 - val_loss: 988.5338\n",
      "Epoch 1738/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1169.1975 - val_loss: 980.7335\n",
      "Epoch 1739/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1175.9004 - val_loss: 975.4957\n",
      "Epoch 1740/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1163.1633 - val_loss: 983.1531\n",
      "Epoch 1741/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1167.6431 - val_loss: 977.4442\n",
      "Epoch 1742/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.3911 - val_loss: 978.4830\n",
      "Epoch 1743/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1158.1617 - val_loss: 972.6218\n",
      "Epoch 1744/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1166.7413 - val_loss: 976.5708\n",
      "Epoch 1745/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1163.7251 - val_loss: 977.2852\n",
      "Epoch 1746/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.4592 - val_loss: 979.0891\n",
      "Epoch 1747/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1168.8005 - val_loss: 975.4838\n",
      "Epoch 1748/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1158.3190 - val_loss: 973.1988\n",
      "Epoch 1749/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1158.1100 - val_loss: 972.5644\n",
      "Epoch 1750/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1165.0597 - val_loss: 978.3279\n",
      "Epoch 1751/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1161.5477 - val_loss: 982.8250\n",
      "Epoch 1752/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1158.5763 - val_loss: 971.5751\n",
      "Epoch 1753/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1161.9144 - val_loss: 976.3299\n",
      "Epoch 1754/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1155.9348 - val_loss: 978.0151\n",
      "Epoch 1755/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.3425 - val_loss: 972.9101\n",
      "Epoch 1756/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1162.8379 - val_loss: 975.3121\n",
      "Epoch 1757/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1160.9447 - val_loss: 976.1384\n",
      "Epoch 1758/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1160.1998 - val_loss: 975.6312\n",
      "Epoch 1759/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.0465 - val_loss: 972.0440\n",
      "Epoch 1760/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.3367 - val_loss: 971.8942\n",
      "Epoch 1761/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1145.0320 - val_loss: 973.8702\n",
      "Epoch 1762/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1164.6577 - val_loss: 971.4871\n",
      "Epoch 1763/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1159.8553 - val_loss: 972.5724\n",
      "Epoch 1764/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1157.9356 - val_loss: 979.6682\n",
      "Epoch 1765/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1166.9799 - val_loss: 978.3366\n",
      "Epoch 1766/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1155.0897 - val_loss: 969.0378\n",
      "Epoch 1767/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1150.1566 - val_loss: 977.8649\n",
      "Epoch 1768/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1156.4852 - val_loss: 973.7790\n",
      "Epoch 1769/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1153.0634 - val_loss: 976.0242\n",
      "Epoch 1770/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1158.2158 - val_loss: 968.9019\n",
      "Epoch 1771/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1162.0122 - val_loss: 973.9017\n",
      "Epoch 1772/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1160.2628 - val_loss: 972.2001\n",
      "Epoch 1773/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1160.3531 - val_loss: 978.1904\n",
      "Epoch 1774/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.1629 - val_loss: 973.2358\n",
      "Epoch 1775/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1156.4004 - val_loss: 970.5269\n",
      "Epoch 1776/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1141.8883 - val_loss: 970.5394\n",
      "Epoch 1777/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1167.4174 - val_loss: 971.2028\n",
      "Epoch 1778/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1157.2557 - val_loss: 974.6132\n",
      "Epoch 1779/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1163.2442 - val_loss: 977.2388\n",
      "Epoch 1780/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1161.6614 - val_loss: 968.1371\n",
      "Epoch 1781/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1153.6919 - val_loss: 970.3066\n",
      "Epoch 1782/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1159.3576 - val_loss: 976.3517\n",
      "Epoch 1783/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1153.1033 - val_loss: 977.8177\n",
      "Epoch 1784/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1158.3178 - val_loss: 970.1208\n",
      "Epoch 1785/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.2641 - val_loss: 970.3470\n",
      "Epoch 1786/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1155.2690 - val_loss: 970.4497\n",
      "Epoch 1787/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.3976 - val_loss: 976.0914\n",
      "Epoch 1788/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1158.4805 - val_loss: 972.9672\n",
      "Epoch 1789/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1158.9415 - val_loss: 972.5316\n",
      "Epoch 1790/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1152.1843 - val_loss: 973.0912\n",
      "Epoch 1791/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1156.2850 - val_loss: 979.2787\n",
      "Epoch 1792/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1164.5968 - val_loss: 975.7217\n",
      "Epoch 1793/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1154.1753 - val_loss: 966.1957\n",
      "Epoch 1794/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1152.7824 - val_loss: 972.0741\n",
      "Epoch 1795/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1152.2253 - val_loss: 969.7057\n",
      "Epoch 1796/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1145.3900 - val_loss: 978.9588\n",
      "Epoch 1797/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1147.1460 - val_loss: 968.0256\n",
      "Epoch 1798/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.0715 - val_loss: 968.5096\n",
      "Epoch 1799/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.7497 - val_loss: 967.2307\n",
      "Epoch 1800/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1153.3324 - val_loss: 972.7405\n",
      "Epoch 1801/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.6244 - val_loss: 969.0132\n",
      "Epoch 1802/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.1366 - val_loss: 973.1852\n",
      "Epoch 1803/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1147.0233 - val_loss: 963.1929\n",
      "Epoch 1804/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1153.2844 - val_loss: 973.0244\n",
      "Epoch 1805/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1146.9109 - val_loss: 965.2366\n",
      "Epoch 1806/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.1841 - val_loss: 975.5069\n",
      "Epoch 1807/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.3633 - val_loss: 966.4457\n",
      "Epoch 1808/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1152.7148 - val_loss: 970.5032\n",
      "Epoch 1809/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.6598 - val_loss: 966.0154\n",
      "Epoch 1810/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1149.5434 - val_loss: 972.2996\n",
      "Epoch 1811/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1155.9117 - val_loss: 968.8145\n",
      "Epoch 1812/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.3827 - val_loss: 970.6832\n",
      "Epoch 1813/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.6979 - val_loss: 966.9124\n",
      "Epoch 1814/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1153.0865 - val_loss: 976.1802\n",
      "Epoch 1815/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.8369 - val_loss: 969.5184\n",
      "Epoch 1816/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1149.7616 - val_loss: 965.2197\n",
      "Epoch 1817/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1143.7018 - val_loss: 968.9622\n",
      "Epoch 1818/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1138.1954 - val_loss: 972.6318\n",
      "Epoch 1819/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.1630 - val_loss: 966.4882\n",
      "Epoch 1820/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1142.2112 - val_loss: 964.7527\n",
      "Epoch 1821/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1145.8225 - val_loss: 973.3284\n",
      "Epoch 1822/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1153.1448 - val_loss: 969.8748\n",
      "Epoch 1823/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1154.1071 - val_loss: 966.5824\n",
      "Epoch 1824/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1146.8364 - val_loss: 965.7891\n",
      "Epoch 1825/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.9971 - val_loss: 964.4327\n",
      "Epoch 1826/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.3596 - val_loss: 972.2413\n",
      "Epoch 1827/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1150.1923 - val_loss: 970.9748\n",
      "Epoch 1828/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1150.3806 - val_loss: 963.4529\n",
      "Epoch 1829/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1137.4845 - val_loss: 962.8107\n",
      "Epoch 1830/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1153.1863 - val_loss: 967.6713\n",
      "Epoch 1831/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1135.4899 - val_loss: 963.9658\n",
      "Epoch 1832/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.4590 - val_loss: 967.0765\n",
      "Epoch 1833/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.8504 - val_loss: 967.3014\n",
      "Epoch 1834/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.2980 - val_loss: 970.4435\n",
      "Epoch 1835/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.3365 - val_loss: 963.9398\n",
      "Epoch 1836/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.9810 - val_loss: 966.1326\n",
      "Epoch 1837/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1156.6194 - val_loss: 963.4476\n",
      "Epoch 1838/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1145.7503 - val_loss: 966.3092\n",
      "Epoch 1839/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1147.8454 - val_loss: 966.2778\n",
      "Epoch 1840/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1149.7194 - val_loss: 969.1080\n",
      "Epoch 1841/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1156.3726 - val_loss: 965.3068\n",
      "Epoch 1842/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.5351 - val_loss: 965.8027\n",
      "Epoch 1843/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1149.6288 - val_loss: 962.8411\n",
      "Epoch 1844/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1143.1290 - val_loss: 964.9580\n",
      "Epoch 1845/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1137.1381 - val_loss: 961.8669\n",
      "Epoch 1846/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1139.3226 - val_loss: 962.7896\n",
      "Epoch 1847/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1138.9369 - val_loss: 964.7035\n",
      "Epoch 1848/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1156.7207 - val_loss: 959.6060\n",
      "Epoch 1849/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1145.5531 - val_loss: 964.7818\n",
      "Epoch 1850/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1141.8946 - val_loss: 960.9859\n",
      "Epoch 1851/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.3934 - val_loss: 965.1578\n",
      "Epoch 1852/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1146.5150 - val_loss: 966.6821\n",
      "Epoch 1853/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1146.3815 - val_loss: 965.7457\n",
      "Epoch 1854/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1147.7275 - val_loss: 966.9694\n",
      "Epoch 1855/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1139.8919 - val_loss: 960.5057\n",
      "Epoch 1856/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1147.4491 - val_loss: 964.7838\n",
      "Epoch 1857/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1146.2457 - val_loss: 964.3583\n",
      "Epoch 1858/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1149.6079 - val_loss: 965.0637\n",
      "Epoch 1859/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1139.8523 - val_loss: 961.9082\n",
      "Epoch 1860/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1142.0212 - val_loss: 958.5138\n",
      "Epoch 1861/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1141.0865 - val_loss: 965.2292\n",
      "Epoch 1862/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1132.9213 - val_loss: 963.2808\n",
      "Epoch 1863/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1138.8845 - val_loss: 962.4229\n",
      "Epoch 1864/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.6344 - val_loss: 960.7374\n",
      "Epoch 1865/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1139.5167 - val_loss: 967.0943\n",
      "Epoch 1866/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1141.1106 - val_loss: 972.5760\n",
      "Epoch 1867/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1140.9837 - val_loss: 959.6559\n",
      "Epoch 1868/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1130.9712 - val_loss: 966.1437\n",
      "Epoch 1869/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1136.7087 - val_loss: 957.0610\n",
      "Epoch 1870/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1150.9459 - val_loss: 965.1232\n",
      "Epoch 1871/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1131.7604 - val_loss: 959.7703\n",
      "Epoch 1872/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1142.0611 - val_loss: 961.1560\n",
      "Epoch 1873/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1148.8657 - val_loss: 960.5142\n",
      "Epoch 1874/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1142.9270 - val_loss: 964.1629\n",
      "Epoch 1875/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1133.1832 - val_loss: 959.0119\n",
      "Epoch 1876/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1133.8501 - val_loss: 960.2398\n",
      "Epoch 1877/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1145.9150 - val_loss: 963.4261\n",
      "Epoch 1878/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1144.3375 - val_loss: 966.8137\n",
      "Epoch 1879/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1137.5500 - val_loss: 963.5670\n",
      "Epoch 1880/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1135.7616 - val_loss: 960.2452\n",
      "Epoch 1881/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1143.4669 - val_loss: 962.2037\n",
      "Epoch 1882/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1147.4569 - val_loss: 960.1765\n",
      "Epoch 1883/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.7222 - val_loss: 958.0666\n",
      "Epoch 1884/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1143.1515 - val_loss: 960.7252\n",
      "Epoch 1885/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1146.0367 - val_loss: 959.0386\n",
      "Epoch 1886/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1151.4328 - val_loss: 965.2561\n",
      "Epoch 1887/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1132.1231 - val_loss: 957.1418\n",
      "Epoch 1888/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1135.5549 - val_loss: 962.0704\n",
      "Epoch 1889/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1140.2398 - val_loss: 957.8376\n",
      "Epoch 1890/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1129.9236 - val_loss: 962.0773\n",
      "Epoch 1891/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1135.9811 - val_loss: 960.6578\n",
      "Epoch 1892/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1140.3088 - val_loss: 965.2645\n",
      "Epoch 1893/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1130.6869 - val_loss: 956.3889\n",
      "Epoch 1894/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.9814 - val_loss: 961.5598\n",
      "Epoch 1895/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1128.8600 - val_loss: 955.9575\n",
      "Epoch 1896/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1133.0614 - val_loss: 957.3099\n",
      "Epoch 1897/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1134.3942 - val_loss: 960.8314\n",
      "Epoch 1898/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1136.9001 - val_loss: 967.0616\n",
      "Epoch 1899/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1137.6979 - val_loss: 957.1564\n",
      "Epoch 1900/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1131.8459 - val_loss: 960.1057\n",
      "Epoch 1901/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1128.4112 - val_loss: 955.3227\n",
      "Epoch 1902/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1130.9005 - val_loss: 960.2210\n",
      "Epoch 1903/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1137.7238 - val_loss: 961.0541\n",
      "Epoch 1904/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1140.8183 - val_loss: 958.8513\n",
      "Epoch 1905/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1134.0918 - val_loss: 956.1622\n",
      "Epoch 1906/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1134.3921 - val_loss: 960.0593\n",
      "Epoch 1907/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1139.4212 - val_loss: 963.9355\n",
      "Epoch 1908/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1125.5213 - val_loss: 954.4608\n",
      "Epoch 1909/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1137.2457 - val_loss: 963.8575\n",
      "Epoch 1910/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1136.1269 - val_loss: 959.7679\n",
      "Epoch 1911/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1141.5910 - val_loss: 959.7790\n",
      "Epoch 1912/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1129.5021 - val_loss: 955.1406\n",
      "Epoch 1913/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1132.2209 - val_loss: 957.6272\n",
      "Epoch 1914/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.4561 - val_loss: 956.2838\n",
      "Epoch 1915/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.4039 - val_loss: 961.9708\n",
      "Epoch 1916/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1134.5289 - val_loss: 957.1263\n",
      "Epoch 1917/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1142.9543 - val_loss: 956.4548\n",
      "Epoch 1918/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1133.6036 - val_loss: 956.3439\n",
      "Epoch 1919/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1135.8138 - val_loss: 959.2153\n",
      "Epoch 1920/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1139.3520 - val_loss: 962.1014\n",
      "Epoch 1921/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1137.6517 - val_loss: 958.6726\n",
      "Epoch 1922/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1129.2866 - val_loss: 956.0355\n",
      "Epoch 1923/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1129.1825 - val_loss: 958.3335\n",
      "Epoch 1924/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1138.9398 - val_loss: 957.3627\n",
      "Epoch 1925/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1134.7178 - val_loss: 956.5912\n",
      "Epoch 1926/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1123.3094 - val_loss: 957.4923\n",
      "Epoch 1927/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1134.9940 - val_loss: 957.2346\n",
      "Epoch 1928/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1129.9504 - val_loss: 957.6553\n",
      "Epoch 1929/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1127.7044 - val_loss: 958.2385\n",
      "Epoch 1930/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1131.9744 - val_loss: 954.9728\n",
      "Epoch 1931/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1133.5674 - val_loss: 955.4412\n",
      "Epoch 1932/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.7107 - val_loss: 957.3639\n",
      "Epoch 1933/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1132.8431 - val_loss: 960.0291\n",
      "Epoch 1934/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1128.8185 - val_loss: 953.6257\n",
      "Epoch 1935/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1134.6486 - val_loss: 959.8569\n",
      "Epoch 1936/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1133.3736 - val_loss: 954.3803\n",
      "Epoch 1937/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1126.9505 - val_loss: 955.3874\n",
      "Epoch 1938/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1127.5379 - val_loss: 955.7101\n",
      "Epoch 1939/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1134.5877 - val_loss: 956.3904\n",
      "Epoch 1940/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1135.0832 - val_loss: 953.1556\n",
      "Epoch 1941/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1133.0353 - val_loss: 954.2240\n",
      "Epoch 1942/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1131.9255 - val_loss: 954.8135\n",
      "Epoch 1943/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1124.2479 - val_loss: 952.0022\n",
      "Epoch 1944/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1133.4250 - val_loss: 954.6778\n",
      "Epoch 1945/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1127.6274 - val_loss: 956.5679\n",
      "Epoch 1946/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1122.4587 - val_loss: 954.2716\n",
      "Epoch 1947/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1123.0815 - val_loss: 956.3249\n",
      "Epoch 1948/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1125.2690 - val_loss: 952.6033\n",
      "Epoch 1949/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1123.7447 - val_loss: 958.9348\n",
      "Epoch 1950/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.2315 - val_loss: 953.2664\n",
      "Epoch 1951/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1130.3743 - val_loss: 955.4642\n",
      "Epoch 1952/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1126.0130 - val_loss: 952.2532\n",
      "Epoch 1953/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1122.9427 - val_loss: 956.5836\n",
      "Epoch 1954/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1130.9820 - val_loss: 953.0469\n",
      "Epoch 1955/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1126.9945 - val_loss: 951.4970\n",
      "Epoch 1956/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.9981 - val_loss: 956.8152\n",
      "Epoch 1957/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1125.1684 - val_loss: 952.3217\n",
      "Epoch 1958/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1132.2183 - val_loss: 955.8436\n",
      "Epoch 1959/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.8056 - val_loss: 952.7079\n",
      "Epoch 1960/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1118.0047 - val_loss: 953.4921\n",
      "Epoch 1961/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1125.6010 - val_loss: 952.3586\n",
      "Epoch 1962/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1127.1931 - val_loss: 954.4138\n",
      "Epoch 1963/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1122.6737 - val_loss: 950.6830\n",
      "Epoch 1964/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1127.9279 - val_loss: 953.6738\n",
      "Epoch 1965/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.4251 - val_loss: 955.4259\n",
      "Epoch 1966/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1129.4288 - val_loss: 953.2665\n",
      "Epoch 1967/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1123.4323 - val_loss: 952.5333\n",
      "Epoch 1968/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1116.5865 - val_loss: 951.5976\n",
      "Epoch 1969/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1127.8924 - val_loss: 953.6595\n",
      "Epoch 1970/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1130.5001 - val_loss: 956.0343\n",
      "Epoch 1971/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1125.4298 - val_loss: 951.5560\n",
      "Epoch 1972/3000\n",
      "36515/36515 [==============================] - 1s 14us/sample - loss: 1125.1357 - val_loss: 950.5247\n",
      "Epoch 1973/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1123.5031 - val_loss: 954.1257\n",
      "Epoch 1974/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1137.5866 - val_loss: 958.9770\n",
      "Epoch 1975/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.0737 - val_loss: 953.8984\n",
      "Epoch 1976/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1118.1248 - val_loss: 954.3003\n",
      "Epoch 1977/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1113.7134 - val_loss: 948.4033\n",
      "Epoch 1978/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.0860 - val_loss: 952.5697\n",
      "Epoch 1979/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1129.2808 - val_loss: 959.2519\n",
      "Epoch 1980/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1126.2134 - val_loss: 956.1434\n",
      "Epoch 1981/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1122.6291 - val_loss: 949.5884\n",
      "Epoch 1982/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1127.2175 - val_loss: 954.0988\n",
      "Epoch 1983/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1126.0824 - val_loss: 960.0726\n",
      "Epoch 1984/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1114.7250 - val_loss: 953.6019\n",
      "Epoch 1985/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1118.7939 - val_loss: 947.1683\n",
      "Epoch 1986/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1126.2639 - val_loss: 952.0032\n",
      "Epoch 1987/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1125.8204 - val_loss: 951.0144\n",
      "Epoch 1988/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.9950 - val_loss: 951.4402\n",
      "Epoch 1989/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.9513 - val_loss: 949.3578\n",
      "Epoch 1990/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.8551 - val_loss: 951.5210\n",
      "Epoch 1991/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1126.7198 - val_loss: 951.7311\n",
      "Epoch 1992/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1128.7752 - val_loss: 952.9648\n",
      "Epoch 1993/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.7644 - val_loss: 950.7305\n",
      "Epoch 1994/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1118.8379 - val_loss: 949.7345\n",
      "Epoch 1995/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1126.0841 - val_loss: 947.0797\n",
      "Epoch 1996/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1106.9934 - val_loss: 951.6426\n",
      "Epoch 1997/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.6991 - val_loss: 947.2948\n",
      "Epoch 1998/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1122.7465 - val_loss: 956.2901\n",
      "Epoch 1999/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1108.3157 - val_loss: 947.7392\n",
      "Epoch 2000/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.0727 - val_loss: 953.1077\n",
      "Epoch 2001/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.6910 - val_loss: 948.7368\n",
      "Epoch 2002/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.3436 - val_loss: 954.0994\n",
      "Epoch 2003/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.7139 - val_loss: 950.1099\n",
      "Epoch 2004/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.6866 - val_loss: 954.2704\n",
      "Epoch 2005/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1108.1811 - val_loss: 951.1466\n",
      "Epoch 2006/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.0898 - val_loss: 950.3434\n",
      "Epoch 2007/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.6465 - val_loss: 948.6890\n",
      "Epoch 2008/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.6790 - val_loss: 948.2923\n",
      "Epoch 2009/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.5589 - val_loss: 950.1378\n",
      "Epoch 2010/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1118.9657 - val_loss: 948.7106\n",
      "Epoch 2011/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1110.9849 - val_loss: 952.2167\n",
      "Epoch 2012/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.1527 - val_loss: 950.6632\n",
      "Epoch 2013/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.2066 - val_loss: 952.5574\n",
      "Epoch 2014/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1125.8065 - val_loss: 946.1948\n",
      "Epoch 2015/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1117.1382 - val_loss: 948.8033\n",
      "Epoch 2016/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1114.9828 - val_loss: 948.0532\n",
      "Epoch 2017/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1117.8150 - val_loss: 947.0616\n",
      "Epoch 2018/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.6555 - val_loss: 949.4686\n",
      "Epoch 2019/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1114.0011 - val_loss: 946.5580\n",
      "Epoch 2020/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1121.5934 - val_loss: 950.6973\n",
      "Epoch 2021/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1115.8652 - val_loss: 945.5226\n",
      "Epoch 2022/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1101.8921 - val_loss: 949.3289\n",
      "Epoch 2023/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1122.8527 - val_loss: 952.9674\n",
      "Epoch 2024/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.7113 - val_loss: 947.2668\n",
      "Epoch 2025/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1123.0730 - val_loss: 946.2800\n",
      "Epoch 2026/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1102.9861 - val_loss: 946.6067\n",
      "Epoch 2027/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1115.1923 - val_loss: 947.4716\n",
      "Epoch 2028/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.8708 - val_loss: 950.7118\n",
      "Epoch 2029/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1116.8332 - val_loss: 949.3012\n",
      "Epoch 2030/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1122.7202 - val_loss: 951.9855\n",
      "Epoch 2031/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.3044 - val_loss: 947.6688\n",
      "Epoch 2032/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.7507 - val_loss: 951.9633\n",
      "Epoch 2033/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.5557 - val_loss: 958.5408\n",
      "Epoch 2034/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.0438 - val_loss: 948.3206\n",
      "Epoch 2035/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1120.2685 - val_loss: 948.2513\n",
      "Epoch 2036/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1116.1025 - val_loss: 943.9797\n",
      "Epoch 2037/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.3136 - val_loss: 949.0548\n",
      "Epoch 2038/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1122.5318 - val_loss: 951.4859\n",
      "Epoch 2039/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1103.6921 - val_loss: 946.5543\n",
      "Epoch 2040/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.5794 - val_loss: 945.8919\n",
      "Epoch 2041/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1115.5759 - val_loss: 945.7449\n",
      "Epoch 2042/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.0184 - val_loss: 945.7871\n",
      "Epoch 2043/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1109.9439 - val_loss: 944.4326\n",
      "Epoch 2044/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1114.3877 - val_loss: 948.3578\n",
      "Epoch 2045/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1111.2508 - val_loss: 943.1224\n",
      "Epoch 2046/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1112.6120 - val_loss: 952.0043\n",
      "Epoch 2047/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1106.4549 - val_loss: 945.0007\n",
      "Epoch 2048/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1119.7265 - val_loss: 950.3338\n",
      "Epoch 2049/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1109.2337 - val_loss: 941.5421\n",
      "Epoch 2050/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1110.8958 - val_loss: 958.0081\n",
      "Epoch 2051/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1113.1814 - val_loss: 948.1533\n",
      "Epoch 2052/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1112.1462 - val_loss: 947.5713\n",
      "Epoch 2053/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1104.4772 - val_loss: 944.3476\n",
      "Epoch 2054/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1115.2205 - val_loss: 943.9296\n",
      "Epoch 2055/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1113.2217 - val_loss: 948.7726\n",
      "Epoch 2056/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1114.7394 - val_loss: 946.1288\n",
      "Epoch 2057/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.3672 - val_loss: 944.3610\n",
      "Epoch 2058/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1110.4421 - val_loss: 945.4949\n",
      "Epoch 2059/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1113.9163 - val_loss: 946.5643\n",
      "Epoch 2060/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1104.1647 - val_loss: 946.9238\n",
      "Epoch 2061/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1095.0299 - val_loss: 940.1610\n",
      "Epoch 2062/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1120.9102 - val_loss: 948.6396\n",
      "Epoch 2063/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1110.5015 - val_loss: 942.1706\n",
      "Epoch 2064/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1107.5822 - val_loss: 944.1796\n",
      "Epoch 2065/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.6437 - val_loss: 945.3660\n",
      "Epoch 2066/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.9360 - val_loss: 941.9931\n",
      "Epoch 2067/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.9799 - val_loss: 948.8882\n",
      "Epoch 2068/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.7926 - val_loss: 942.0129\n",
      "Epoch 2069/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.5555 - val_loss: 949.7667\n",
      "Epoch 2070/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1108.3173 - val_loss: 942.6819\n",
      "Epoch 2071/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1106.9260 - val_loss: 948.6728\n",
      "Epoch 2072/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.3763 - val_loss: 942.2078\n",
      "Epoch 2073/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.5063 - val_loss: 945.3237\n",
      "Epoch 2074/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1110.8364 - val_loss: 941.0913\n",
      "Epoch 2075/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1117.8081 - val_loss: 945.8084\n",
      "Epoch 2076/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1114.0666 - val_loss: 950.1882\n",
      "Epoch 2077/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1108.8372 - val_loss: 943.2526\n",
      "Epoch 2078/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.0987 - val_loss: 946.9892\n",
      "Epoch 2079/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1102.1040 - val_loss: 945.7516\n",
      "Epoch 2080/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1106.2953 - val_loss: 943.5082\n",
      "Epoch 2081/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1101.0865 - val_loss: 945.6959\n",
      "Epoch 2082/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1118.7431 - val_loss: 944.9318\n",
      "Epoch 2083/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.2196 - val_loss: 944.0541\n",
      "Epoch 2084/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1109.8524 - val_loss: 948.7140\n",
      "Epoch 2085/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1113.7569 - val_loss: 946.5629\n",
      "Epoch 2086/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1109.7086 - val_loss: 946.3755\n",
      "Epoch 2087/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1103.2263 - val_loss: 940.6748\n",
      "Epoch 2088/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1109.7704 - val_loss: 946.3915\n",
      "Epoch 2089/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.8068 - val_loss: 941.5837\n",
      "Epoch 2090/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1112.3108 - val_loss: 946.0616\n",
      "Epoch 2091/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1102.5052 - val_loss: 942.3188\n",
      "Epoch 2092/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1101.4452 - val_loss: 947.1983\n",
      "Epoch 2093/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1115.6471 - val_loss: 939.4139\n",
      "Epoch 2094/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1104.8723 - val_loss: 945.3082\n",
      "Epoch 2095/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1107.8249 - val_loss: 940.2990\n",
      "Epoch 2096/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1102.9488 - val_loss: 950.3130\n",
      "Epoch 2097/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.7184 - val_loss: 943.4479\n",
      "Epoch 2098/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1108.7976 - val_loss: 943.6237\n",
      "Epoch 2099/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1097.7790 - val_loss: 939.1635\n",
      "Epoch 2100/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1105.1765 - val_loss: 947.2972\n",
      "Epoch 2101/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1107.2943 - val_loss: 946.7689\n",
      "Epoch 2102/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1109.5483 - val_loss: 942.8400\n",
      "Epoch 2103/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.2608 - val_loss: 939.8733\n",
      "Epoch 2104/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1103.0589 - val_loss: 942.5406\n",
      "Epoch 2105/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1094.3484 - val_loss: 941.8608\n",
      "Epoch 2106/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1101.5948 - val_loss: 939.9761\n",
      "Epoch 2107/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1106.9530 - val_loss: 948.1552\n",
      "Epoch 2108/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1114.7912 - val_loss: 942.5991\n",
      "Epoch 2109/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1101.4824 - val_loss: 942.3638\n",
      "Epoch 2110/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1098.1199 - val_loss: 940.3266\n",
      "Epoch 2111/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1112.9017 - val_loss: 942.5378\n",
      "Epoch 2112/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1110.7894 - val_loss: 939.6383\n",
      "Epoch 2113/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1097.3496 - val_loss: 938.8284\n",
      "Epoch 2114/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1098.9253 - val_loss: 940.8323\n",
      "Epoch 2115/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1104.8407 - val_loss: 941.2054\n",
      "Epoch 2116/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1100.9996 - val_loss: 940.5571\n",
      "Epoch 2117/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1111.7112 - val_loss: 940.1605\n",
      "Epoch 2118/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1098.8787 - val_loss: 938.5250\n",
      "Epoch 2119/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1101.6026 - val_loss: 940.0411\n",
      "Epoch 2120/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1091.6650 - val_loss: 939.5204\n",
      "Epoch 2121/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1099.4611 - val_loss: 943.6216\n",
      "Epoch 2122/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1099.5885 - val_loss: 937.5534\n",
      "Epoch 2123/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1101.6542 - val_loss: 942.3256\n",
      "Epoch 2124/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1090.0627 - val_loss: 938.7000\n",
      "Epoch 2125/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1096.4112 - val_loss: 939.3975\n",
      "Epoch 2126/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1102.5033 - val_loss: 940.0524\n",
      "Epoch 2127/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1100.9988 - val_loss: 939.3199\n",
      "Epoch 2128/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1110.6585 - val_loss: 943.2627\n",
      "Epoch 2129/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.8803 - val_loss: 938.1103\n",
      "Epoch 2130/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1098.3837 - val_loss: 940.2466\n",
      "Epoch 2131/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1098.8427 - val_loss: 939.7719\n",
      "Epoch 2132/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1102.1556 - val_loss: 939.8376\n",
      "Epoch 2133/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1091.0311 - val_loss: 936.6977\n",
      "Epoch 2134/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1103.9197 - val_loss: 938.5367\n",
      "Epoch 2135/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1098.7602 - val_loss: 940.6348\n",
      "Epoch 2136/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1101.0988 - val_loss: 941.2247\n",
      "Epoch 2137/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1090.1825 - val_loss: 943.3586\n",
      "Epoch 2138/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1094.1727 - val_loss: 937.1832\n",
      "Epoch 2139/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1092.5774 - val_loss: 940.6785\n",
      "Epoch 2140/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.9466 - val_loss: 940.0040\n",
      "Epoch 2141/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1102.2277 - val_loss: 937.7776\n",
      "Epoch 2142/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.3604 - val_loss: 949.6605\n",
      "Epoch 2143/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1106.7396 - val_loss: 937.7505\n",
      "Epoch 2144/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1098.2821 - val_loss: 941.4376\n",
      "Epoch 2145/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1093.6315 - val_loss: 934.5390\n",
      "Epoch 2146/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1102.9039 - val_loss: 943.7115\n",
      "Epoch 2147/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.1321 - val_loss: 937.6610\n",
      "Epoch 2148/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1106.5427 - val_loss: 938.9948\n",
      "Epoch 2149/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1093.2215 - val_loss: 937.4566\n",
      "Epoch 2150/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1094.8747 - val_loss: 936.5068\n",
      "Epoch 2151/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1088.0780 - val_loss: 938.9600\n",
      "Epoch 2152/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.5754 - val_loss: 940.0923\n",
      "Epoch 2153/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1100.3818 - val_loss: 941.5173\n",
      "Epoch 2154/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1094.2013 - val_loss: 938.1930\n",
      "Epoch 2155/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.5603 - val_loss: 940.2724\n",
      "Epoch 2156/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1092.3607 - val_loss: 938.9230\n",
      "Epoch 2157/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1105.3188 - val_loss: 941.3425\n",
      "Epoch 2158/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.4659 - val_loss: 936.8711\n",
      "Epoch 2159/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.9577 - val_loss: 937.0388\n",
      "Epoch 2160/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1087.9738 - val_loss: 940.2410\n",
      "Epoch 2161/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1083.6962 - val_loss: 935.2595\n",
      "Epoch 2162/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1086.2110 - val_loss: 942.6066\n",
      "Epoch 2163/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.9054 - val_loss: 935.1027\n",
      "Epoch 2164/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1104.0216 - val_loss: 939.5984\n",
      "Epoch 2165/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.9925 - val_loss: 935.5396\n",
      "Epoch 2166/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1094.9042 - val_loss: 937.8084\n",
      "Epoch 2167/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1090.2668 - val_loss: 934.7437\n",
      "Epoch 2168/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1099.2083 - val_loss: 939.4937\n",
      "Epoch 2169/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1095.4353 - val_loss: 933.5039\n",
      "Epoch 2170/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.8467 - val_loss: 941.5157\n",
      "Epoch 2171/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1090.7637 - val_loss: 933.9987\n",
      "Epoch 2172/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.0623 - val_loss: 941.4976\n",
      "Epoch 2173/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1087.1175 - val_loss: 933.7875\n",
      "Epoch 2174/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.3001 - val_loss: 937.0750\n",
      "Epoch 2175/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.3272 - val_loss: 933.5865\n",
      "Epoch 2176/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1085.2136 - val_loss: 935.0793\n",
      "Epoch 2177/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1091.9588 - val_loss: 937.4528\n",
      "Epoch 2178/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1086.0958 - val_loss: 936.3413\n",
      "Epoch 2179/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.6336 - val_loss: 939.5180\n",
      "Epoch 2180/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1104.9221 - val_loss: 936.4734\n",
      "Epoch 2181/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1091.7567 - val_loss: 939.6736\n",
      "Epoch 2182/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1098.9818 - val_loss: 938.4547\n",
      "Epoch 2183/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.5794 - val_loss: 933.6854\n",
      "Epoch 2184/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1096.5496 - val_loss: 938.7055\n",
      "Epoch 2185/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1091.6450 - val_loss: 934.8388\n",
      "Epoch 2186/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1094.6078 - val_loss: 940.0997\n",
      "Epoch 2187/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1092.5476 - val_loss: 932.3994\n",
      "Epoch 2188/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1091.8922 - val_loss: 934.3339\n",
      "Epoch 2189/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1079.0423 - val_loss: 935.0329\n",
      "Epoch 2190/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1093.2243 - val_loss: 933.8093\n",
      "Epoch 2191/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1091.5844 - val_loss: 936.0572\n",
      "Epoch 2192/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1096.2018 - val_loss: 937.8542\n",
      "Epoch 2193/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1085.6050 - val_loss: 935.8091\n",
      "Epoch 2194/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1100.1718 - val_loss: 939.7523\n",
      "Epoch 2195/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1095.0845 - val_loss: 937.3701\n",
      "Epoch 2196/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1088.5637 - val_loss: 939.6304\n",
      "Epoch 2197/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.2688 - val_loss: 941.2037\n",
      "Epoch 2198/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.6819 - val_loss: 935.2550\n",
      "Epoch 2199/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1096.2656 - val_loss: 939.9299\n",
      "Epoch 2200/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1082.7549 - val_loss: 934.6029\n",
      "Epoch 2201/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.7483 - val_loss: 939.0493\n",
      "Epoch 2202/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1088.6843 - val_loss: 936.7336\n",
      "Epoch 2203/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1088.5093 - val_loss: 934.2410\n",
      "Epoch 2204/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1086.9552 - val_loss: 936.2318\n",
      "Epoch 2205/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1084.9414 - val_loss: 932.4419\n",
      "Epoch 2206/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.8287 - val_loss: 936.6653\n",
      "Epoch 2207/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1090.0187 - val_loss: 931.4314\n",
      "Epoch 2208/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1081.6428 - val_loss: 936.8131\n",
      "Epoch 2209/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1079.5199 - val_loss: 934.1290\n",
      "Epoch 2210/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1085.9101 - val_loss: 936.6611\n",
      "Epoch 2211/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1081.6010 - val_loss: 935.4500\n",
      "Epoch 2212/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1093.1388 - val_loss: 933.9746\n",
      "Epoch 2213/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1092.1803 - val_loss: 933.8948\n",
      "Epoch 2214/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1088.2747 - val_loss: 934.6337\n",
      "Epoch 2215/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1091.0356 - val_loss: 936.2291\n",
      "Epoch 2216/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.0930 - val_loss: 933.2399\n",
      "Epoch 2217/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1078.2422 - val_loss: 931.4899\n",
      "Epoch 2218/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1082.1398 - val_loss: 933.2490\n",
      "Epoch 2219/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1086.8500 - val_loss: 933.4313\n",
      "Epoch 2220/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1080.8772 - val_loss: 930.0223\n",
      "Epoch 2221/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1092.3835 - val_loss: 932.8476\n",
      "Epoch 2222/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1086.6962 - val_loss: 933.8516\n",
      "Epoch 2223/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.8923 - val_loss: 931.5314\n",
      "Epoch 2224/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1091.1647 - val_loss: 933.9066\n",
      "Epoch 2225/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1093.2275 - val_loss: 931.6122\n",
      "Epoch 2226/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1085.0963 - val_loss: 936.4686\n",
      "Epoch 2227/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1097.5247 - val_loss: 931.0873\n",
      "Epoch 2228/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1076.8925 - val_loss: 934.5568\n",
      "Epoch 2229/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.8098 - val_loss: 932.5784\n",
      "Epoch 2230/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1078.8562 - val_loss: 931.7708\n",
      "Epoch 2231/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1090.7975 - val_loss: 934.1125\n",
      "Epoch 2232/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1084.0246 - val_loss: 936.0510\n",
      "Epoch 2233/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1082.2433 - val_loss: 931.4020\n",
      "Epoch 2234/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1074.2342 - val_loss: 930.0534\n",
      "Epoch 2235/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1087.1860 - val_loss: 933.3684\n",
      "Epoch 2236/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1080.1259 - val_loss: 935.0353\n",
      "Epoch 2237/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1085.3711 - val_loss: 935.6837\n",
      "Epoch 2238/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.3909 - val_loss: 933.3600\n",
      "Epoch 2239/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1080.0101 - val_loss: 933.1743\n",
      "Epoch 2240/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1079.6780 - val_loss: 934.3274\n",
      "Epoch 2241/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1083.7388 - val_loss: 933.7065\n",
      "Epoch 2242/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1073.1215 - val_loss: 930.2905\n",
      "Epoch 2243/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.0446 - val_loss: 931.7798\n",
      "Epoch 2244/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1078.2628 - val_loss: 932.1550\n",
      "Epoch 2245/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.1410 - val_loss: 933.5759\n",
      "Epoch 2246/3000\n",
      "36515/36515 [==============================] - 1s 21us/sample - loss: 1084.1761 - val_loss: 928.6109\n",
      "Epoch 2247/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1093.7582 - val_loss: 935.5062\n",
      "Epoch 2248/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1089.4759 - val_loss: 934.1852\n",
      "Epoch 2249/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1078.2599 - val_loss: 928.8120\n",
      "Epoch 2250/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1076.5848 - val_loss: 933.4305\n",
      "Epoch 2251/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1092.9264 - val_loss: 934.4415\n",
      "Epoch 2252/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1067.2028 - val_loss: 930.9818\n",
      "Epoch 2253/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.4650 - val_loss: 932.3054\n",
      "Epoch 2254/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1086.4952 - val_loss: 929.5645\n",
      "Epoch 2255/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1078.5522 - val_loss: 933.4862\n",
      "Epoch 2256/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1079.0836 - val_loss: 928.1499\n",
      "Epoch 2257/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1078.6963 - val_loss: 938.1074\n",
      "Epoch 2258/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1081.5440 - val_loss: 926.5969\n",
      "Epoch 2259/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1085.3829 - val_loss: 936.6606\n",
      "Epoch 2260/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1081.6063 - val_loss: 930.5504\n",
      "Epoch 2261/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1084.6166 - val_loss: 931.1729\n",
      "Epoch 2262/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1081.7523 - val_loss: 932.8549\n",
      "Epoch 2263/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.4317 - val_loss: 930.7780\n",
      "Epoch 2264/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.7072 - val_loss: 932.0186\n",
      "Epoch 2265/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1079.5236 - val_loss: 931.2532\n",
      "Epoch 2266/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1085.8797 - val_loss: 929.8014\n",
      "Epoch 2267/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1086.4178 - val_loss: 931.2004\n",
      "Epoch 2268/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1085.0725 - val_loss: 934.4517\n",
      "Epoch 2269/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.9984 - val_loss: 929.9513\n",
      "Epoch 2270/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.4977 - val_loss: 929.7669\n",
      "Epoch 2271/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1079.0979 - val_loss: 931.3030\n",
      "Epoch 2272/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1074.0224 - val_loss: 930.2298\n",
      "Epoch 2273/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.1098 - val_loss: 935.2227\n",
      "Epoch 2274/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1073.5126 - val_loss: 929.2791\n",
      "Epoch 2275/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1076.9326 - val_loss: 932.8162\n",
      "Epoch 2276/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1083.4432 - val_loss: 933.3419\n",
      "Epoch 2277/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.4796 - val_loss: 929.4392\n",
      "Epoch 2278/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1081.2011 - val_loss: 935.6744\n",
      "Epoch 2279/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1084.7321 - val_loss: 930.7726\n",
      "Epoch 2280/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1085.7085 - val_loss: 929.8983\n",
      "Epoch 2281/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1076.8179 - val_loss: 930.8098\n",
      "Epoch 2282/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1080.5422 - val_loss: 929.1422\n",
      "Epoch 2283/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1072.6914 - val_loss: 927.6669\n",
      "Epoch 2284/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1082.1263 - val_loss: 933.8580\n",
      "Epoch 2285/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1073.5162 - val_loss: 928.3553\n",
      "Epoch 2286/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.0624 - val_loss: 929.9363\n",
      "Epoch 2287/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1068.8780 - val_loss: 929.0973\n",
      "Epoch 2288/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1082.6917 - val_loss: 926.9637\n",
      "Epoch 2289/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1076.9970 - val_loss: 932.7689\n",
      "Epoch 2290/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1071.8742 - val_loss: 927.8662\n",
      "Epoch 2291/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1073.0198 - val_loss: 932.2988\n",
      "Epoch 2292/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1078.2787 - val_loss: 927.2119\n",
      "Epoch 2293/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1068.8462 - val_loss: 929.2129\n",
      "Epoch 2294/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1072.1969 - val_loss: 934.7736\n",
      "Epoch 2295/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.8140 - val_loss: 932.3148\n",
      "Epoch 2296/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1082.8785 - val_loss: 930.4675\n",
      "Epoch 2297/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.0350 - val_loss: 926.8924\n",
      "Epoch 2298/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1074.6993 - val_loss: 930.5911\n",
      "Epoch 2299/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1078.8098 - val_loss: 930.9517\n",
      "Epoch 2300/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.7805 - val_loss: 931.0018\n",
      "Epoch 2301/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.1659 - val_loss: 926.7715\n",
      "Epoch 2302/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1069.2602 - val_loss: 929.0534\n",
      "Epoch 2303/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.1757 - val_loss: 927.9072\n",
      "Epoch 2304/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.8205 - val_loss: 927.0412\n",
      "Epoch 2305/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1070.2946 - val_loss: 926.1985\n",
      "Epoch 2306/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1078.8218 - val_loss: 928.1042\n",
      "Epoch 2307/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1069.9457 - val_loss: 930.7476\n",
      "Epoch 2308/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1068.7146 - val_loss: 925.7304\n",
      "Epoch 2309/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1069.5102 - val_loss: 927.2288\n",
      "Epoch 2310/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.5322 - val_loss: 931.7657\n",
      "Epoch 2311/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1068.9730 - val_loss: 925.6958\n",
      "Epoch 2312/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1079.8734 - val_loss: 927.3703\n",
      "Epoch 2313/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1068.1989 - val_loss: 928.2045\n",
      "Epoch 2314/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1068.7837 - val_loss: 929.7669\n",
      "Epoch 2315/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1073.7935 - val_loss: 926.1707\n",
      "Epoch 2316/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1067.2076 - val_loss: 930.0453\n",
      "Epoch 2317/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1074.1597 - val_loss: 925.7365\n",
      "Epoch 2318/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.2598 - val_loss: 928.8324\n",
      "Epoch 2319/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1069.6348 - val_loss: 925.9768\n",
      "Epoch 2320/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1069.2836 - val_loss: 928.1606\n",
      "Epoch 2321/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1072.1451 - val_loss: 925.9526\n",
      "Epoch 2322/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.9423 - val_loss: 932.2837\n",
      "Epoch 2323/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1064.4109 - val_loss: 933.0802\n",
      "Epoch 2324/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1071.1873 - val_loss: 929.1600\n",
      "Epoch 2325/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1072.9888 - val_loss: 930.4479\n",
      "Epoch 2326/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1076.9979 - val_loss: 925.6121\n",
      "Epoch 2327/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.9503 - val_loss: 927.8193\n",
      "Epoch 2328/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1077.0175 - val_loss: 925.9010\n",
      "Epoch 2329/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1075.8063 - val_loss: 930.4301\n",
      "Epoch 2330/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1064.2517 - val_loss: 926.8302\n",
      "Epoch 2331/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1071.4115 - val_loss: 929.5764\n",
      "Epoch 2332/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1071.6841 - val_loss: 928.4391\n",
      "Epoch 2333/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1064.1303 - val_loss: 928.7867\n",
      "Epoch 2334/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1073.7600 - val_loss: 929.2009\n",
      "Epoch 2335/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1063.2293 - val_loss: 924.4042\n",
      "Epoch 2336/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1064.4434 - val_loss: 925.0682\n",
      "Epoch 2337/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.8179 - val_loss: 927.1210\n",
      "Epoch 2338/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1072.2380 - val_loss: 926.0463\n",
      "Epoch 2339/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1067.6165 - val_loss: 925.6741\n",
      "Epoch 2340/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1069.0573 - val_loss: 926.8881\n",
      "Epoch 2341/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1063.9187 - val_loss: 927.8971\n",
      "Epoch 2342/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1061.6871 - val_loss: 924.2451\n",
      "Epoch 2343/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1074.5260 - val_loss: 926.8215\n",
      "Epoch 2344/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1059.7821 - val_loss: 924.0319\n",
      "Epoch 2345/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1065.3782 - val_loss: 927.1595\n",
      "Epoch 2346/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1058.9618 - val_loss: 926.4415\n",
      "Epoch 2347/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1059.9427 - val_loss: 925.1796\n",
      "Epoch 2348/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.6153 - val_loss: 925.9358\n",
      "Epoch 2349/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.3990 - val_loss: 926.2936\n",
      "Epoch 2350/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1058.9720 - val_loss: 925.0884\n",
      "Epoch 2351/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.7796 - val_loss: 925.7377\n",
      "Epoch 2352/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1060.1796 - val_loss: 925.9116\n",
      "Epoch 2353/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.8382 - val_loss: 928.4521\n",
      "Epoch 2354/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1059.9980 - val_loss: 929.5820\n",
      "Epoch 2355/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1068.3799 - val_loss: 925.7919\n",
      "Epoch 2356/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1062.5485 - val_loss: 921.6331\n",
      "Epoch 2357/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.2612 - val_loss: 932.3062\n",
      "Epoch 2358/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.2420 - val_loss: 924.8262\n",
      "Epoch 2359/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.6015 - val_loss: 935.6953\n",
      "Epoch 2360/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1064.5287 - val_loss: 922.9778\n",
      "Epoch 2361/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.8598 - val_loss: 926.7632\n",
      "Epoch 2362/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1064.4604 - val_loss: 925.1395\n",
      "Epoch 2363/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1065.8338 - val_loss: 929.5167\n",
      "Epoch 2364/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.0711 - val_loss: 924.6052\n",
      "Epoch 2365/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.0209 - val_loss: 926.8166\n",
      "Epoch 2366/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1063.5193 - val_loss: 921.6622\n",
      "Epoch 2367/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.7224 - val_loss: 925.5434\n",
      "Epoch 2368/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1061.3809 - val_loss: 925.1309\n",
      "Epoch 2369/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1060.6987 - val_loss: 925.4323\n",
      "Epoch 2370/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1058.6206 - val_loss: 923.6987\n",
      "Epoch 2371/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1067.6714 - val_loss: 924.3663\n",
      "Epoch 2372/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1072.6805 - val_loss: 922.9679\n",
      "Epoch 2373/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.8280 - val_loss: 928.9695\n",
      "Epoch 2374/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.9498 - val_loss: 922.6970\n",
      "Epoch 2375/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.9649 - val_loss: 926.5166\n",
      "Epoch 2376/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1069.9404 - val_loss: 921.9952\n",
      "Epoch 2377/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1065.4836 - val_loss: 926.2481\n",
      "Epoch 2378/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.4897 - val_loss: 922.3113\n",
      "Epoch 2379/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1065.0023 - val_loss: 928.1332\n",
      "Epoch 2380/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.7544 - val_loss: 922.1255\n",
      "Epoch 2381/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1068.5079 - val_loss: 924.6525\n",
      "Epoch 2382/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.0501 - val_loss: 927.3282\n",
      "Epoch 2383/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.8980 - val_loss: 923.1843\n",
      "Epoch 2384/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1061.9158 - val_loss: 930.6534\n",
      "Epoch 2385/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1071.8583 - val_loss: 928.6614\n",
      "Epoch 2386/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1070.8950 - val_loss: 925.6654\n",
      "Epoch 2387/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1061.4124 - val_loss: 926.5463\n",
      "Epoch 2388/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.4502 - val_loss: 928.6906\n",
      "Epoch 2389/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1063.7439 - val_loss: 922.6822\n",
      "Epoch 2390/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1061.6584 - val_loss: 924.5687\n",
      "Epoch 2391/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1059.4969 - val_loss: 924.7150\n",
      "Epoch 2392/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1059.9909 - val_loss: 922.6299\n",
      "Epoch 2393/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1058.9539 - val_loss: 924.4121\n",
      "Epoch 2394/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1066.6404 - val_loss: 924.7488\n",
      "Epoch 2395/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.9543 - val_loss: 922.6003\n",
      "Epoch 2396/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1063.7151 - val_loss: 924.2657\n",
      "Epoch 2397/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1055.7238 - val_loss: 922.2114\n",
      "Epoch 2398/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1065.1091 - val_loss: 926.0529\n",
      "Epoch 2399/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1054.8573 - val_loss: 924.0142\n",
      "Epoch 2400/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.2880 - val_loss: 927.5814\n",
      "Epoch 2401/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1063.5527 - val_loss: 920.6141\n",
      "Epoch 2402/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1064.9411 - val_loss: 925.2145\n",
      "Epoch 2403/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.4830 - val_loss: 923.9694\n",
      "Epoch 2404/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1060.5514 - val_loss: 924.6544\n",
      "Epoch 2405/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1061.2799 - val_loss: 924.9343\n",
      "Epoch 2406/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1057.9263 - val_loss: 924.6324\n",
      "Epoch 2407/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.3460 - val_loss: 922.8684\n",
      "Epoch 2408/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1059.7150 - val_loss: 922.5099\n",
      "Epoch 2409/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1060.6617 - val_loss: 926.9365\n",
      "Epoch 2410/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.6581 - val_loss: 921.0877\n",
      "Epoch 2411/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.0743 - val_loss: 927.1346\n",
      "Epoch 2412/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1053.9382 - val_loss: 921.8982\n",
      "Epoch 2413/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1058.5508 - val_loss: 925.6631\n",
      "Epoch 2414/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1062.6293 - val_loss: 920.4868\n",
      "Epoch 2415/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1055.9386 - val_loss: 925.3567\n",
      "Epoch 2416/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.5928 - val_loss: 925.6245\n",
      "Epoch 2417/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1062.3888 - val_loss: 926.1610\n",
      "Epoch 2418/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.7649 - val_loss: 923.5024\n",
      "Epoch 2419/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1057.1283 - val_loss: 924.4722\n",
      "Epoch 2420/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1059.8737 - val_loss: 923.4740\n",
      "Epoch 2421/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1054.6338 - val_loss: 921.2706\n",
      "Epoch 2422/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1054.7936 - val_loss: 922.0459\n",
      "Epoch 2423/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1051.7513 - val_loss: 922.7965\n",
      "Epoch 2424/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1050.1821 - val_loss: 922.0099\n",
      "Epoch 2425/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1058.0625 - val_loss: 922.9512\n",
      "Epoch 2426/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1053.2102 - val_loss: 920.5686\n",
      "Epoch 2427/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1055.2556 - val_loss: 921.0484\n",
      "Epoch 2428/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1059.2087 - val_loss: 923.5790\n",
      "Epoch 2429/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1055.9196 - val_loss: 924.1741\n",
      "Epoch 2430/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1053.9573 - val_loss: 922.3210\n",
      "Epoch 2431/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1054.7361 - val_loss: 920.3259\n",
      "Epoch 2432/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1053.0398 - val_loss: 921.0171\n",
      "Epoch 2433/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1047.6535 - val_loss: 921.7090\n",
      "Epoch 2434/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1053.5047 - val_loss: 921.0304\n",
      "Epoch 2435/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1052.8846 - val_loss: 921.7021\n",
      "Epoch 2436/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1049.2136 - val_loss: 921.5022\n",
      "Epoch 2437/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.5941 - val_loss: 921.7532\n",
      "Epoch 2438/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1058.0524 - val_loss: 922.4752\n",
      "Epoch 2439/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.0837 - val_loss: 921.3170\n",
      "Epoch 2440/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.9820 - val_loss: 920.8013\n",
      "Epoch 2441/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.8648 - val_loss: 921.5522\n",
      "Epoch 2442/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1058.0685 - val_loss: 928.1447\n",
      "Epoch 2443/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1053.5347 - val_loss: 918.7983\n",
      "Epoch 2444/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.6564 - val_loss: 927.1600\n",
      "Epoch 2445/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1055.3896 - val_loss: 922.3761\n",
      "Epoch 2446/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1057.1074 - val_loss: 921.0976\n",
      "Epoch 2447/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1052.2293 - val_loss: 920.8763\n",
      "Epoch 2448/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1049.9111 - val_loss: 921.5368\n",
      "Epoch 2449/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1037.7566 - val_loss: 919.4240\n",
      "Epoch 2450/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1048.5597 - val_loss: 921.1024\n",
      "Epoch 2451/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.1265 - val_loss: 919.7043\n",
      "Epoch 2452/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1049.1522 - val_loss: 917.1521\n",
      "Epoch 2453/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1050.3918 - val_loss: 920.2480\n",
      "Epoch 2454/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.7357 - val_loss: 921.1479\n",
      "Epoch 2455/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1060.9415 - val_loss: 922.4916\n",
      "Epoch 2456/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1053.3478 - val_loss: 920.0034\n",
      "Epoch 2457/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1058.5220 - val_loss: 923.7773\n",
      "Epoch 2458/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.6287 - val_loss: 918.4943\n",
      "Epoch 2459/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1052.6501 - val_loss: 921.4092\n",
      "Epoch 2460/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1046.5694 - val_loss: 921.3435\n",
      "Epoch 2461/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.0018 - val_loss: 921.0765\n",
      "Epoch 2462/3000\n",
      "36515/36515 [==============================] - 0s 12us/sample - loss: 1050.0391 - val_loss: 916.8414\n",
      "Epoch 2463/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1048.4327 - val_loss: 921.9858\n",
      "Epoch 2464/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1056.6653 - val_loss: 920.0358\n",
      "Epoch 2465/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1053.3428 - val_loss: 921.5978\n",
      "Epoch 2466/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1041.1234 - val_loss: 917.0999\n",
      "Epoch 2467/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1047.1646 - val_loss: 923.7769\n",
      "Epoch 2468/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1052.2073 - val_loss: 917.2800\n",
      "Epoch 2469/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1054.3609 - val_loss: 919.0077\n",
      "Epoch 2470/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1054.1126 - val_loss: 919.9469\n",
      "Epoch 2471/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1047.5440 - val_loss: 919.6860\n",
      "Epoch 2472/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1044.4808 - val_loss: 915.1866\n",
      "Epoch 2473/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1040.1854 - val_loss: 925.6161\n",
      "Epoch 2474/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1048.5005 - val_loss: 914.1968\n",
      "Epoch 2475/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1057.6182 - val_loss: 924.4252\n",
      "Epoch 2476/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1049.0185 - val_loss: 917.6606\n",
      "Epoch 2477/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1050.6349 - val_loss: 922.1079\n",
      "Epoch 2478/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1052.0570 - val_loss: 917.9432\n",
      "Epoch 2479/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1040.9126 - val_loss: 917.9817\n",
      "Epoch 2480/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1043.0929 - val_loss: 917.1054\n",
      "Epoch 2481/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1043.5723 - val_loss: 917.0267\n",
      "Epoch 2482/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.6254 - val_loss: 919.2448\n",
      "Epoch 2483/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1048.2909 - val_loss: 915.7036\n",
      "Epoch 2484/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1048.9747 - val_loss: 919.9686\n",
      "Epoch 2485/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.1011 - val_loss: 916.7353\n",
      "Epoch 2486/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1046.9366 - val_loss: 918.1156\n",
      "Epoch 2487/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1043.2662 - val_loss: 916.0501\n",
      "Epoch 2488/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1035.3618 - val_loss: 916.8292\n",
      "Epoch 2489/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1048.1248 - val_loss: 920.8314\n",
      "Epoch 2490/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1047.3806 - val_loss: 918.8796\n",
      "Epoch 2491/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.7680 - val_loss: 920.9437\n",
      "Epoch 2492/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1048.9064 - val_loss: 916.0634\n",
      "Epoch 2493/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.1462 - val_loss: 917.9208\n",
      "Epoch 2494/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.7605 - val_loss: 919.8529\n",
      "Epoch 2495/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1041.1994 - val_loss: 915.6967\n",
      "Epoch 2496/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1047.1209 - val_loss: 923.3854\n",
      "Epoch 2497/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1041.4042 - val_loss: 917.1046\n",
      "Epoch 2498/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.7076 - val_loss: 920.9417\n",
      "Epoch 2499/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1050.9567 - val_loss: 916.3010\n",
      "Epoch 2500/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1037.9523 - val_loss: 920.9844\n",
      "Epoch 2501/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.0071 - val_loss: 919.3909\n",
      "Epoch 2502/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1049.7573 - val_loss: 918.5946\n",
      "Epoch 2503/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1052.6119 - val_loss: 917.8362\n",
      "Epoch 2504/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1035.0647 - val_loss: 918.9034\n",
      "Epoch 2505/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1047.1870 - val_loss: 915.6257\n",
      "Epoch 2506/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.1860 - val_loss: 919.2726\n",
      "Epoch 2507/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1046.6845 - val_loss: 918.2719\n",
      "Epoch 2508/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.6411 - val_loss: 915.7026\n",
      "Epoch 2509/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.2974 - val_loss: 917.3159\n",
      "Epoch 2510/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.0065 - val_loss: 916.8865\n",
      "Epoch 2511/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1032.9555 - val_loss: 918.0610\n",
      "Epoch 2512/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.9132 - val_loss: 917.0560\n",
      "Epoch 2513/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.9428 - val_loss: 920.0831\n",
      "Epoch 2514/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.5964 - val_loss: 914.9709\n",
      "Epoch 2515/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.8412 - val_loss: 920.4609\n",
      "Epoch 2516/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.3776 - val_loss: 914.2217\n",
      "Epoch 2517/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.9280 - val_loss: 916.4135\n",
      "Epoch 2518/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.6859 - val_loss: 916.4615\n",
      "Epoch 2519/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.8186 - val_loss: 915.1153\n",
      "Epoch 2520/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.9805 - val_loss: 915.0618\n",
      "Epoch 2521/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.8910 - val_loss: 916.3625\n",
      "Epoch 2522/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.3282 - val_loss: 917.1691\n",
      "Epoch 2523/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1042.9169 - val_loss: 914.0610\n",
      "Epoch 2524/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1045.3513 - val_loss: 917.2637\n",
      "Epoch 2525/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1030.4878 - val_loss: 916.7092\n",
      "Epoch 2526/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.8762 - val_loss: 917.3210\n",
      "Epoch 2527/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1050.4058 - val_loss: 916.6188\n",
      "Epoch 2528/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1043.8356 - val_loss: 913.8487\n",
      "Epoch 2529/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1040.4724 - val_loss: 916.6729\n",
      "Epoch 2530/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1036.0473 - val_loss: 916.7017\n",
      "Epoch 2531/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.7360 - val_loss: 914.0637\n",
      "Epoch 2532/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1040.2064 - val_loss: 921.1326\n",
      "Epoch 2533/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1036.5892 - val_loss: 916.8181\n",
      "Epoch 2534/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.0319 - val_loss: 915.9919\n",
      "Epoch 2535/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.3698 - val_loss: 916.4293\n",
      "Epoch 2536/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1046.6816 - val_loss: 915.6264\n",
      "Epoch 2537/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1046.6747 - val_loss: 921.1731\n",
      "Epoch 2538/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.9821 - val_loss: 920.3413\n",
      "Epoch 2539/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1045.5099 - val_loss: 919.2106\n",
      "Epoch 2540/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1041.3598 - val_loss: 918.9336\n",
      "Epoch 2541/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1040.7377 - val_loss: 914.7559\n",
      "Epoch 2542/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.3011 - val_loss: 916.6976\n",
      "Epoch 2543/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.3664 - val_loss: 918.2427\n",
      "Epoch 2544/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.3149 - val_loss: 921.1667\n",
      "Epoch 2545/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1048.8409 - val_loss: 915.2142\n",
      "Epoch 2546/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.4188 - val_loss: 925.2528\n",
      "Epoch 2547/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1046.7570 - val_loss: 916.3544\n",
      "Epoch 2548/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.0816 - val_loss: 914.6728\n",
      "Epoch 2549/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1053.8698 - val_loss: 917.7184\n",
      "Epoch 2550/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.4537 - val_loss: 918.9662\n",
      "Epoch 2551/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1047.1681 - val_loss: 918.2338\n",
      "Epoch 2552/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1041.7483 - val_loss: 917.3190\n",
      "Epoch 2553/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.3334 - val_loss: 919.1489\n",
      "Epoch 2554/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.8668 - val_loss: 917.0708\n",
      "Epoch 2555/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1033.1313 - val_loss: 917.3801\n",
      "Epoch 2556/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.3278 - val_loss: 917.2689\n",
      "Epoch 2557/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1033.0620 - val_loss: 914.8198\n",
      "Epoch 2558/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.4239 - val_loss: 917.5153\n",
      "Epoch 2559/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1031.3330 - val_loss: 911.5193\n",
      "Epoch 2560/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1026.0932 - val_loss: 915.1042\n",
      "Epoch 2561/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1033.0844 - val_loss: 915.6151\n",
      "Epoch 2562/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.3847 - val_loss: 915.3358\n",
      "Epoch 2563/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.5079 - val_loss: 913.9466\n",
      "Epoch 2564/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.0894 - val_loss: 915.8384\n",
      "Epoch 2565/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1040.5598 - val_loss: 911.0309\n",
      "Epoch 2566/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1042.8837 - val_loss: 917.7645\n",
      "Epoch 2567/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1031.0294 - val_loss: 915.2773\n",
      "Epoch 2568/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1032.7371 - val_loss: 912.3161\n",
      "Epoch 2569/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1035.1504 - val_loss: 920.0493\n",
      "Epoch 2570/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1036.1108 - val_loss: 911.1729\n",
      "Epoch 2571/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.2320 - val_loss: 915.5482\n",
      "Epoch 2572/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1031.0632 - val_loss: 912.7931\n",
      "Epoch 2573/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.3793 - val_loss: 913.0093\n",
      "Epoch 2574/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1032.1968 - val_loss: 915.6834\n",
      "Epoch 2575/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1033.5017 - val_loss: 916.1144\n",
      "Epoch 2576/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.6508 - val_loss: 912.3676\n",
      "Epoch 2577/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1042.9433 - val_loss: 920.9350\n",
      "Epoch 2578/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.0324 - val_loss: 912.7842\n",
      "Epoch 2579/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1030.2665 - val_loss: 918.9174\n",
      "Epoch 2580/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1036.5181 - val_loss: 915.8917\n",
      "Epoch 2581/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1033.1258 - val_loss: 916.0790\n",
      "Epoch 2582/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1032.3099 - val_loss: 919.2855\n",
      "Epoch 2583/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1031.2845 - val_loss: 912.9363\n",
      "Epoch 2584/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1040.2269 - val_loss: 918.7296\n",
      "Epoch 2585/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1031.2875 - val_loss: 913.2789\n",
      "Epoch 2586/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1026.9354 - val_loss: 915.2165\n",
      "Epoch 2587/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.4702 - val_loss: 914.4311\n",
      "Epoch 2588/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.4678 - val_loss: 916.3143\n",
      "Epoch 2589/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1027.1796 - val_loss: 914.8347\n",
      "Epoch 2590/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1030.6203 - val_loss: 909.4700\n",
      "Epoch 2591/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1040.0589 - val_loss: 917.7990\n",
      "Epoch 2592/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1029.3772 - val_loss: 912.5016\n",
      "Epoch 2593/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1037.6707 - val_loss: 917.6134\n",
      "Epoch 2594/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1041.8818 - val_loss: 914.9701\n",
      "Epoch 2595/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1031.8926 - val_loss: 917.0356\n",
      "Epoch 2596/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1037.2143 - val_loss: 910.4339\n",
      "Epoch 2597/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1035.5792 - val_loss: 918.5378\n",
      "Epoch 2598/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1036.2212 - val_loss: 915.5912\n",
      "Epoch 2599/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.6799 - val_loss: 913.0228\n",
      "Epoch 2600/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1035.1650 - val_loss: 914.0110\n",
      "Epoch 2601/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1040.8281 - val_loss: 915.7073\n",
      "Epoch 2602/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1044.0624 - val_loss: 910.8916\n",
      "Epoch 2603/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1037.1996 - val_loss: 915.6171\n",
      "Epoch 2604/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.2451 - val_loss: 914.6558\n",
      "Epoch 2605/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1032.5390 - val_loss: 910.8600\n",
      "Epoch 2606/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1039.8631 - val_loss: 916.0525\n",
      "Epoch 2607/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1029.7515 - val_loss: 912.9457\n",
      "Epoch 2608/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.1775 - val_loss: 911.7775\n",
      "Epoch 2609/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.5803 - val_loss: 909.8098\n",
      "Epoch 2610/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1035.4212 - val_loss: 915.3842\n",
      "Epoch 2611/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1031.5491 - val_loss: 912.0148\n",
      "Epoch 2612/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.2745 - val_loss: 913.0931\n",
      "Epoch 2613/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1030.1121 - val_loss: 909.9927\n",
      "Epoch 2614/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1029.0671 - val_loss: 913.2802\n",
      "Epoch 2615/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.0514 - val_loss: 913.2336\n",
      "Epoch 2616/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.8214 - val_loss: 911.4092\n",
      "Epoch 2617/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.3552 - val_loss: 913.2625\n",
      "Epoch 2618/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.2501 - val_loss: 911.8611\n",
      "Epoch 2619/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.6216 - val_loss: 916.1721\n",
      "Epoch 2620/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1029.7318 - val_loss: 911.0519\n",
      "Epoch 2621/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1029.7804 - val_loss: 918.1652\n",
      "Epoch 2622/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1030.1755 - val_loss: 910.8733\n",
      "Epoch 2623/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1030.8523 - val_loss: 912.7075\n",
      "Epoch 2624/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.6869 - val_loss: 910.9363\n",
      "Epoch 2625/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.8636 - val_loss: 912.0643\n",
      "Epoch 2626/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1021.7610 - val_loss: 911.2177\n",
      "Epoch 2627/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.2059 - val_loss: 916.6945\n",
      "Epoch 2628/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1020.1946 - val_loss: 908.9974\n",
      "Epoch 2629/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1021.4044 - val_loss: 914.7321\n",
      "Epoch 2630/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 1022.0471 - val_loss: 907.1053\n",
      "Epoch 2631/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1045.1709 - val_loss: 916.6307\n",
      "Epoch 2632/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.2082 - val_loss: 910.7091\n",
      "Epoch 2633/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.4450 - val_loss: 911.0795\n",
      "Epoch 2634/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.6919 - val_loss: 910.0994\n",
      "Epoch 2635/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.1537 - val_loss: 910.3271\n",
      "Epoch 2636/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1029.0988 - val_loss: 913.7798\n",
      "Epoch 2637/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1027.6768 - val_loss: 911.7916\n",
      "Epoch 2638/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1013.0236 - val_loss: 910.7677\n",
      "Epoch 2639/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1026.3138 - val_loss: 910.3035\n",
      "Epoch 2640/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1038.6579 - val_loss: 915.3397\n",
      "Epoch 2641/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1026.6685 - val_loss: 911.5239\n",
      "Epoch 2642/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.2459 - val_loss: 915.7232\n",
      "Epoch 2643/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.4677 - val_loss: 908.8112\n",
      "Epoch 2644/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.1686 - val_loss: 909.7074\n",
      "Epoch 2645/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.6776 - val_loss: 910.0356\n",
      "Epoch 2646/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.0900 - val_loss: 910.4767\n",
      "Epoch 2647/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1030.6658 - val_loss: 908.2000\n",
      "Epoch 2648/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.8486 - val_loss: 911.1888\n",
      "Epoch 2649/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.3429 - val_loss: 910.8058\n",
      "Epoch 2650/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.5188 - val_loss: 912.7713\n",
      "Epoch 2651/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.0113 - val_loss: 917.1943\n",
      "Epoch 2652/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1027.7644 - val_loss: 908.5894\n",
      "Epoch 2653/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.6018 - val_loss: 911.8733\n",
      "Epoch 2654/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.3131 - val_loss: 911.4111\n",
      "Epoch 2655/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.8263 - val_loss: 913.6261\n",
      "Epoch 2656/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1035.9251 - val_loss: 909.3958\n",
      "Epoch 2657/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1020.2361 - val_loss: 911.5240\n",
      "Epoch 2658/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.6648 - val_loss: 910.7383\n",
      "Epoch 2659/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.9529 - val_loss: 911.4494\n",
      "Epoch 2660/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.6427 - val_loss: 914.0570\n",
      "Epoch 2661/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.6161 - val_loss: 909.5882\n",
      "Epoch 2662/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.3787 - val_loss: 912.5417\n",
      "Epoch 2663/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.7545 - val_loss: 910.3770\n",
      "Epoch 2664/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1021.9609 - val_loss: 911.3699\n",
      "Epoch 2665/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1026.0060 - val_loss: 913.7775\n",
      "Epoch 2666/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1026.1053 - val_loss: 910.3087\n",
      "Epoch 2667/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.5069 - val_loss: 910.2009\n",
      "Epoch 2668/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.2163 - val_loss: 914.2684\n",
      "Epoch 2669/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1026.8069 - val_loss: 909.2294\n",
      "Epoch 2670/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.0591 - val_loss: 913.6466\n",
      "Epoch 2671/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.3958 - val_loss: 911.4991\n",
      "Epoch 2672/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.8936 - val_loss: 912.4521\n",
      "Epoch 2673/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.3027 - val_loss: 910.1395\n",
      "Epoch 2674/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1024.6073 - val_loss: 913.1491\n",
      "Epoch 2675/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1019.2861 - val_loss: 905.0945\n",
      "Epoch 2676/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1021.8986 - val_loss: 910.4155\n",
      "Epoch 2677/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1031.2522 - val_loss: 910.7909\n",
      "Epoch 2678/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.8212 - val_loss: 911.0026\n",
      "Epoch 2679/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1020.9656 - val_loss: 911.1050\n",
      "Epoch 2680/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1027.3308 - val_loss: 912.2501\n",
      "Epoch 2681/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.4225 - val_loss: 910.4242\n",
      "Epoch 2682/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1034.5453 - val_loss: 911.6024\n",
      "Epoch 2683/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.8460 - val_loss: 909.5475\n",
      "Epoch 2684/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.0004 - val_loss: 912.7601\n",
      "Epoch 2685/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1027.1547 - val_loss: 912.2245\n",
      "Epoch 2686/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.2549 - val_loss: 911.4183\n",
      "Epoch 2687/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1007.1077 - val_loss: 908.7460\n",
      "Epoch 2688/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.0363 - val_loss: 910.6375\n",
      "Epoch 2689/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.8016 - val_loss: 911.4930\n",
      "Epoch 2690/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.5441 - val_loss: 915.6068\n",
      "Epoch 2691/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1020.9535 - val_loss: 909.0742\n",
      "Epoch 2692/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1017.8687 - val_loss: 908.4382\n",
      "Epoch 2693/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.6667 - val_loss: 909.2373\n",
      "Epoch 2694/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.4880 - val_loss: 909.4956\n",
      "Epoch 2695/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.7753 - val_loss: 909.1992\n",
      "Epoch 2696/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1010.8168 - val_loss: 907.4512\n",
      "Epoch 2697/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.5545 - val_loss: 909.1943\n",
      "Epoch 2698/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.1235 - val_loss: 909.5741\n",
      "Epoch 2699/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.8385 - val_loss: 909.7217\n",
      "Epoch 2700/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1010.7726 - val_loss: 910.4460\n",
      "Epoch 2701/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1014.0377 - val_loss: 911.2235\n",
      "Epoch 2702/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.8590 - val_loss: 908.2575\n",
      "Epoch 2703/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.2697 - val_loss: 906.1092\n",
      "Epoch 2704/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1014.6950 - val_loss: 910.0019\n",
      "Epoch 2705/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.1841 - val_loss: 905.4941\n",
      "Epoch 2706/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1009.5715 - val_loss: 911.0069\n",
      "Epoch 2707/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1017.5981 - val_loss: 907.0106\n",
      "Epoch 2708/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1021.9886 - val_loss: 907.1818\n",
      "Epoch 2709/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1014.6561 - val_loss: 912.6583\n",
      "Epoch 2710/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.7290 - val_loss: 905.8698\n",
      "Epoch 2711/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.1483 - val_loss: 908.6753\n",
      "Epoch 2712/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.3803 - val_loss: 906.8815\n",
      "Epoch 2713/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.0519 - val_loss: 906.9741\n",
      "Epoch 2714/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.5501 - val_loss: 911.1182\n",
      "Epoch 2715/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1020.9316 - val_loss: 911.2938\n",
      "Epoch 2716/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1020.6117 - val_loss: 908.1683\n",
      "Epoch 2717/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1022.2603 - val_loss: 913.5936\n",
      "Epoch 2718/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1013.9777 - val_loss: 910.0353\n",
      "Epoch 2719/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.5600 - val_loss: 908.3586\n",
      "Epoch 2720/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1021.7595 - val_loss: 907.8203\n",
      "Epoch 2721/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.0745 - val_loss: 914.2903\n",
      "Epoch 2722/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1017.1548 - val_loss: 906.6740\n",
      "Epoch 2723/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.1515 - val_loss: 905.6161\n",
      "Epoch 2724/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1020.3373 - val_loss: 908.2401\n",
      "Epoch 2725/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1009.9424 - val_loss: 908.7805\n",
      "Epoch 2726/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1021.6030 - val_loss: 910.7783\n",
      "Epoch 2727/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.3861 - val_loss: 905.7133\n",
      "Epoch 2728/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.9742 - val_loss: 908.5674\n",
      "Epoch 2729/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1017.5365 - val_loss: 909.7370\n",
      "Epoch 2730/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1008.9059 - val_loss: 905.8260\n",
      "Epoch 2731/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1010.7972 - val_loss: 909.2735\n",
      "Epoch 2732/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.0656 - val_loss: 909.0012\n",
      "Epoch 2733/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.0982 - val_loss: 908.6763\n",
      "Epoch 2734/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.2100 - val_loss: 905.1620\n",
      "Epoch 2735/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.9526 - val_loss: 911.0079\n",
      "Epoch 2736/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1005.0991 - val_loss: 906.9548\n",
      "Epoch 2737/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.0305 - val_loss: 911.1770\n",
      "Epoch 2738/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.3978 - val_loss: 905.5432\n",
      "Epoch 2739/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1010.5316 - val_loss: 907.0347\n",
      "Epoch 2740/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1023.1488 - val_loss: 912.6104\n",
      "Epoch 2741/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1013.5381 - val_loss: 905.4114\n",
      "Epoch 2742/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.7321 - val_loss: 910.4627\n",
      "Epoch 2743/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1013.4458 - val_loss: 908.0797\n",
      "Epoch 2744/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.9065 - val_loss: 908.5600\n",
      "Epoch 2745/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.1784 - val_loss: 908.2120\n",
      "Epoch 2746/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1020.2288 - val_loss: 904.1964\n",
      "Epoch 2747/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1009.0222 - val_loss: 906.4338\n",
      "Epoch 2748/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.6538 - val_loss: 905.2055\n",
      "Epoch 2749/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1010.8597 - val_loss: 906.9245\n",
      "Epoch 2750/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.0464 - val_loss: 906.0180\n",
      "Epoch 2751/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1028.9840 - val_loss: 907.1181\n",
      "Epoch 2752/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.1388 - val_loss: 909.1308\n",
      "Epoch 2753/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.6522 - val_loss: 907.3546\n",
      "Epoch 2754/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.4632 - val_loss: 910.5536\n",
      "Epoch 2755/3000\n",
      "36515/36515 [==============================] - 0s 8us/sample - loss: 1005.0341 - val_loss: 902.9756\n",
      "Epoch 2756/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1009.6828 - val_loss: 912.7811\n",
      "Epoch 2757/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1016.0111 - val_loss: 903.5526\n",
      "Epoch 2758/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.3689 - val_loss: 912.5524\n",
      "Epoch 2759/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.3766 - val_loss: 904.7457\n",
      "Epoch 2760/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1016.3488 - val_loss: 907.6052\n",
      "Epoch 2761/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.9331 - val_loss: 906.7448\n",
      "Epoch 2762/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1009.4616 - val_loss: 904.7328\n",
      "Epoch 2763/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.3623 - val_loss: 904.1396\n",
      "Epoch 2764/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.7930 - val_loss: 908.3563\n",
      "Epoch 2765/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1013.7301 - val_loss: 905.1424\n",
      "Epoch 2766/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.9197 - val_loss: 910.7926\n",
      "Epoch 2767/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.2020 - val_loss: 908.7056\n",
      "Epoch 2768/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.0718 - val_loss: 904.5381\n",
      "Epoch 2769/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1014.2417 - val_loss: 908.4908\n",
      "Epoch 2770/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.4376 - val_loss: 905.5136\n",
      "Epoch 2771/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1020.8406 - val_loss: 911.0953\n",
      "Epoch 2772/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1018.3699 - val_loss: 908.1783\n",
      "Epoch 2773/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.2716 - val_loss: 904.9824\n",
      "Epoch 2774/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.7162 - val_loss: 905.4281\n",
      "Epoch 2775/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1015.6605 - val_loss: 911.8706\n",
      "Epoch 2776/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.2098 - val_loss: 903.6572\n",
      "Epoch 2777/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1021.2533 - val_loss: 910.6476\n",
      "Epoch 2778/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.4640 - val_loss: 904.6357\n",
      "Epoch 2779/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.6000 - val_loss: 907.5314\n",
      "Epoch 2780/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.5911 - val_loss: 906.1647\n",
      "Epoch 2781/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1013.2000 - val_loss: 904.0719\n",
      "Epoch 2782/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1010.1583 - val_loss: 904.8593\n",
      "Epoch 2783/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.8920 - val_loss: 905.6183\n",
      "Epoch 2784/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.9269 - val_loss: 907.7329\n",
      "Epoch 2785/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.0527 - val_loss: 904.7684\n",
      "Epoch 2786/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1019.0591 - val_loss: 907.3651\n",
      "Epoch 2787/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1008.7464 - val_loss: 904.6790\n",
      "Epoch 2788/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.2853 - val_loss: 906.7805\n",
      "Epoch 2789/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1025.7309 - val_loss: 906.8047\n",
      "Epoch 2790/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 992.4053 - val_loss: 904.6781\n",
      "Epoch 2791/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1008.2573 - val_loss: 905.0154\n",
      "Epoch 2792/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1006.0028 - val_loss: 906.4539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2793/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 998.3036 - val_loss: 906.5278\n",
      "Epoch 2794/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.3788 - val_loss: 907.4447\n",
      "Epoch 2795/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1017.5054 - val_loss: 905.5933\n",
      "Epoch 2796/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.7396 - val_loss: 905.5454\n",
      "Epoch 2797/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.4817 - val_loss: 906.7516\n",
      "Epoch 2798/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.6100 - val_loss: 905.9419\n",
      "Epoch 2799/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1013.6150 - val_loss: 903.0598\n",
      "Epoch 2800/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.9322 - val_loss: 907.3558\n",
      "Epoch 2801/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1005.1184 - val_loss: 904.7840\n",
      "Epoch 2802/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.6200 - val_loss: 907.3098\n",
      "Epoch 2803/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.3898 - val_loss: 905.3922\n",
      "Epoch 2804/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.7477 - val_loss: 903.7901\n",
      "Epoch 2805/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1008.2113 - val_loss: 903.2026\n",
      "Epoch 2806/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 996.0046 - val_loss: 903.4699\n",
      "Epoch 2807/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1006.4430 - val_loss: 907.2363\n",
      "Epoch 2808/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.5241 - val_loss: 907.6185\n",
      "Epoch 2809/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.7045 - val_loss: 903.4937\n",
      "Epoch 2810/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.6586 - val_loss: 905.0741\n",
      "Epoch 2811/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 1012.4697 - val_loss: 901.5325\n",
      "Epoch 2812/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1005.9932 - val_loss: 903.9432\n",
      "Epoch 2813/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1010.7717 - val_loss: 905.8453\n",
      "Epoch 2814/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1005.2522 - val_loss: 904.5239\n",
      "Epoch 2815/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.3473 - val_loss: 905.6045\n",
      "Epoch 2816/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1005.7413 - val_loss: 903.3059\n",
      "Epoch 2817/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1008.3447 - val_loss: 906.3306\n",
      "Epoch 2818/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.1767 - val_loss: 904.8729\n",
      "Epoch 2819/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1009.2798 - val_loss: 906.9633\n",
      "Epoch 2820/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.3056 - val_loss: 904.0312\n",
      "Epoch 2821/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.3573 - val_loss: 904.3208\n",
      "Epoch 2822/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.9761 - val_loss: 902.6003\n",
      "Epoch 2823/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.5104 - val_loss: 907.2894\n",
      "Epoch 2824/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.5857 - val_loss: 904.1171\n",
      "Epoch 2825/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1005.1572 - val_loss: 903.4097\n",
      "Epoch 2826/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.6195 - val_loss: 904.0918\n",
      "Epoch 2827/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.3152 - val_loss: 904.0372\n",
      "Epoch 2828/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.5800 - val_loss: 902.5062\n",
      "Epoch 2829/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.6546 - val_loss: 904.5815\n",
      "Epoch 2830/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.2763 - val_loss: 906.1702\n",
      "Epoch 2831/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1007.2391 - val_loss: 904.0017\n",
      "Epoch 2832/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1000.7713 - val_loss: 905.2003\n",
      "Epoch 2833/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.0465 - val_loss: 901.6647\n",
      "Epoch 2834/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.9343 - val_loss: 909.3329\n",
      "Epoch 2835/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.0954 - val_loss: 904.1092\n",
      "Epoch 2836/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.2742 - val_loss: 905.7480\n",
      "Epoch 2837/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.7921 - val_loss: 902.2642\n",
      "Epoch 2838/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.3543 - val_loss: 906.0220\n",
      "Epoch 2839/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.1997 - val_loss: 906.0844\n",
      "Epoch 2840/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1006.7340 - val_loss: 902.2236\n",
      "Epoch 2841/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.8256 - val_loss: 905.2240\n",
      "Epoch 2842/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1000.9754 - val_loss: 909.1086\n",
      "Epoch 2843/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1000.7551 - val_loss: 906.0822\n",
      "Epoch 2844/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.1166 - val_loss: 903.3607\n",
      "Epoch 2845/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.5820 - val_loss: 906.2778\n",
      "Epoch 2846/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.2429 - val_loss: 903.6680\n",
      "Epoch 2847/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 993.2872 - val_loss: 904.1077\n",
      "Epoch 2848/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.3352 - val_loss: 907.5247\n",
      "Epoch 2849/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1000.2990 - val_loss: 903.1432\n",
      "Epoch 2850/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.6181 - val_loss: 902.9274\n",
      "Epoch 2851/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.2733 - val_loss: 905.1986\n",
      "Epoch 2852/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 999.5066 - val_loss: 901.4678\n",
      "Epoch 2853/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 998.6055 - val_loss: 905.2146\n",
      "Epoch 2854/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 1001.5531 - val_loss: 899.0287\n",
      "Epoch 2855/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1003.1903 - val_loss: 907.9678\n",
      "Epoch 2856/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.0717 - val_loss: 906.8208\n",
      "Epoch 2857/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.1659 - val_loss: 902.2829\n",
      "Epoch 2858/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.0537 - val_loss: 900.3350\n",
      "Epoch 2859/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1005.6815 - val_loss: 903.4094\n",
      "Epoch 2860/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.1026 - val_loss: 903.0031\n",
      "Epoch 2861/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1011.7887 - val_loss: 905.2521\n",
      "Epoch 2862/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1012.4608 - val_loss: 904.9707\n",
      "Epoch 2863/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.9398 - val_loss: 907.5684\n",
      "Epoch 2864/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.8498 - val_loss: 902.1845\n",
      "Epoch 2865/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1008.1792 - val_loss: 905.9127\n",
      "Epoch 2866/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.9061 - val_loss: 904.1252\n",
      "Epoch 2867/3000\n",
      "36515/36515 [==============================] - 0s 13us/sample - loss: 994.4423 - val_loss: 898.4020\n",
      "Epoch 2868/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1005.7751 - val_loss: 910.5919\n",
      "Epoch 2869/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1004.2402 - val_loss: 902.7388\n",
      "Epoch 2870/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1007.0063 - val_loss: 909.3511\n",
      "Epoch 2871/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 998.9842 - val_loss: 905.3425\n",
      "Epoch 2872/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 996.4410 - val_loss: 902.6569\n",
      "Epoch 2873/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1000.7157 - val_loss: 904.0697\n",
      "Epoch 2874/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1008.4170 - val_loss: 902.8413\n",
      "Epoch 2875/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.7611 - val_loss: 908.5632\n",
      "Epoch 2876/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 991.2130 - val_loss: 904.1099\n",
      "Epoch 2877/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 993.1003 - val_loss: 904.2970\n",
      "Epoch 2878/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 1008.3596 - val_loss: 904.7882\n",
      "Epoch 2879/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1000.6751 - val_loss: 905.8727\n",
      "Epoch 2880/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.7342 - val_loss: 900.1050\n",
      "Epoch 2881/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.7284 - val_loss: 904.8635\n",
      "Epoch 2882/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1006.5439 - val_loss: 899.3938\n",
      "Epoch 2883/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.2863 - val_loss: 906.4293\n",
      "Epoch 2884/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1003.1279 - val_loss: 900.4988\n",
      "Epoch 2885/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.6030 - val_loss: 905.2185\n",
      "Epoch 2886/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.9371 - val_loss: 903.5612\n",
      "Epoch 2887/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 999.2915 - val_loss: 902.8737\n",
      "Epoch 2888/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.9836 - val_loss: 900.6949\n",
      "Epoch 2889/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.7107 - val_loss: 903.8376\n",
      "Epoch 2890/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 997.7000 - val_loss: 906.5664\n",
      "Epoch 2891/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.2312 - val_loss: 901.9408\n",
      "Epoch 2892/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 993.5835 - val_loss: 901.9981\n",
      "Epoch 2893/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.9750 - val_loss: 903.2632\n",
      "Epoch 2894/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 996.3144 - val_loss: 899.5632\n",
      "Epoch 2895/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 996.7059 - val_loss: 905.4005\n",
      "Epoch 2896/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.2920 - val_loss: 902.4332\n",
      "Epoch 2897/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.7204 - val_loss: 902.0003\n",
      "Epoch 2898/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1000.8033 - val_loss: 906.9351\n",
      "Epoch 2899/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.3843 - val_loss: 903.4963\n",
      "Epoch 2900/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 984.8962 - val_loss: 900.9166\n",
      "Epoch 2901/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 998.8778 - val_loss: 902.7365\n",
      "Epoch 2902/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.2267 - val_loss: 905.1776\n",
      "Epoch 2903/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.2801 - val_loss: 904.7996\n",
      "Epoch 2904/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.9618 - val_loss: 903.2589\n",
      "Epoch 2905/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.7322 - val_loss: 903.5099\n",
      "Epoch 2906/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.2696 - val_loss: 904.5205\n",
      "Epoch 2907/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1008.2288 - val_loss: 903.7668\n",
      "Epoch 2908/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.2402 - val_loss: 908.9390\n",
      "Epoch 2909/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 996.0411 - val_loss: 902.7655\n",
      "Epoch 2910/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.9457 - val_loss: 902.6544\n",
      "Epoch 2911/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.4168 - val_loss: 902.3323\n",
      "Epoch 2912/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.7728 - val_loss: 903.1545\n",
      "Epoch 2913/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.6367 - val_loss: 902.4664\n",
      "Epoch 2914/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 981.3872 - val_loss: 902.5708\n",
      "Epoch 2915/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 992.4935 - val_loss: 904.3760\n",
      "Epoch 2916/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.0685 - val_loss: 902.9991\n",
      "Epoch 2917/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1001.4869 - val_loss: 902.9783\n",
      "Epoch 2918/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 993.1712 - val_loss: 902.8603\n",
      "Epoch 2919/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.1540 - val_loss: 898.7327\n",
      "Epoch 2920/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 986.5505 - val_loss: 900.0363\n",
      "Epoch 2921/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 993.8763 - val_loss: 900.0927\n",
      "Epoch 2922/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.8053 - val_loss: 905.3828\n",
      "Epoch 2923/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.9437 - val_loss: 898.9966\n",
      "Epoch 2924/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 990.2602 - val_loss: 903.4163\n",
      "Epoch 2925/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.3220 - val_loss: 902.5670\n",
      "Epoch 2926/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 995.4608 - val_loss: 903.6685\n",
      "Epoch 2927/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.8745 - val_loss: 901.3985\n",
      "Epoch 2928/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.0812 - val_loss: 901.4098\n",
      "Epoch 2929/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 980.9016 - val_loss: 906.5674\n",
      "Epoch 2930/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.9585 - val_loss: 905.4252\n",
      "Epoch 2931/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 993.7863 - val_loss: 898.7297\n",
      "Epoch 2932/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 992.3075 - val_loss: 910.2583\n",
      "Epoch 2933/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.1535 - val_loss: 899.6614\n",
      "Epoch 2934/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.8133 - val_loss: 904.0439\n",
      "Epoch 2935/3000\n",
      "36515/36515 [==============================] - 0s 11us/sample - loss: 978.1758 - val_loss: 898.2862\n",
      "Epoch 2936/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 982.9285 - val_loss: 903.9849\n",
      "Epoch 2937/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 985.9441 - val_loss: 900.3877\n",
      "Epoch 2938/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 990.9548 - val_loss: 899.5269\n",
      "Epoch 2939/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.8582 - val_loss: 899.8051\n",
      "Epoch 2940/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.4124 - val_loss: 900.7168\n",
      "Epoch 2941/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 987.4385 - val_loss: 904.3959\n",
      "Epoch 2942/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.8052 - val_loss: 900.7770\n",
      "Epoch 2943/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.2522 - val_loss: 899.1074\n",
      "Epoch 2944/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.9813 - val_loss: 902.4630\n",
      "Epoch 2945/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.1167 - val_loss: 898.4059\n",
      "Epoch 2946/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 982.8354 - val_loss: 902.4044\n",
      "Epoch 2947/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.5412 - val_loss: 902.3538\n",
      "Epoch 2948/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 990.9795 - val_loss: 901.5119\n",
      "Epoch 2949/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 996.4988 - val_loss: 907.9116\n",
      "Epoch 2950/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 998.1453 - val_loss: 907.0656\n",
      "Epoch 2951/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 999.3322 - val_loss: 901.3895\n",
      "Epoch 2952/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 985.7155 - val_loss: 899.3729\n",
      "Epoch 2953/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 987.8786 - val_loss: 898.6765\n",
      "Epoch 2954/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 987.6875 - val_loss: 903.2805\n",
      "Epoch 2955/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 984.5020 - val_loss: 900.7283\n",
      "Epoch 2956/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.8969 - val_loss: 905.1747\n",
      "Epoch 2957/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 987.5303 - val_loss: 905.5024\n",
      "Epoch 2958/3000\n",
      "36515/36515 [==============================] - 0s 10us/sample - loss: 990.5712 - val_loss: 896.2109\n",
      "Epoch 2959/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 1002.2633 - val_loss: 906.5111\n",
      "Epoch 2960/3000\n",
      "36515/36515 [==============================] - 0s 2us/sample - loss: 989.6146 - val_loss: 897.9726\n",
      "Epoch 2961/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 982.4612 - val_loss: 902.4133\n",
      "Epoch 2962/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 992.7917 - val_loss: 902.8901\n",
      "Epoch 2963/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 984.6483 - val_loss: 901.2929\n",
      "Epoch 2964/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 979.7814 - val_loss: 896.2391\n",
      "Epoch 2965/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.9926 - val_loss: 900.3928\n",
      "Epoch 2966/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.2176 - val_loss: 901.0615\n",
      "Epoch 2967/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.4998 - val_loss: 901.8179\n",
      "Epoch 2968/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 997.8666 - val_loss: 900.4604\n",
      "Epoch 2969/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 985.5603 - val_loss: 899.1854\n",
      "Epoch 2970/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 991.4126 - val_loss: 898.5568\n",
      "Epoch 2971/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 979.5370 - val_loss: 902.3571\n",
      "Epoch 2972/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 980.4433 - val_loss: 899.7797\n",
      "Epoch 2973/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.7941 - val_loss: 900.7190\n",
      "Epoch 2974/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 994.8664 - val_loss: 903.2647\n",
      "Epoch 2975/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 984.3779 - val_loss: 898.5197\n",
      "Epoch 2976/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 975.2856 - val_loss: 900.9199\n",
      "Epoch 2977/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.8985 - val_loss: 898.9990\n",
      "Epoch 2978/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.1697 - val_loss: 903.6540\n",
      "Epoch 2979/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 990.7333 - val_loss: 900.0733\n",
      "Epoch 2980/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 987.0342 - val_loss: 900.0214\n",
      "Epoch 2981/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 978.1490 - val_loss: 899.1409\n",
      "Epoch 2982/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 982.0268 - val_loss: 901.2715\n",
      "Epoch 2983/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.3777 - val_loss: 899.4044\n",
      "Epoch 2984/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 996.4241 - val_loss: 902.7927\n",
      "Epoch 2985/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 993.4447 - val_loss: 900.9777\n",
      "Epoch 2986/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.7637 - val_loss: 898.0638\n",
      "Epoch 2987/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 996.7623 - val_loss: 900.5133\n",
      "Epoch 2988/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 985.9841 - val_loss: 899.5891\n",
      "Epoch 2989/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 984.9041 - val_loss: 901.5480\n",
      "Epoch 2990/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.4491 - val_loss: 898.4880\n",
      "Epoch 2991/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 988.6184 - val_loss: 904.1591\n",
      "Epoch 2992/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 979.3299 - val_loss: 896.7170\n",
      "Epoch 2993/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 985.4357 - val_loss: 898.8627\n",
      "Epoch 2994/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 976.3986 - val_loss: 902.7612\n",
      "Epoch 2995/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.5656 - val_loss: 898.7388\n",
      "Epoch 2996/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 998.2064 - val_loss: 901.3543\n",
      "Epoch 2997/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 989.7601 - val_loss: 896.5624\n",
      "Epoch 2998/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 984.4361 - val_loss: 897.6199\n",
      "Epoch 2999/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 984.3120 - val_loss: 901.7180\n",
      "Epoch 3000/3000\n",
      "36515/36515 [==============================] - 0s 1us/sample - loss: 979.7349 - val_loss: 900.3864\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Dense(32, activation = 'relu', input_dim = 300))\n",
    "\n",
    "model.add(keras.Input(shape=(300,)))\n",
    "model.add(keras.layers.Dense(256, activation='relu', kernel_initializer = 'normal'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(128, activation='relu', kernel_initializer = 'normal'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "# model.add(keras.layers.Dense(512, activation='relu', kernel_initializer = 'normal'))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(units = 1))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer= 'adam',loss = 'mean_squared_error')\n",
    "\n",
    "checkpoint_filepath = '/log'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "# model.load_weights(checkpoint_filepath)\n",
    "    \n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=10000, epochs=3000, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_log.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][:3000])\n",
    "plt.plot(history.history['val_loss'][:3000])\n",
    "plt.title('Model Accuracy',fontsize=20)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.497373332322866\n",
      "0.6610306253961309 0.5823663144592786 0.552474902527388\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred= model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "abs_er = mean_absolute_error(y_test, y_test_pred)\n",
    "print(abs_er)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "rsq_train = r2_score(y_train, y_train_pred)\n",
    "rsq_val = r2_score(y_val, y_val_pred)\n",
    "rsq_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(rsq_train, rsq_val, rsq_test)\n",
    "# 100 epoches: abs_er= 19.991914022416207; rsq =0.6311475230416835; rsq_train = 0.9392278263642062 \n",
    "# 20.781554059329675\n",
    "# 0.6444936458044239 0.5632780303898981 0.5536371000303386\n",
    "\n",
    "#3000 epoch (512/256/512) abs=23.203737412144314  r2 = 0.768495009799099  0.5852656900697112 0.5530109538595611\n",
    "#3000 epoch (512/0.3,256/0.3, 512)abs=20.688904906315482 r2 =0.9325278290184188 0.6484640725710789 0.6103992408162731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.plot(range(300), range(300), '-r')\n",
    "plt.xlim(0, 300)\n",
    "plt.ylim(0, 300)\n",
    "plt.title(\"Neural Network\")\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfnn['le_halfyear'] = dfnn['le_months'].apply(lambda x: round(x/6))\n",
    "\n",
    "dfnn['le_halfyear'].value_counts().sort_index()\n",
    "\n",
    "X = np.array(dfnn['note_spacy_vec'].tolist())\n",
    "label = dfnn['le_halfyear']\n",
    "\n",
    "X_trainval, X_test, label_trainval, label_test = train_test_split(X, label, test_size=0.2, random_state=42)\n",
    "X_train, X_val, label_train, label_val = train_test_split(X_trainval, label_trainval, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "# model.add(keras.layers.Dense(32, activation = 'relu', input_dim = 300))\n",
    "\n",
    "model.add(keras.Input(shape=(300,)))\n",
    "model.add(keras.layers.Dense(256, activation='relu', kernel_initializer = 'normal'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(256, activation='relu', kernel_initializer = 'normal'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(256, activation='relu', kernel_initializer = 'normal'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(43, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer= 'adam',loss = 'sparse_categorical_crossentropy')\n",
    "\n",
    "checkpoint_filepath = '/log'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "# model.load_weights(checkpoint_filepath)\n",
    "    \n",
    "model_log = model.fit(X_train, label_train, validation_data=(X_val, label_val), batch_size=10000, epochs=10000, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_log.history['acc'][:1000])\n",
    "plt.plot(model_log.history['val_acc'][:1000])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(checkpoint_filepath)\n",
    "\n",
    "label_train_pred = np.argmax(model.predict(X_train),1)\n",
    "label_val_pred = np.argmax(model.predict(X_val),1)\n",
    "label_test_pred= np.argmax(model.predict(X_test),1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "rsq_train = accuracy_score(label_train, label_train_pred)\n",
    "rsq_val = accuracy_score(label_val, label_val_pred)\n",
    "rsq_test = accuracy_score(label_test, label_test_pred)\n",
    "\n",
    "print(rsq_train, rsq_val, rsq_test)\n",
    "# 0.7535449361659181 0.2555634051571883 0.25633554083885207\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
