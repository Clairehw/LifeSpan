{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Quadro P2000\n",
      "5.0 0 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():   \n",
    "  \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name()\n",
    "torch.cuda.current_device()\n",
    "t = torch.cuda.get_device_properties(0).total_memory/1024/1024/1024\n",
    "c = torch.cuda.memory_cached(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "print(t, c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Insight1\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "os.chdir(\"I:\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize notes by Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('spacy_vec_split_len.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean2(note):\n",
    "    table = str.maketrans('', '','!\"#$%&\\'()*+,-./:;<=>?@‘¥£’—“[\\\\]^_`{|}~«»§é')\n",
    "    s = note.translate(table)\n",
    "    s1 = s.replace('\\n',' ').lower()\n",
    "    s2 = re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '', s1)\n",
    "    st_clean = re.sub(r' +', ' ', s2)\n",
    "    return st_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['notes_clean'] = df['notes'].progress_apply(lambda x: clean2(x))\n",
    "\n",
    "df['len_clean'] = df['notes_clean'].progress_apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "df[['key','notes','le_months','notes_clean','len_clean']].to_pickle('notes_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['noteclean_spacy_vec'] = df['notes_clean'].progress_apply(lambda x: nlp(x).vector)\n",
    "\n",
    "df[['notes_clean','noteclean_spacy_vec','le_months']].to_pickle('clean_note_spacy_vec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df['len_clean']<=2000) & (df['len_clean']>=100) & (df['le_months'] <=250)\n",
    "df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note_spacy_vec'] = df['notes'].progress_apply(lambda x: nlp(x).vector)\n",
    "\n",
    "df.to_pickle('spacy_vec.pkl') #save Spacy vectorized notes to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['le_months'] = df['le_months'].astype(int)\n",
    "print(df.dtypes)\n",
    "\n",
    "print(df['le_months'].astype(int).min())\n",
    "print(df['le_months'].astype(int).max())\n",
    "\n",
    "ave_mo = np.average(df['le_months'].to_numpy())\n",
    "mode_mo = stats.mode(df['le_months'].to_numpy())\n",
    "print('Months to live Average: {} \\nMonths to live mode: {}'.format(ave_mo, mode_mo[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save spacy_vec, note_split, len_word as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['len_char'] = df['notes'].apply(len)\n",
    "df['note_split'] = df['notes'].str.replace('\\n', '').str.replace(r' +', ' ').str.split(' ') #replace \\n with space or not\n",
    "df['len_word'] = df['note_split'].apply(len)\n",
    "\n",
    "df.to_pickle('spacy_vec_split_len.pkl') #save Spacy vectorized notes to pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load spacy_vec_split_len.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('spacy_vec_split_len.pkl')\n",
    "# type(df['note_split'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note_spacy_vec'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot life expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['le_months']].plot(kind='hist',bins=[0,100, 200, 400],rwidth=0.8)\n",
    "plt.hist(df['le_months'].to_numpy(), bins = 50, color = 'gold', ec = 'black')\n",
    "plt.xlabel('Month', fontsize =12)\n",
    "plt.ylabel('Frequency',fontsize =12)\n",
    "plt.title('Remaining Life Expectancy  Distribution')\n",
    "# plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot number of words per note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['len_word']].plot(kind='hist',bins=[0,100, 1000, 5000, math.inf],rwidth=0.8)\n",
    "plt.hist(df['len_word'].to_numpy(), bins = 50, color = 'pink', ec = 'black')\n",
    "plt.xlabel('Words Per Note',fontsize =12)\n",
    "plt.ylabel('Frequency',fontsize =12)\n",
    "plt.title('Number of Words per Note')#### Plot life expectancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "df.drop(index = df[(df['len_word'] <=2) | (df['len_word']>= 2000)].index, inplace = True) # remonve empty or >2000 note\n",
    "df.drop(index = df[df['le_months']>250].index, inplace = True) # remove life expect > 250 mo (21 years)\n",
    "# above total removed 706 data\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot note Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('spacy_vec_split_len.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df['len_word'] >= 500) & (df['len_word'] <= 600)\n",
    "notewc = df.loc[filt, 'notes'].copy()\n",
    "notewc.index = range(len(notewc))\n",
    "\n",
    "import random\n",
    "a = random.randrange(len(notewc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "STOPWORDS.update(['noted', 'was', 'say','Was','cited','Vv'])\n",
    "stopwords = set(STOPWORDS)\n",
    "wc = WordCloud(width = 800, height = 800, \n",
    "               background_color ='white', \n",
    "               stopwords = stopwords)\n",
    "\n",
    "\n",
    "wc.generate(notewc[a])\n",
    "plt.figure(figsize = (6, 6), facecolor = None) \n",
    "plt.imshow(wc) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() \n",
    "wc.to_file('note_wc7.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y from noteclean_spacy_vec\n",
    "filt = df[(df['len_clean']>=100) & (df['len_clean']<=2000) & (df['le_months']<= 250)] # filter data for ML\n",
    "\n",
    "X = np.array(filt['noteclean_spacy_vec'].values.tolist())\n",
    "y = filt['le_months'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y from note_spacy_vec\n",
    "filt = df[(df['len_word']>3) & (df['len_word']<=2000) & (df['le_months']<= 250)] # filter data for ML\n",
    "# filt['len_word'].value_counts().sort_index()\n",
    "\n",
    "X = np.array(filt['note_spacy_vec'].values.tolist())\n",
    "y = filt['le_months'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y from spacy_lss\n",
    "df = pd.read_pickle('spacy_lss.pkl')\n",
    "filt = df[(df['len_lss']>50) & (df['len_lss']<=1000) & (df['le_months']<= 250)] # filter data for ML\n",
    "# filt['len_word'].value_counts().sort_index()\n",
    "\n",
    "X = np.array(filt['spacy_lss'].values.tolist())\n",
    "y = filt['le_months'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple ML models based on Spacy vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4617313122239614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(reg.score(X_test, y_test)) # R^2 variance weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot y_pred over y_test for linear regression (score = 0.43662885147475616)\n",
    "#linear reg spacy_lss r2=0.4617313122239614 for 50-1000 len_lss, le_months<250\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(range(300), range(300), '-r')\n",
    "plt.xlim(0, 300)\n",
    "plt.ylim(0, 300)\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:25:33] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.44425965934761835\n"
     ]
    }
   ],
   "source": [
    "#xgb regressor r2 score = 0.4118154583805178 for 57k data\n",
    "#xgb reg spacy_lss r2= 0.44425965934761835  for 50-1000 len_lss, le_months<250\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "xgb = XGBRegressor().fit(X_train,y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(r2_score(y_test, y_pred_xgb, multioutput='variance_weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(range(300), range(300), '-r')\n",
    "plt.xlim(0, 300)\n",
    "plt.ylim(0, 300)\n",
    "plt.title(\"XGBoost Regressor\")\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5800088178042535\n"
     ]
    }
   ],
   "source": [
    "# random forest regressor score = 0.5402527642512915 for 57k data\n",
    "# rf regressor r2 = 0.5560166555170266 when filted len_word<=750, le_months<=250\n",
    "# rf regressor r2 = 0.5384426783146021 when filted 100<=len_word<=2000, le_months<=250 on noteclean_spacy_vec\n",
    "#rf reg spacy_lss r2= 0.5800088178042535 for 50-1000 len_lss, le_months<250\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "reg_rf = RandomForestRegressor(n_estimators = 100, random_state = 0) \n",
    "reg_rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "y_pred_reg_rf = reg_rf.predict(X_test)\n",
    "y_train_pred = reg_rf.predict(X_train)\n",
    "\n",
    "print(reg_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([167.12      , 122.85      ,  33.48      , 100.39      ,\n",
       "        42.645     ,  58.26166667, 150.86442857,  70.9974127 ,\n",
       "        81.72      ,  35.87195238,  55.31166667,  40.6055    ,\n",
       "        93.28      ,  45.40595238, 104.056     , 160.33      ,\n",
       "        99.996     , 212.32      ,  97.79330952,  41.56666667,\n",
       "        93.25666667, 102.25      ,  84.98      ,  85.5175    ,\n",
       "        45.678     ,  72.42      , 152.82      ,  52.35      ,\n",
       "       115.88      , 156.31      ,  74.3425    ,  77.66045238,\n",
       "       132.395     , 114.59      ,  37.48      , 129.0337619 ,\n",
       "       105.14      , 119.24      ,  98.955     , 102.26      ,\n",
       "        68.91      ,  43.02166667, 100.56      ,  51.98828571,\n",
       "       126.48738095, 101.42333333,  71.48833333, 118.98      ,\n",
       "        37.00666667,  76.988     ,  77.45      , 123.54333333,\n",
       "        87.79952381, 108.08      , 107.23      ,  78.655     ,\n",
       "       151.58      ,  67.177     , 128.45      ,  76.39014286,\n",
       "        48.92933333,  83.14      , 148.93      , 101.355     ,\n",
       "       101.42      , 150.245     , 177.65733333,  34.385     ,\n",
       "       107.67869048,  40.21036587,  30.07361905, 130.71964286,\n",
       "        85.5       ,  49.59857143,  86.92      , 157.73283333,\n",
       "       121.43      , 172.69      ,  61.625     , 122.7       ,\n",
       "        88.505     ,  79.81      , 149.51      , 154.05      ,\n",
       "       124.68666667, 138.44333333, 104.97      ,  43.36      ,\n",
       "       104.62      ,  71.28      , 107.58316667,  78.72      ,\n",
       "       107.575     ,  99.        , 101.28      ,  88.03      ,\n",
       "        69.74      , 151.22      , 146.384     ,  86.64      ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(y_test[100:150], y_pred_reg_rf[100:150], label = 'Test')\n",
    "plt.scatter(y_train[100:200], y_train_pred[100:200], label = 'Train')\n",
    "plt.plot(range(300), range(300), '-r')\n",
    "plt.xlim(0, 300)\n",
    "plt.ylim(0, 300)\n",
    "plt.title(\"Random Forest Regressor\")\n",
    "plt.xlabel(\"True\",fontsize =12)\n",
    "plt.ylabel(\"Predicted\",fontsize =12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianRidge regressor score = 0.4366820387501755, basically the model didn't work. \n",
    "# std for predicted label is nearly 60% of predicted value.\n",
    "from sklearn import linear_model\n",
    "reg_br = linear_model.BayesianRidge()\n",
    "reg_br.fit(X_train, y_train)\n",
    "\n",
    "print(reg_br.score(X_test, y_test))\n",
    "\n",
    "print(reg_br.predict(X_test[:10], return_std = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lstm, self).__init__()\n",
    "        self.lstm_layer = nn.LSTM(300, 300)\n",
    "        self.linear_layer = nn.Linear(300, 1)\n",
    "    def forward(self, input_vec):\n",
    "        output, _ = self.lstm_layer(input_vec)\n",
    "        logit = self.linear_layer(output.view(len(input_vec), -1))\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm()\n",
    "print(model)\n",
    "\n",
    "for p in model.named_parameters():\n",
    "    print(p[0], str(tuple(p[1].size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Text into 510 per group for BERT input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_idmtx(note):\n",
    "    ids = tokenizer.encode(note, add_special_tokens = False)\n",
    "    idmtx = [[101]+ids[i:i+510]+[102] for i in range(0, len(ids), 510)]\n",
    "    idmtx[-1] += (512-len(idmtx[-1]))*[0]\n",
    "    idmtx = np.array(idmtx).reshape(-1, 512)\n",
    "    return idmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_token_id'] = df['token_id'].progress_apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['token_id_matrix'] = df['notes'].progress_apply(text_to_idmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['key','notes', 'le_months', 'note_spacy_vec', 'bert_token_id','token_id_matrix']].to_csv('note_vec_token.csv', index = False)\n",
    "\n",
    "df[['key','notes', 'le_months', 'note_spacy_vec','token_id_matrix']].to_pickle('note_vec_token.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_row(mtx, k=6):\n",
    "    row = mtx.shape[0]\n",
    "    if row <= k:\n",
    "        n = 512*(k-row)\n",
    "        mtx_new = np.append(mtx.reshape(1, -1), [0]*n)\n",
    "    else:\n",
    "        mtx_new = np.squeeze(mtx.reshape(1,-1))[: k*512]\n",
    "    return mtx_new\n",
    "\n",
    "\n",
    "df['six_row'] = df['token_id_matrix'].progress_apply(k_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['six_row'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbert = df[df['le_months'] <= 250]\n",
    "X = np.array(dfbert['six_row'].tolist()).astype(np.int64)\n",
    "y = dfbert['le_months'].astype(np.float32).to_numpy()\n",
    "\n",
    "mask = (X!=0).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import  AutoTokenizer, AutoModel\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(input_ids, input_mask, labels, batch_size=32, val_test_size=0.1, random_seed=2020):\n",
    "  \"\"\"This function takes in all available data, split into train, val, test, and return a torch DataLoader for each. \n",
    "  \"\"\"\n",
    "  # split into train, validation, test \n",
    "  X_train_val, X_test, y_train_val, y_test = train_test_split(input_ids, labels, random_state=random_seed, test_size=val_test_size)\n",
    "  mask_train_val, mask_test, _, _ = train_test_split(input_mask, labels, random_state=random_seed, test_size=val_test_size)\n",
    "\n",
    "  X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=random_seed, test_size=val_test_size)\n",
    "  mask_train, mask_val, _, _ = train_test_split(mask_train_val, y_train_val, random_state=random_seed, test_size=val_test_size)\n",
    "\n",
    "  # turn numpy array into tensor\n",
    "  X_train, X_val, X_test  = torch.tensor(X_train), torch.tensor(X_val), torch.tensor(X_test)\n",
    "  y_train, y_val, y_test = torch.tensor(y_train), torch.tensor(y_val), torch.tensor(y_test)\n",
    "  mask_train, mask_val, mask_test = torch.tensor(mask_train), torch.tensor(mask_val), torch.tensor(mask_test)\n",
    "\n",
    "  # Create the DataLoader for training set.\n",
    "  train_data = TensorDataset(X_train, mask_train, y_train)\n",
    "  train_sampler = RandomSampler(train_data)\n",
    "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "  # Create the DataLoader for validation set.\n",
    "  validation_data = TensorDataset(X_val, mask_val, y_val)\n",
    "  validation_sampler = SequentialSampler(validation_data)\n",
    "  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "  # Create the DataLoader for testing set.\n",
    "  test_data = TensorDataset(X_test, mask_test, y_test)\n",
    "  test_sampler = SequentialSampler(test_data)\n",
    "  test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "  return(train_dataloader, validation_dataloader, test_dataloader)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "  def __init__(self, num_class=1, freeze_bert = True):\n",
    "    super(Model, self).__init__()\n",
    "\n",
    "    #Instantiating clinical_bert model  \n",
    "    self.clinical_bert_layer = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "    #Freeze bert layers\n",
    "    if freeze_bert:\n",
    "        for p in self.clinical_bert_layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    self.lstm_layer = nn.LSTM(input_size=768, hidden_size=768, num_layers=1, batch_first=False)\n",
    "    self.cls_layer = nn.Linear(768, num_class)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "  \n",
    "    batch_size, lstm_length = input_ids.shape[0], int(input_ids.shape[1] / 512)\n",
    "    input_ids, attention_mask = input_ids.view(-1, 512), attention_mask.view(-1, 512)\n",
    "    last_hidden_state , _ = self.clinical_bert_layer(input_ids, attention_mask = attention_mask)\n",
    "    cls_embedding = last_hidden_state[:, 0, :].unsqueeze(1)\n",
    "    cls_embedding = cls_embedding.view(lstm_length, batch_size, -1)\n",
    "    _, (hn, _) = self.lstm_layer(cls_embedding) \n",
    "    cls_holistic = hn[-1]\n",
    "    logits = self.cls_layer(cls_holistic).squeeze()\n",
    "    del input_ids, attention_mask, last_hidden_state, cls_embedding, hn, cls_holistic\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_dataloader, val_dataloader, config, scheduler=None):\n",
    "  \n",
    "  random.seed(config.random_seed)\n",
    "  np.random.seed(config.random_seed)\n",
    "  torch.manual_seed(config.random_seed)\n",
    "  torch.cuda.manual_seed_all(config.random_seed)\n",
    "\n",
    "      # ========================================\n",
    "      #               Training\n",
    "      # ========================================\n",
    "  iterations = 0\n",
    "  for epoch in tqdm(range(0, config.epochs)):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, config.epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader),desc='Training one epoch'):\n",
    "\n",
    "      # Unpack this training batch from our dataloader. \n",
    "      b_input_ids = batch[0].to(config.device)\n",
    "      b_input_mask = batch[1].to(config.device)\n",
    "      b_targets = batch[2].to(config.device)\n",
    "\n",
    "      model.zero_grad()  # set gradient to 0 before training\n",
    "      logits = model(b_input_ids, attention_mask=b_input_mask)  # forward pass\n",
    "\n",
    "      loss = criterion(logits, b_targets) # calculate the batch loss\n",
    "      total_loss += loss.item() # accumulate loss in an epoch to compute average loss \n",
    "\n",
    "      elapsed = format_time(time.time() - t0) # Calculate elapsed time in minutes.\n",
    "      if step % config.print_interval == 0 and not step == 0:\n",
    "        print('  Batch {:>5,}  of  {:>5,}.  Elapsed: {:}.  Loss: {:>6.4f}.'.format(step, len(train_dataloader), elapsed, loss))\n",
    "\n",
    "      loss.backward()  # back prop\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # clip gradient to prevent exploding\n",
    "      optimizer.step()  # update weights\n",
    "      if scheduler:\n",
    "        scheduler.step()  # Update the learning rate.\n",
    "      iterations += 1\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "\n",
    "      if iterations % config.val_interal == 0 and not iterations == 0:\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t1 = time.time()\n",
    "        model.eval()   # Put the model in evaluation mode--the dropout layers behave differently during eval\n",
    "\n",
    "        eval_loss, nb_eval_steps = 0, 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "            \n",
    "            batch = tuple(t.to(config.device) for t in batch)       # Add batch to GPU\n",
    "            b_input_ids, b_input_mask, b_targets = batch      # Unpack the inputs from our dataloader\n",
    "            \n",
    "            # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "            with torch.no_grad():\n",
    "              logits = model(b_input_ids, attention_mask=b_input_mask)\n",
    "\n",
    "            loss = criterion(logits, b_targets) # calculate the batch loss\n",
    "            eval_loss += loss\n",
    "\n",
    "            nb_eval_steps += 1      # Track the number of batches\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        print(\"  MSE: {0:.4f}\".format(eval_loss/nb_eval_steps))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - t1)))\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'iterations': iterations,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss_MAE': eval_loss/nb_eval_steps,\n",
    "            }, config.PATH + '_' + str(iterations))\n",
    "        model.train()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)  # Calculate the average loss over the training data.      \n",
    "\n",
    "    print(\"  Average training MSE: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "  print(\"\")\n",
    "  print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "  device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "  batch_size=32\n",
    "  epochs = 10\n",
    "  val_interal=100   # do validation after this number of batches have been trained\n",
    "  print_interval=40 # print the details of the training every this number of batch\n",
    "  val_test_size=0.1  \n",
    "  random_seed=42\n",
    "  PATH = './checkpoints/checkpoint'\n",
    "\n",
    "config = Config()\n",
    "\n",
    "model = Model(num_class=1, freeze_bert=True)\n",
    "model.to(config.device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8 )\n",
    "\n",
    "\n",
    "# # dummy data\n",
    "# input_ids = np.random.randint(1, 10000, (1000, 512))\n",
    "# input_mask = np.ones_like(input_ids)\n",
    "# targets = np.random.randint(1, 5, (1000,))\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = dataLoader(X, mask, y)\n",
    "total_steps = len(train_dataloader) * config.epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.batch_size = 8\n",
    "config.val_interal = 500\n",
    "config.epochs = 10\n",
    "\n",
    "# model = Model(num_class=1, freeze_bert=True)\n",
    "# model.to(config.device)\n",
    "train(model, criterion, optimizer, train_dataloader, val_dataloader, config, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.max_memory_allocated(device=config.device) / 1024 / 1024 / 1024)\n",
    "torch.cuda.memory_allocated(device=config.device) / 1024 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_divmod'] = df['len_token_id'].apply(lambda x: divmod(x, 510))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_matrix (series):\n",
    "    div = series['len_divmod'][0]\n",
    "    rem = series['len_divmod'][1]\n",
    "    if rem != 0:\n",
    "        divs = 510 * div\n",
    "        series[1] = series[0][divs:]\n",
    "        series[0] = np.array(series[0][:divs]).reshape(div, 510)\n",
    "        \n",
    "    else:\n",
    "        series[1][1] == 0\n",
    "        series[1] = [' ']\n",
    "        series[0] = np.array(series[0]).reshape(div, 510)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['token_id','len_divmod']].copy()\n",
    "df1.iloc[0]\n",
    "df1 = df1.progress_apply(id_matrix, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
